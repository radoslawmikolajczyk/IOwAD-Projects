{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Karolina_Filipiuk_Radoslaw_Mikolajczyk.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrUWbS5BRMy-"
      },
      "source": [
        "Karolina Filipiuk: kfilipiuk@student.agh.edu.pl\n",
        "\n",
        "Radosław Mikołajczyk: rmikolajczyk@student.agh.edu.pl"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_G82yIKHsrH"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.datasets import mnist\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from keras import models, layers\n",
        "from keras.utils import to_categorical\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "\n",
        "\n",
        "## [deskew]\n",
        "SZ=28\n",
        "affine_flags = cv2.WARP_INVERSE_MAP|cv2.INTER_LINEAR\n",
        "\n",
        "def deskew(img):\n",
        "    m = cv2.moments(img)\n",
        "    if abs(m['mu02']) < 1e-2:\n",
        "        return img.copy()\n",
        "    skew = m['mu11']/m['mu02']\n",
        "    M = np.float32([[1, skew, -0.5*SZ*skew], [0, 1, 0]])\n",
        "    img = cv2.warpAffine(img,M,(SZ, SZ),flags=affine_flags)\n",
        "    return img\n",
        "## [deskew]\n",
        "\n",
        "def showOpencvImage(image, isGray=False):\n",
        "    fig = plt.figure(figsize=(6, 6))\n",
        "    plt.imshow(image, cmap = 'gray')\n",
        "    plt.show()\n",
        "\n",
        "def openCVHOG(im):\n",
        "    winSize = (20,20)\n",
        "    blockSize = (10,10)\n",
        "    blockStride = (5,5)\n",
        "    cellSize = (10,10)\n",
        "    nbins = 9\n",
        "    derivAperture = 1\n",
        "    winSigma = -1.\n",
        "    histogramNormType = 0\n",
        "    L2HysThreshold = 0.2\n",
        "    gammaCorrection = 1\n",
        "    nlevels = 64\n",
        "    signedGradients = True\n",
        "\n",
        "    hog = cv2.HOGDescriptor(winSize,blockSize,blockStride,cellSize,nbins,derivAperture,winSigma,histogramNormType,L2HysThreshold,gammaCorrection,nlevels, signedGradients)\n",
        "    descriptor = np.ravel(hog.compute(im))\n",
        "    \n",
        "    return descriptor"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBb4X1T8H1hj"
      },
      "source": [
        "Wczytanie oraz wstępne przetwarzanie danych"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYdrte9hH4Rw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c699bcc0-cc5a-4481-de2d-676dacbeba23"
      },
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Wektoryzowane surowe dane\n",
        "train_raw = train_images.reshape(len(train_images), 28 * 28)\n",
        "test_raw = test_images.reshape(len(test_images), 28 * 28)\n",
        "\n",
        "# Dane zmieszane\n",
        "train_shuffle_data = np.random.permutation(train_raw)\n",
        "test_shuffle_data = np.random.permutation(test_raw)\n",
        "\n",
        "\n",
        "# Dane wyrównane\n",
        "train_deskewed = np.float32([deskew(im) for im in train_raw])\n",
        "test_deskewed = np.float32([deskew(im) for im in test_raw])\n",
        "train_deskewed = np.asarray(train_deskewed).reshape(-1,28*28)\n",
        "test_deskewed = np.asarray(test_deskewed).reshape(-1,28*28)\n",
        "\n",
        "\n",
        "# Dane hog descriptor\n",
        "hogdata_train = np.float32([openCVHOG(im) for im in train_images]).reshape(-1,81)\n",
        "hogdata_test = np.float32([openCVHOG(im) for im in test_images]).reshape(-1,81)\n",
        "hogdata_train_deskewed = np.float32([openCVHOG(deskew(im)) for im in train_images]).reshape(-1,81)\n",
        "hogdata_test_deskewed = np.float32([openCVHOG(deskew(im)) for im in test_images]).reshape(-1,81)\n",
        "\n",
        "\n",
        "# Dane do wyszukiwania w siatce i przeszukiwania siatki z walidacją krzyżową\n",
        "hogdata_train_deskewed_short = hogdata_train_deskewed[:600]\n",
        "train_labels_short = train_labels[:600]\n",
        "hogdata_train_short = hogdata_train[:600]\n",
        "\n",
        "# przygotowanie modelu dla sieci neuronowej\n",
        "def create_model():\n",
        "  model = models.Sequential()\n",
        "  model.add(layers.Dense(512, activation='relu'))\n",
        "  model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "  model.compile(optimizer='rmsprop',\n",
        "                    loss='categorical_crossentropy',\n",
        "                    metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sbAL-4BTHaR"
      },
      "source": [
        "# **Zadanie 2**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kW29tko0YTLo"
      },
      "source": [
        "Porównanie wyników działania klasyfikatorów dla poniższych przypadków:\n",
        "\n",
        "1.   Obrazy oryginalne->Deskew->HOG->Klasyfikator (SVM, Las losowy, Sieć)\n",
        "2.   Obrazy oryginalne->HOG->Klasyfikator (SVM, Las losowy, Sieć)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1cvbieDZ3Ca"
      },
      "source": [
        "**SVM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Slqy8l9YaX95",
        "outputId": "6ccda8a0-7b53-440b-a779-0a2b8232be6d"
      },
      "source": [
        "#Walidacja krzyżowa z wykorzystaniem GridsearchCV\n",
        "\n",
        "deskew_parameters = {'kernel':('linear', 'rbf'), 'C': np.linspace(start = 0.001, stop = 2, num = 200)}\n",
        "deskew_model = GridSearchCV(svm.SVC(), deskew_parameters, scoring='accuracy', cv=5)\n",
        "deskew_model.fit(hogdata_train_deskewed_short, train_labels[:600])\n",
        "deskew_params = deskew_model.best_params_\n",
        "deskew_svc_best_estimator = deskew_model.best_estimator_\n",
        "print(\"Chosing SVM params for deskewed data: \", deskew_params)\n",
        "print(\"Best SVM estimator for deskewed data: \", deskew_svc_best_estimator)\n",
        "\n",
        "print('\\n\\n')\n",
        "\n",
        "parameters = {'kernel':('linear', 'rbf'), 'C': np.linspace(start = 0.001, stop = 2, num = 200)}\n",
        "model = GridSearchCV(svm.SVC(), parameters, scoring='accuracy', cv=5)\n",
        "model.fit(hogdata_train_short, train_labels[:600])\n",
        "params = model.best_params_\n",
        "svc_best_estimator = model.best_estimator_\n",
        "print(\"Chosing SVM params for non-deskewed data: \", params)\n",
        "print(\"Best SVM estimator for non-deskewed data: \", svc_best_estimator)\n",
        "\n",
        "\n",
        "pred_labels_deskewed = deskew_model.predict(hogdata_test_deskewed)\n",
        "pred_labels = model.predict(hogdata_test)\n",
        "\n",
        "print(\"SVM Accuracy for deskewed images: {}\".format(accuracy_score(test_labels, pred_labels_deskewed)))\n",
        "print(\"SVM Accuracy for non-deskewed images: {}\\n\".format(accuracy_score(test_labels, pred_labels)))\n",
        "\n",
        "print(\"SVM Confusion matrix for deskewed images:\\n{}\".format(confusion_matrix(test_labels, pred_labels_deskewed)))\n",
        "print(\"SVM Classification report for deskewed images:\\n{}\\n\\n\".format(classification_report(test_labels, pred_labels_deskewed)))\n",
        "\n",
        "print(\"SVM Confusion matrix for non-deskewed images:\\n{}\".format(confusion_matrix(test_labels, pred_labels)))\n",
        "print(\"SVM Classification report for non-deskewed images:\\n{}\\n\\n\".format(classification_report(test_labels, pred_labels)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Chosing params for deskewed data:  {'C': 0.714211055276382, 'kernel': 'linear'}\n",
            "Best estimator for deskewed data:  SVC(C=0.714211055276382, break_ties=False, cache_size=200, class_weight=None,\n",
            "    coef0=0.0, decision_function_shape='ovr', degree=3, gamma='scale',\n",
            "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
            "    shrinking=True, tol=0.001, verbose=False)\n",
            "\n",
            "\n",
            "\n",
            "Chosing params for deskewed data:  {'C': 0.864889447236181, 'kernel': 'linear'}\n",
            "Best estimator for deskewed data:  SVC(C=0.864889447236181, break_ties=False, cache_size=200, class_weight=None,\n",
            "    coef0=0.0, decision_function_shape='ovr', degree=3, gamma='scale',\n",
            "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
            "    shrinking=True, tol=0.001, verbose=False)\n",
            "Accuracy for deskewed images: 0.9374\n",
            "Accuracy for non-deskewed images: 0.9151\n",
            "\n",
            "Confusion matrix for deskewed images:\n",
            "[[ 950    3    3    0    3    6    2    3    0   10]\n",
            " [   1 1124    2    0    0    0    1    6    1    0]\n",
            " [   2    1  986    2    1    2    3   27    5    3]\n",
            " [   0    2   27  918    1   21    0   20   11   10]\n",
            " [   2    1    5    0  944    2   17    2    0    9]\n",
            " [   3    0    3    3    4  867    0    3    4    5]\n",
            " [  14    5    2    0    8    9  919    0    1    0]\n",
            " [   6    0   50   33    0    2    0  916    4   17]\n",
            " [   3    1   10    7   15   12    2    7  829   88]\n",
            " [   7    0   16    2    5   16   12   22    8  921]]\n",
            "Classification report for deskewed images:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.97      0.97       980\n",
            "           1       0.99      0.99      0.99      1135\n",
            "           2       0.89      0.96      0.92      1032\n",
            "           3       0.95      0.91      0.93      1010\n",
            "           4       0.96      0.96      0.96       982\n",
            "           5       0.93      0.97      0.95       892\n",
            "           6       0.96      0.96      0.96       958\n",
            "           7       0.91      0.89      0.90      1028\n",
            "           8       0.96      0.85      0.90       974\n",
            "           9       0.87      0.91      0.89      1009\n",
            "\n",
            "    accuracy                           0.94     10000\n",
            "   macro avg       0.94      0.94      0.94     10000\n",
            "weighted avg       0.94      0.94      0.94     10000\n",
            "\n",
            "\n",
            "\n",
            "Confusion matrix for non-deskewed images:\n",
            "[[ 943    1   14    0    3    4    9    3    1    2]\n",
            " [   0 1121    2    0    0    0    6    6    0    0]\n",
            " [   2    3  948    6    3    5    4   53    5    3]\n",
            " [   1    1   30  918    0   23    0   22    6    9]\n",
            " [   4    3    2    0  933    0   23    0    0   17]\n",
            " [   2   15    1    6    1  814    5    3   18   27]\n",
            " [  24    5    2    0   19   11  892    0    3    2]\n",
            " [   6    5   63   25    0    3    0  913    1   12]\n",
            " [  11    5   17   11   14   24   18   14  750  110]\n",
            " [  28    5    5    1    5    9    5   22   10  919]]\n",
            "Classification report for non-deskewed images:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.96      0.94       980\n",
            "           1       0.96      0.99      0.98      1135\n",
            "           2       0.87      0.92      0.90      1032\n",
            "           3       0.95      0.91      0.93      1010\n",
            "           4       0.95      0.95      0.95       982\n",
            "           5       0.91      0.91      0.91       892\n",
            "           6       0.93      0.93      0.93       958\n",
            "           7       0.88      0.89      0.88      1028\n",
            "           8       0.94      0.77      0.85       974\n",
            "           9       0.83      0.91      0.87      1009\n",
            "\n",
            "    accuracy                           0.92     10000\n",
            "   macro avg       0.92      0.91      0.91     10000\n",
            "weighted avg       0.92      0.92      0.91     10000\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUnJAC2XiR32"
      },
      "source": [
        "Na podstawie powyższych rezultatów można zauważyc, że klasyfikator SVM działa lepiej dla obrazów z wyrównaniem. \n",
        "\n",
        "*   Accuracy dla obrazów z wyrównaniem: 0.9374\n",
        "*   Accuracy dla obrazów bez wyrównania: 0.9151\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0kLWxNwjSLp"
      },
      "source": [
        "**Las losowy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8UmP_UUjY3w",
        "outputId": "381834c1-002a-437c-9458-030150be5143"
      },
      "source": [
        "parameters_for_cross_validation = {'max_depth':[5, 10, 15], 'n_estimators': [80,100,120], 'max_features': [30, 45, 60]}\n",
        "deskew_model = GridSearchCV(RandomForestClassifier(), parameters_for_cross_validation, cv=5, scoring='accuracy')\n",
        "deskew_model.fit(hogdata_train_deskewed_short, train_labels[:600])\n",
        "deskew_params = deskew_model.best_params_\n",
        "deskew_rfc_best_estimator = deskew_model.best_estimator_\n",
        "print(\"Chosing RandomForestClassifier params for deskewed data: \", deskew_params)\n",
        "print(\"Best RandomForestClassifier estimator for deskewed data: \", deskew_rfc_best_estimator)\n",
        "\n",
        "print('\\n\\n')\n",
        "\n",
        "model = GridSearchCV(RandomForestClassifier(), parameters_for_cross_validation, cv=5, scoring='accuracy')\n",
        "model.fit(hogdata_train_short, train_labels[:600])\n",
        "params = model.best_params_\n",
        "rfc_best_estimator = model.best_estimator_\n",
        "print(\"Chosing RandomForestClassifier params for non-deskewed data: \", params)\n",
        "print(\"Best RandomForestClassifier estimator for non-deskewed data: \", rfc_best_estimator)\n",
        "\n",
        "pred_labels_deskewed = deskew_model.predict(hogdata_test_deskewed)\n",
        "pred_labels = model.predict(hogdata_test)\n",
        "\n",
        "print(\"RFC Accuracy for deskewed images: {}\".format(accuracy_score(test_labels, pred_labels_deskewed)))\n",
        "print(\"RFC Accuracy for non-deskewed images: {}\\n\".format(accuracy_score(test_labels, pred_labels)))\n",
        "\n",
        "print(\"RFC Confusion matrix for deskewed images:\\n{}\".format(confusion_matrix(test_labels, pred_labels_deskewed)))\n",
        "print(\"RFC Classification report for deskewed images:\\n{}\\n\\n\".format(classification_report(test_labels, pred_labels_deskewed)))\n",
        "\n",
        "print(\"RFC Confusion matrix for non-deskewed images:\\n{}\".format(confusion_matrix(test_labels, pred_labels)))\n",
        "print(\"RFC Classification report for non-deskewed images:\\n{}\\n\\n\".format(classification_report(test_labels, pred_labels)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Chosing RandomForestClassifier params for deskewed data:  {'max_depth': 10, 'max_features': 30, 'n_estimators': 80}\n",
            "Best RandomForestClassifier estimator for deskewed data:  RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=10, max_features=30,\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=80,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False)\n",
            "\n",
            "\n",
            "\n",
            "Chosing RandomForestClassifier params for non-deskewed data:  {'max_depth': 10, 'max_features': 30, 'n_estimators': 120}\n",
            "Best RandomForestClassifier estimator for non-deskewed data:  RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=10, max_features=30,\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=120,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False)\n",
            "RFC Accuracy for deskewed images: 0.9075\n",
            "RFC Accuracy for non-deskewed images: 0.8745\n",
            "\n",
            "RFC Confusion matrix for deskewed images:\n",
            "[[ 938    3    5    3    1   12    5    3    2    8]\n",
            " [   1 1114    6    0    4    0    5    4    1    0]\n",
            " [   1    8  928   25    5    5    6   36   11    7]\n",
            " [   0    1   33  916    4    9    0   21   22    4]\n",
            " [   5    3    6    0  911    2   29    0    1   25]\n",
            " [  10    7    2    8    2  830    9    5   11    8]\n",
            " [  21   19    1    1   24    8  882    0    1    1]\n",
            " [   9    1   57   22    1    1    0  911    3   23]\n",
            " [  16   10    9   15   20   23   12    6  768   95]\n",
            " [  21    0   22    4   14   27    6   23   15  877]]\n",
            "RFC Classification report for deskewed images:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.96      0.94       980\n",
            "           1       0.96      0.98      0.97      1135\n",
            "           2       0.87      0.90      0.88      1032\n",
            "           3       0.92      0.91      0.91      1010\n",
            "           4       0.92      0.93      0.93       982\n",
            "           5       0.91      0.93      0.92       892\n",
            "           6       0.92      0.92      0.92       958\n",
            "           7       0.90      0.89      0.89      1028\n",
            "           8       0.92      0.79      0.85       974\n",
            "           9       0.84      0.87      0.85      1009\n",
            "\n",
            "    accuracy                           0.91     10000\n",
            "   macro avg       0.91      0.91      0.91     10000\n",
            "weighted avg       0.91      0.91      0.91     10000\n",
            "\n",
            "\n",
            "\n",
            "RFC Confusion matrix for non-deskewed images:\n",
            "[[ 898    5   14    1    5   17   29    4    1    6]\n",
            " [   0 1119    5    0    1    3    1    5    1    0]\n",
            " [   9    6  868   44    7    8    5   67   10    8]\n",
            " [   2    0   26  889    5   48    0   14   15   11]\n",
            " [   9    2    5    1  893    6   25    1    4   36]\n",
            " [   8   14    7   17    2  785    7    6   15   31]\n",
            " [  54   10    3    0   50   18  818    0    5    0]\n",
            " [   5    0   47   40    1    3    0  914    3   15]\n",
            " [  24   12    7   11   21   55   18    7  690  129]\n",
            " [  32    1   14    1   17   18   11   27   17  871]]\n",
            "RFC Classification report for non-deskewed images:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.92      0.89       980\n",
            "           1       0.96      0.99      0.97      1135\n",
            "           2       0.87      0.84      0.86      1032\n",
            "           3       0.89      0.88      0.88      1010\n",
            "           4       0.89      0.91      0.90       982\n",
            "           5       0.82      0.88      0.85       892\n",
            "           6       0.89      0.85      0.87       958\n",
            "           7       0.87      0.89      0.88      1028\n",
            "           8       0.91      0.71      0.80       974\n",
            "           9       0.79      0.86      0.82      1009\n",
            "\n",
            "    accuracy                           0.87     10000\n",
            "   macro avg       0.87      0.87      0.87     10000\n",
            "weighted avg       0.88      0.87      0.87     10000\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SO-wfWbvSQU"
      },
      "source": [
        "Na podstawie powyższych rezultatów można zauważyc, że klasyfikator RFC działa lepiej dla obrazów z wyrównaniem. \n",
        "\n",
        "*   Accuracy dla obrazów z wyrównaniem: 0.9075\n",
        "*   Accuracy dla obrazów bez wyrównania: 0.8745"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ysg07Rxfvue_"
      },
      "source": [
        "**Sieć neuronowa**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axZhuZIav1Vt",
        "outputId": "543b2496-120d-4495-b7c5-8456f21fe028"
      },
      "source": [
        "nn_train_deskewed = np.array(hogdata_train_deskewed).reshape((60000, 81))\n",
        "nn_train_deskewed = nn_train_deskewed.astype('float32') / 255\n",
        "\n",
        "nn_test_deskewed = np.array(hogdata_test_deskewed).reshape((10000, 81))\n",
        "nn_test_deskewed = nn_test_deskewed.astype('float32') / 255\n",
        "\n",
        "nn_train_non_deskewed = np.array(hogdata_train).reshape((60000, 81))\n",
        "nn_train_non_deskewed = nn_train_non_deskewed.astype('float32') / 255\n",
        "\n",
        "nn_test_non_deskewed = np.array(hogdata_test).reshape((10000, 81))\n",
        "nn_test_non_deskewed = nn_test_non_deskewed.astype('float32') / 255\n",
        "\n",
        "encoded_train_labels = to_categorical(train_labels)\n",
        "encoded_test_labels = to_categorical(test_labels)\n",
        "\n",
        "parameters_for_cross_validation = {'epochs':[1,6,12], 'batch_size':[32,64,128]}\n",
        "deskew_network = KerasClassifier(create_model)\n",
        "deskew_model = GridSearchCV(estimator=deskew_network, param_grid=parameters_for_cross_validation, cv=5)\n",
        "deskew_model.fit(nn_train_deskewed, encoded_train_labels)\n",
        "deskew_params = deskew_model.best_params_\n",
        "print(\"Chosing Neural Network params for deskewed data: \", deskew_params)\n",
        "\n",
        "network = KerasClassifier(build_fn=create_model, verbose=0)\n",
        "model = GridSearchCV(estimator=network, param_grid=parameters_for_cross_validation, cv=5)\n",
        "model.fit(nn_train_non_deskewed, encoded_train_labels)\n",
        "params = model.best_params_\n",
        "print(\"Chosing Neural Network params for non-deskewed data: \", params)\n",
        "\n",
        "pred_labels_deskewed = deskew_model.predict(nn_test_deskewed)\n",
        "pred_labels_non_deskewed = model.predict(nn_test_non_deskewed)\n",
        "\n",
        "\n",
        "print(\"NN Accuracy for deskewed data: {}\".format(accuracy_score(test_labels, pred_labels_deskewed)))\n",
        "print(\"NN Accuracy for non-deskewed data: {}\\n\\n\".format(accuracy_score(test_labels, pred_labels_non_deskewed)))\n",
        "\n",
        "print(\"NN Confusion matrix for deskewed images:\\n{}\".format(confusion_matrix(test_labels, pred_labels_deskewed)))\n",
        "print(\"NN Classification report for deskewed images:\\n{}\\n\\n\".format(classification_report(test_labels, pred_labels_deskewed)))\n",
        "\n",
        "print(\"NN Confusion matrix for non-deskewed images:\\n{}\".format(confusion_matrix(test_labels, pred_labels_non_deskewed)))\n",
        "print(\"NN Classification report for non-deskewed images:\\n{}\\n\\n\".format(classification_report(test_labels, pred_labels_non_deskewed)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1500/1500 [==============================] - 3s 2ms/step - loss: 2.1430 - accuracy: 0.2714\n",
            "375/375 [==============================] - 1s 1ms/step - loss: 1.4339 - accuracy: 0.6647\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 2.1427 - accuracy: 0.2878\n",
            "375/375 [==============================] - 1s 1ms/step - loss: 1.4168 - accuracy: 0.6730\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 2.1335 - accuracy: 0.2871\n",
            "375/375 [==============================] - 1s 1ms/step - loss: 1.3924 - accuracy: 0.6658\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 2.1314 - accuracy: 0.2928\n",
            "375/375 [==============================] - 1s 1ms/step - loss: 1.4017 - accuracy: 0.6863\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 2.1313 - accuracy: 0.2945\n",
            "375/375 [==============================] - 1s 1ms/step - loss: 1.4079 - accuracy: 0.7008\n",
            "Epoch 1/6\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 2.1490 - accuracy: 0.2929\n",
            "Epoch 2/6\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 1.2581 - accuracy: 0.7124\n",
            "Epoch 3/6\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.7631 - accuracy: 0.8161\n",
            "Epoch 4/6\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.5349 - accuracy: 0.8597\n",
            "Epoch 5/6\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.4224 - accuracy: 0.8834\n",
            "Epoch 6/6\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.3520 - accuracy: 0.8983\n",
            "375/375 [==============================] - 1s 1ms/step - loss: 0.3118 - accuracy: 0.9132\n",
            "Epoch 1/6\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 2.1384 - accuracy: 0.3009\n",
            "Epoch 2/6\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 1.2468 - accuracy: 0.7103\n",
            "Epoch 3/6\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.7385 - accuracy: 0.8170\n",
            "Epoch 4/6\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.5108 - accuracy: 0.8658\n",
            "Epoch 5/6\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.4043 - accuracy: 0.8891\n",
            "Epoch 6/6\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.3257 - accuracy: 0.9085\n",
            "375/375 [==============================] - 1s 1ms/step - loss: 0.2925 - accuracy: 0.9120\n",
            "Epoch 1/6\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 2.1457 - accuracy: 0.2849\n",
            "Epoch 2/6\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 1.2601 - accuracy: 0.7152\n",
            "Epoch 3/6\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.7542 - accuracy: 0.8171\n",
            "Epoch 4/6\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.5288 - accuracy: 0.8591\n",
            "Epoch 5/6\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.4138 - accuracy: 0.8870\n",
            "Epoch 6/6\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.3425 - accuracy: 0.9043\n",
            "375/375 [==============================] - 1s 1ms/step - loss: 0.3190 - accuracy: 0.9086\n",
            "Epoch 1/6\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 2.1435 - accuracy: 0.2811\n",
            "Epoch 2/6\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 1.2703 - accuracy: 0.7042\n",
            "Epoch 3/6\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.7625 - accuracy: 0.8136\n",
            "Epoch 4/6\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.5317 - accuracy: 0.8584\n",
            "Epoch 5/6\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.4174 - accuracy: 0.8869\n",
            "Epoch 6/6\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.3453 - accuracy: 0.9041\n",
            "375/375 [==============================] - 1s 1ms/step - loss: 0.3217 - accuracy: 0.9099\n",
            "Epoch 1/6\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 2.1202 - accuracy: 0.2790\n",
            "Epoch 2/6\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 1.1889 - accuracy: 0.7266\n",
            "Epoch 3/6\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.7061 - accuracy: 0.8294\n",
            "Epoch 4/6\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.4922 - accuracy: 0.8700\n",
            "Epoch 5/6\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.3887 - accuracy: 0.8940\n",
            "Epoch 6/6\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.3239 - accuracy: 0.9082\n",
            "375/375 [==============================] - 1s 1ms/step - loss: 0.2757 - accuracy: 0.9230\n",
            "Epoch 1/12\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 2.1524 - accuracy: 0.2899\n",
            "Epoch 2/12\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 1.3067 - accuracy: 0.7004\n",
            "Epoch 3/12\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.8095 - accuracy: 0.8094\n",
            "Epoch 4/12\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.5489 - accuracy: 0.8613\n",
            "Epoch 5/12\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.4232 - accuracy: 0.8859\n",
            "Epoch 6/12\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.3548 - accuracy: 0.8994\n",
            "Epoch 7/12\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.3012 - accuracy: 0.9138\n",
            "Epoch 8/12\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2657 - accuracy: 0.9213\n",
            "Epoch 9/12\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.2394 - accuracy: 0.9290\n",
            "Epoch 10/12\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.2206 - accuracy: 0.9334\n",
            "Epoch 11/12\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2077 - accuracy: 0.9369\n",
            "Epoch 12/12\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1948 - accuracy: 0.9422\n",
            "375/375 [==============================] - 1s 1ms/step - loss: 0.1837 - accuracy: 0.9458\n",
            "Epoch 1/12\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 2.1488 - accuracy: 0.3018\n",
            "Epoch 2/12\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 1.2794 - accuracy: 0.7127\n",
            "Epoch 3/12\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.7738 - accuracy: 0.8134\n",
            "Epoch 4/12\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.5379 - accuracy: 0.8599\n",
            "Epoch 5/12\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.4214 - accuracy: 0.8827\n",
            "Epoch 6/12\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.3516 - accuracy: 0.8995\n",
            "Epoch 7/12\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.2968 - accuracy: 0.9151\n",
            "Epoch 8/12\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.2629 - accuracy: 0.9239\n",
            "Epoch 9/12\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.2383 - accuracy: 0.9296\n",
            "Epoch 10/12\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2142 - accuracy: 0.9374\n",
            "Epoch 11/12\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2010 - accuracy: 0.9415\n",
            "Epoch 12/12\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1927 - accuracy: 0.9426\n",
            "375/375 [==============================] - 1s 1ms/step - loss: 0.1843 - accuracy: 0.9411\n",
            "Epoch 1/12\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 2.1228 - accuracy: 0.3132\n",
            "Epoch 2/12\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 1.1690 - accuracy: 0.7385\n",
            "Epoch 3/12\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.6901 - accuracy: 0.8285\n",
            "Epoch 4/12\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.4851 - accuracy: 0.8701\n",
            "Epoch 5/12\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.3876 - accuracy: 0.8923\n",
            "Epoch 6/12\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3237 - accuracy: 0.9091\n",
            "Epoch 7/12\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2757 - accuracy: 0.9202\n",
            "Epoch 8/12\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.2455 - accuracy: 0.9256\n",
            "Epoch 9/12\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2245 - accuracy: 0.9333\n",
            "Epoch 10/12\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2033 - accuracy: 0.9402\n",
            "Epoch 11/12\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1971 - accuracy: 0.9401\n",
            "Epoch 12/12\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1815 - accuracy: 0.9453\n",
            "375/375 [==============================] - 1s 1ms/step - loss: 0.1870 - accuracy: 0.9417\n",
            "Epoch 1/12\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 2.1510 - accuracy: 0.3208\n",
            "Epoch 2/12\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 1.2808 - accuracy: 0.7067\n",
            "Epoch 3/12\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.7730 - accuracy: 0.8146\n",
            "Epoch 4/12\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.5374 - accuracy: 0.8587\n",
            "Epoch 5/12\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.4141 - accuracy: 0.8876\n",
            "Epoch 6/12\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3420 - accuracy: 0.9022\n",
            "Epoch 7/12\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2896 - accuracy: 0.9181\n",
            "Epoch 8/12\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.2544 - accuracy: 0.9240\n",
            "Epoch 9/12\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.2327 - accuracy: 0.9300\n",
            "Epoch 10/12\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.2107 - accuracy: 0.9368\n",
            "Epoch 11/12\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.2019 - accuracy: 0.9383\n",
            "Epoch 12/12\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1882 - accuracy: 0.9433\n",
            "375/375 [==============================] - 1s 1ms/step - loss: 0.1928 - accuracy: 0.9407\n",
            "Epoch 1/12\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 2.1513 - accuracy: 0.2694\n",
            "Epoch 2/12\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 1.2998 - accuracy: 0.6882\n",
            "Epoch 3/12\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.8060 - accuracy: 0.8071\n",
            "Epoch 4/12\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.5619 - accuracy: 0.8517\n",
            "Epoch 5/12\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.4338 - accuracy: 0.8822\n",
            "Epoch 6/12\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3613 - accuracy: 0.8976\n",
            "Epoch 7/12\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3072 - accuracy: 0.9138\n",
            "Epoch 8/12\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.2726 - accuracy: 0.9196\n",
            "Epoch 9/12\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2455 - accuracy: 0.9276\n",
            "Epoch 10/12\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2218 - accuracy: 0.9325\n",
            "Epoch 11/12\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2032 - accuracy: 0.9387\n",
            "Epoch 12/12\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.2026 - accuracy: 0.9384\n",
            "375/375 [==============================] - 1s 1ms/step - loss: 0.1836 - accuracy: 0.9475\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 2.2235 - accuracy: 0.2474\n",
            "188/188 [==============================] - 0s 1ms/step - loss: 1.7638 - accuracy: 0.6271\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 2.2256 - accuracy: 0.2062\n",
            "188/188 [==============================] - 0s 1ms/step - loss: 1.7686 - accuracy: 0.6193\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 2.2294 - accuracy: 0.2220\n",
            "188/188 [==============================] - 0s 1ms/step - loss: 1.7834 - accuracy: 0.5336\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 2.2289 - accuracy: 0.2267\n",
            "188/188 [==============================] - 0s 1ms/step - loss: 1.7793 - accuracy: 0.5264\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 2.2309 - accuracy: 0.2181\n",
            "188/188 [==============================] - 0s 1ms/step - loss: 1.8020 - accuracy: 0.5473\n",
            "Epoch 1/6\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 2.2298 - accuracy: 0.2241\n",
            "Epoch 2/6\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 1.6352 - accuracy: 0.6065\n",
            "Epoch 3/6\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 1.1754 - accuracy: 0.7395\n",
            "Epoch 4/6\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.8509 - accuracy: 0.8034\n",
            "Epoch 5/6\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.6428 - accuracy: 0.8402\n",
            "Epoch 6/6\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.5117 - accuracy: 0.8666\n",
            "188/188 [==============================] - 0s 1ms/step - loss: 0.4463 - accuracy: 0.8831\n",
            "Epoch 1/6\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 2.2253 - accuracy: 0.2480\n",
            "Epoch 2/6\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 1.6117 - accuracy: 0.6181\n",
            "Epoch 3/6\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 1.1213 - accuracy: 0.7499\n",
            "Epoch 4/6\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.7952 - accuracy: 0.8145\n",
            "Epoch 5/6\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.5931 - accuracy: 0.8500\n",
            "Epoch 6/6\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.4810 - accuracy: 0.8736\n",
            "188/188 [==============================] - 1s 1ms/step - loss: 0.4147 - accuracy: 0.8879\n",
            "Epoch 1/6\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 2.2220 - accuracy: 0.2379\n",
            "Epoch 2/6\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 1.5849 - accuracy: 0.6369\n",
            "Epoch 3/6\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 1.0771 - accuracy: 0.7667\n",
            "Epoch 4/6\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.7528 - accuracy: 0.8228\n",
            "Epoch 5/6\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.5705 - accuracy: 0.8543\n",
            "Epoch 6/6\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.4627 - accuracy: 0.8775\n",
            "188/188 [==============================] - 0s 1ms/step - loss: 0.4188 - accuracy: 0.8818\n",
            "Epoch 1/6\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 2.2252 - accuracy: 0.2265\n",
            "Epoch 2/6\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 1.6037 - accuracy: 0.6161\n",
            "Epoch 3/6\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 1.1135 - accuracy: 0.7525\n",
            "Epoch 4/6\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.7927 - accuracy: 0.8171\n",
            "Epoch 5/6\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.5946 - accuracy: 0.8506\n",
            "Epoch 6/6\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.4780 - accuracy: 0.8747\n",
            "188/188 [==============================] - 0s 1ms/step - loss: 0.4321 - accuracy: 0.8847\n",
            "Epoch 1/6\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 2.2183 - accuracy: 0.2636\n",
            "Epoch 2/6\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 1.5659 - accuracy: 0.6191\n",
            "Epoch 3/6\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 1.0701 - accuracy: 0.7589\n",
            "Epoch 4/6\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.7628 - accuracy: 0.8152\n",
            "Epoch 5/6\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.5758 - accuracy: 0.8521\n",
            "Epoch 6/6\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.4666 - accuracy: 0.8759\n",
            "188/188 [==============================] - 0s 1ms/step - loss: 0.4003 - accuracy: 0.8960\n",
            "Epoch 1/12\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 2.2291 - accuracy: 0.2070\n",
            "Epoch 2/12\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 1.6466 - accuracy: 0.6128\n",
            "Epoch 3/12\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 1.1685 - accuracy: 0.7364\n",
            "Epoch 4/12\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.8549 - accuracy: 0.8014\n",
            "Epoch 5/12\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.6428 - accuracy: 0.8380\n",
            "Epoch 6/12\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.5163 - accuracy: 0.8656\n",
            "Epoch 7/12\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.4355 - accuracy: 0.8816\n",
            "Epoch 8/12\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3831 - accuracy: 0.8937\n",
            "Epoch 9/12\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3357 - accuracy: 0.9046\n",
            "Epoch 10/12\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3024 - accuracy: 0.9149\n",
            "Epoch 11/12\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.2817 - accuracy: 0.9183\n",
            "Epoch 12/12\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.2518 - accuracy: 0.9269\n",
            "188/188 [==============================] - 0s 1ms/step - loss: 0.2402 - accuracy: 0.9284\n",
            "Epoch 1/12\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 2.2239 - accuracy: 0.2574\n",
            "Epoch 2/12\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 1.5889 - accuracy: 0.6308\n",
            "Epoch 3/12\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 1.0916 - accuracy: 0.7594\n",
            "Epoch 4/12\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.7767 - accuracy: 0.8177\n",
            "Epoch 5/12\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.5795 - accuracy: 0.8544\n",
            "Epoch 6/12\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.4695 - accuracy: 0.8762\n",
            "Epoch 7/12\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.4000 - accuracy: 0.8916\n",
            "Epoch 8/12\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3457 - accuracy: 0.9057\n",
            "Epoch 9/12\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3060 - accuracy: 0.9150\n",
            "Epoch 10/12\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.2772 - accuracy: 0.9205\n",
            "Epoch 11/12\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.2535 - accuracy: 0.9283\n",
            "Epoch 12/12\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.2379 - accuracy: 0.9315\n",
            "188/188 [==============================] - 0s 1ms/step - loss: 0.2220 - accuracy: 0.9315\n",
            "Epoch 1/12\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 2.2304 - accuracy: 0.2236\n",
            "Epoch 2/12\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 1.6304 - accuracy: 0.6397\n",
            "Epoch 3/12\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 1.1438 - accuracy: 0.7475\n",
            "Epoch 4/12\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.8178 - accuracy: 0.8075\n",
            "Epoch 5/12\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.6140 - accuracy: 0.8481\n",
            "Epoch 6/12\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.4949 - accuracy: 0.8692\n",
            "Epoch 7/12\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.4225 - accuracy: 0.8846\n",
            "Epoch 8/12\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3615 - accuracy: 0.9003\n",
            "Epoch 9/12\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.3221 - accuracy: 0.9104\n",
            "Epoch 10/12\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.2878 - accuracy: 0.9198\n",
            "Epoch 11/12\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.2637 - accuracy: 0.9233\n",
            "Epoch 12/12\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.2409 - accuracy: 0.9310\n",
            "188/188 [==============================] - 0s 1ms/step - loss: 0.2494 - accuracy: 0.9247\n",
            "Epoch 1/12\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 2.2257 - accuracy: 0.2245\n",
            "Epoch 2/12\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 1.6120 - accuracy: 0.6267\n",
            "Epoch 3/12\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 1.1215 - accuracy: 0.7524\n",
            "Epoch 4/12\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.7969 - accuracy: 0.8102\n",
            "Epoch 5/12\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.6004 - accuracy: 0.8535\n",
            "Epoch 6/12\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.4829 - accuracy: 0.8746\n",
            "Epoch 7/12\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.4102 - accuracy: 0.8894\n",
            "Epoch 8/12\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3501 - accuracy: 0.9045\n",
            "Epoch 9/12\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.3124 - accuracy: 0.9119\n",
            "Epoch 10/12\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.2829 - accuracy: 0.9170\n",
            "Epoch 11/12\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.2577 - accuracy: 0.9245\n",
            "Epoch 12/12\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.2394 - accuracy: 0.9299\n",
            "188/188 [==============================] - 0s 1ms/step - loss: 0.2360 - accuracy: 0.9298\n",
            "Epoch 1/12\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 2.2254 - accuracy: 0.2204\n",
            "Epoch 2/12\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 1.6159 - accuracy: 0.6168\n",
            "Epoch 3/12\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 1.1276 - accuracy: 0.7496\n",
            "Epoch 4/12\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.8032 - accuracy: 0.8094\n",
            "Epoch 5/12\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.6038 - accuracy: 0.8473\n",
            "Epoch 6/12\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.4907 - accuracy: 0.8689\n",
            "Epoch 7/12\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.4131 - accuracy: 0.8854\n",
            "Epoch 8/12\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.3586 - accuracy: 0.9005\n",
            "Epoch 9/12\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.3198 - accuracy: 0.9101\n",
            "Epoch 10/12\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.2908 - accuracy: 0.9166\n",
            "Epoch 11/12\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.2613 - accuracy: 0.9250\n",
            "Epoch 12/12\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.2433 - accuracy: 0.9294\n",
            "188/188 [==============================] - 0s 1ms/step - loss: 0.2183 - accuracy: 0.9388\n",
            "375/375 [==============================] - 2s 3ms/step - loss: 2.2690 - accuracy: 0.1886\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 2.0560 - accuracy: 0.3494\n",
            "375/375 [==============================] - 2s 3ms/step - loss: 2.2703 - accuracy: 0.1704\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 2.0584 - accuracy: 0.3781\n",
            "375/375 [==============================] - 2s 3ms/step - loss: 2.2729 - accuracy: 0.1590\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 2.0852 - accuracy: 0.5011\n",
            "375/375 [==============================] - 2s 3ms/step - loss: 2.2666 - accuracy: 0.2048\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 2.0444 - accuracy: 0.4514\n",
            "375/375 [==============================] - 2s 3ms/step - loss: 2.2707 - accuracy: 0.1660\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 2.0776 - accuracy: 0.4177\n",
            "Epoch 1/6\n",
            "375/375 [==============================] - 2s 3ms/step - loss: 2.2689 - accuracy: 0.2103\n",
            "Epoch 2/6\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.9446 - accuracy: 0.4766\n",
            "Epoch 3/6\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.5426 - accuracy: 0.6413\n",
            "Epoch 4/6\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.2348 - accuracy: 0.7302\n",
            "Epoch 5/6\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.9905 - accuracy: 0.7821\n",
            "Epoch 6/6\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.7947 - accuracy: 0.8134\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6741 - accuracy: 0.8353\n",
            "Epoch 1/6\n",
            "375/375 [==============================] - 2s 3ms/step - loss: 2.2680 - accuracy: 0.1925\n",
            "Epoch 2/6\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.9315 - accuracy: 0.4944\n",
            "Epoch 3/6\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.5137 - accuracy: 0.6550\n",
            "Epoch 4/6\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.2127 - accuracy: 0.7377\n",
            "Epoch 5/6\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.9630 - accuracy: 0.7833\n",
            "Epoch 6/6\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.7731 - accuracy: 0.8202\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6582 - accuracy: 0.8406\n",
            "Epoch 1/6\n",
            "375/375 [==============================] - 2s 3ms/step - loss: 2.2695 - accuracy: 0.1817\n",
            "Epoch 2/6\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.9501 - accuracy: 0.5061\n",
            "Epoch 3/6\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.5519 - accuracy: 0.6496\n",
            "Epoch 4/6\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.2361 - accuracy: 0.7247\n",
            "Epoch 5/6\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.9947 - accuracy: 0.7778\n",
            "Epoch 6/6\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.8025 - accuracy: 0.8078\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.7001 - accuracy: 0.8208\n",
            "Epoch 1/6\n",
            "375/375 [==============================] - 2s 3ms/step - loss: 2.2670 - accuracy: 0.1634\n",
            "Epoch 2/6\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.9353 - accuracy: 0.4868\n",
            "Epoch 3/6\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.5259 - accuracy: 0.6535\n",
            "Epoch 4/6\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.2263 - accuracy: 0.7291\n",
            "Epoch 5/6\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.9783 - accuracy: 0.7827\n",
            "Epoch 6/6\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.7879 - accuracy: 0.8150\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6891 - accuracy: 0.8330\n",
            "Epoch 1/6\n",
            "375/375 [==============================] - 2s 3ms/step - loss: 2.2692 - accuracy: 0.1588\n",
            "Epoch 2/6\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.9491 - accuracy: 0.4953\n",
            "Epoch 3/6\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.5514 - accuracy: 0.6398\n",
            "Epoch 4/6\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.2477 - accuracy: 0.7182\n",
            "Epoch 5/6\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.0055 - accuracy: 0.7697\n",
            "Epoch 6/6\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.8150 - accuracy: 0.8071\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.8411\n",
            "Epoch 1/12\n",
            "375/375 [==============================] - 2s 3ms/step - loss: 2.2651 - accuracy: 0.1869\n",
            "Epoch 2/12\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.9255 - accuracy: 0.4997\n",
            "Epoch 3/12\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.5173 - accuracy: 0.6636\n",
            "Epoch 4/12\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.1989 - accuracy: 0.7376\n",
            "Epoch 5/12\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.9479 - accuracy: 0.7862\n",
            "Epoch 6/12\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.7662 - accuracy: 0.8182\n",
            "Epoch 7/12\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.6303 - accuracy: 0.8439\n",
            "Epoch 8/12\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.5395 - accuracy: 0.8612\n",
            "Epoch 9/12\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4702 - accuracy: 0.8743\n",
            "Epoch 10/12\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4181 - accuracy: 0.8868\n",
            "Epoch 11/12\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3696 - accuracy: 0.8984\n",
            "Epoch 12/12\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3353 - accuracy: 0.9069\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.3106 - accuracy: 0.9159\n",
            "Epoch 1/12\n",
            "375/375 [==============================] - 2s 3ms/step - loss: 2.2658 - accuracy: 0.1714\n",
            "Epoch 2/12\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.9204 - accuracy: 0.4999\n",
            "Epoch 3/12\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.5079 - accuracy: 0.6628\n",
            "Epoch 4/12\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.1919 - accuracy: 0.7440\n",
            "Epoch 5/12\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.9445 - accuracy: 0.7875\n",
            "Epoch 6/12\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.7513 - accuracy: 0.8218\n",
            "Epoch 7/12\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.6214 - accuracy: 0.8445\n",
            "Epoch 8/12\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.5241 - accuracy: 0.8635\n",
            "Epoch 9/12\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4655 - accuracy: 0.8767\n",
            "Epoch 10/12\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4053 - accuracy: 0.8909\n",
            "Epoch 11/12\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3689 - accuracy: 0.8986\n",
            "Epoch 12/12\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3304 - accuracy: 0.9092\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.3078 - accuracy: 0.9118\n",
            "Epoch 1/12\n",
            "375/375 [==============================] - 2s 3ms/step - loss: 2.2705 - accuracy: 0.1715\n",
            "Epoch 2/12\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.9740 - accuracy: 0.4582\n",
            "Epoch 3/12\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.5843 - accuracy: 0.6348\n",
            "Epoch 4/12\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.2778 - accuracy: 0.7172\n",
            "Epoch 5/12\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.0439 - accuracy: 0.7677\n",
            "Epoch 6/12\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.8429 - accuracy: 0.8053\n",
            "Epoch 7/12\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.7010 - accuracy: 0.8294\n",
            "Epoch 8/12\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.5876 - accuracy: 0.8520\n",
            "Epoch 9/12\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.5041 - accuracy: 0.8704\n",
            "Epoch 10/12\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4480 - accuracy: 0.8814\n",
            "Epoch 11/12\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3993 - accuracy: 0.8940\n",
            "Epoch 12/12\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3630 - accuracy: 0.9028\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.3493 - accuracy: 0.9021\n",
            "Epoch 1/12\n",
            "375/375 [==============================] - 2s 3ms/step - loss: 2.2689 - accuracy: 0.1719\n",
            "Epoch 2/12\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.9512 - accuracy: 0.4658\n",
            "Epoch 3/12\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.5469 - accuracy: 0.6386\n",
            "Epoch 4/12\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.2371 - accuracy: 0.7307\n",
            "Epoch 5/12\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.0025 - accuracy: 0.7770\n",
            "Epoch 6/12\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.8025 - accuracy: 0.8161\n",
            "Epoch 7/12\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.6658 - accuracy: 0.8397\n",
            "Epoch 8/12\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.5568 - accuracy: 0.8616\n",
            "Epoch 9/12\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4830 - accuracy: 0.8742\n",
            "Epoch 10/12\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4211 - accuracy: 0.8905\n",
            "Epoch 11/12\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3771 - accuracy: 0.8987\n",
            "Epoch 12/12\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3444 - accuracy: 0.9055\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.3356 - accuracy: 0.9092\n",
            "Epoch 1/12\n",
            "375/375 [==============================] - 2s 3ms/step - loss: 2.2704 - accuracy: 0.1678\n",
            "Epoch 2/12\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.9711 - accuracy: 0.4982\n",
            "Epoch 3/12\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.5835 - accuracy: 0.6342\n",
            "Epoch 4/12\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.2814 - accuracy: 0.7068\n",
            "Epoch 5/12\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.0419 - accuracy: 0.7635\n",
            "Epoch 6/12\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.8504 - accuracy: 0.7973\n",
            "Epoch 7/12\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.7027 - accuracy: 0.8268\n",
            "Epoch 8/12\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.5980 - accuracy: 0.8469\n",
            "Epoch 9/12\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.5149 - accuracy: 0.8668\n",
            "Epoch 10/12\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4599 - accuracy: 0.8752\n",
            "Epoch 11/12\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4091 - accuracy: 0.8886\n",
            "Epoch 12/12\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3713 - accuracy: 0.8974\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.3394 - accuracy: 0.9082\n",
            "Epoch 1/12\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 2.0583 - accuracy: 0.3509\n",
            "Epoch 2/12\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 1.0095 - accuracy: 0.7695\n",
            "Epoch 3/12\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.5739 - accuracy: 0.8515\n",
            "Epoch 4/12\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4105 - accuracy: 0.8863\n",
            "Epoch 5/12\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3275 - accuracy: 0.9062\n",
            "Epoch 6/12\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2710 - accuracy: 0.9217\n",
            "Epoch 7/12\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2341 - accuracy: 0.9310\n",
            "Epoch 8/12\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2125 - accuracy: 0.9363\n",
            "Epoch 9/12\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1990 - accuracy: 0.9399\n",
            "Epoch 10/12\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1824 - accuracy: 0.9439\n",
            "Epoch 11/12\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1717 - accuracy: 0.9465\n",
            "Epoch 12/12\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1648 - accuracy: 0.9492\n",
            "Chosing Neural Network params for deskewed data:  {'batch_size': 32, 'epochs': 12}\n",
            "Chosing Neural Network params for non-deskewed data:  {'batch_size': 32, 'epochs': 12}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NN Accuracy for deskewed data: 0.9516\n",
            "NN Accuracy for non-deskewed data: 0.9362\n",
            "\n",
            "\n",
            "NN Confusion matrix for deskewed images:\n",
            "[[ 954    1    3    0    2    3    9    1    1    6]\n",
            " [   2 1117    2    0    6    0    4    2    2    0]\n",
            " [   0    2  987    2    3    0    2   20   15    1]\n",
            " [   0    1   18  951    1    9    0   12   15    3]\n",
            " [   2    1    1    0  967    1    8    0    0    2]\n",
            " [   4    0    1    3    6  841    4    1   22   10]\n",
            " [   6    3    0    0   13    3  930    0    3    0]\n",
            " [   8    4   45   20    5    0    0  922    7   17]\n",
            " [   1    0    3    7   12    2    6    4  924   15]\n",
            " [   9    1    3    1   12    7    8    9   36  923]]\n",
            "NN Classification report for deskewed images:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.97      0.97       980\n",
            "           1       0.99      0.98      0.99      1135\n",
            "           2       0.93      0.96      0.94      1032\n",
            "           3       0.97      0.94      0.95      1010\n",
            "           4       0.94      0.98      0.96       982\n",
            "           5       0.97      0.94      0.96       892\n",
            "           6       0.96      0.97      0.96       958\n",
            "           7       0.95      0.90      0.92      1028\n",
            "           8       0.90      0.95      0.92       974\n",
            "           9       0.94      0.91      0.93      1009\n",
            "\n",
            "    accuracy                           0.95     10000\n",
            "   macro avg       0.95      0.95      0.95     10000\n",
            "weighted avg       0.95      0.95      0.95     10000\n",
            "\n",
            "\n",
            "\n",
            "NN Confusion matrix for non-deskewed images:\n",
            "[[ 953    2    5    0    3    5    8    2    1    1]\n",
            " [   0 1122    3    0    4    0    1    2    2    1]\n",
            " [   6    4  970    4    0    1    0   38    8    1]\n",
            " [   1    1   22  939    0   15    0   20    9    3]\n",
            " [   7    3    1    0  944    1   16    0    1    9]\n",
            " [   7    2    0    8    1  815    2    2   42   13]\n",
            " [  21    4    0    0   14    5  908    0    5    1]\n",
            " [   7    5   59   15    1    1    0  923    6   11]\n",
            " [   9    4   13    7    8   10    8    7  878   30]\n",
            " [  28    3    0    3    4   12    2   18   29  910]]\n",
            "NN Classification report for non-deskewed images:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.97      0.94       980\n",
            "           1       0.98      0.99      0.98      1135\n",
            "           2       0.90      0.94      0.92      1032\n",
            "           3       0.96      0.93      0.95      1010\n",
            "           4       0.96      0.96      0.96       982\n",
            "           5       0.94      0.91      0.93       892\n",
            "           6       0.96      0.95      0.95       958\n",
            "           7       0.91      0.90      0.90      1028\n",
            "           8       0.90      0.90      0.90       974\n",
            "           9       0.93      0.90      0.92      1009\n",
            "\n",
            "    accuracy                           0.94     10000\n",
            "   macro avg       0.94      0.94      0.94     10000\n",
            "weighted avg       0.94      0.94      0.94     10000\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7QGxKEBzEBm"
      },
      "source": [
        "Na podstawie powyższych rezultatów można zauważyc, że Sieć neuronowa działa lepiej dla obrazów z wyrównaniem. \n",
        "\n",
        "*   Accuracy dla obrazów z wyrównaniem: 0.9516\n",
        "*   Accuracy dla obrazów bez wyrównania: 0.9362\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZL9fohZzcW4"
      },
      "source": [
        "Po porównaniu obu scenariuszy z treści zadania, możemy stwierdzić, że wyrównanie obrazów za pomocą funkcji *deskew* przed zastosowaniem deskryptora HOG zwiększa wydajność każdego z testowanych modeli. Dzięki zastosowaniu funkcji *deskew* elementy treningowe były do siebie zbliżone, więc klasyfikator był w stanie łatwiej znaleźć wspólne cechy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RyKgr75TNho"
      },
      "source": [
        "# **Zadanie 3**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-AZ4FzbM11Sz"
      },
      "source": [
        "Porównanie wyników działania klasyfikatorów dla poniższych przypadków:\n",
        "\n",
        "1.   Obrazy oryginalne -> Deskew -> HOG -> Klasyfikator (SVM, Las losowy, Sieć)\n",
        "2.   Obrazy oryginalne -> Deskew -> ReshapeTo1D -> Klasyfikator (SVM, Las losowy, Sieć)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkDlva2_2Mti"
      },
      "source": [
        "**SVM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yeeLr8LKTYFA",
        "outputId": "315371bf-6127-4d4c-de59-5786961e7872"
      },
      "source": [
        "parameters = {'kernel':('linear', 'rbf'), 'C': np.linspace(start = 0.001, stop = 2, num = 200)}\n",
        "\n",
        "hog_model = GridSearchCV(svm.SVC(), parameters, scoring='accuracy', cv=5)\n",
        "hog_model.fit(hogdata_train_deskewed[:300], train_labels[:300])\n",
        "hog_params = hog_model.best_params_\n",
        "print(\"Chosing SVM params with HOG data: \", hog_params, '\\n')\n",
        "\n",
        "reshape_train = train_images[:300].reshape(len(train_images[:300]), 28*28)\n",
        "reshape_train = reshape_train.astype('float32')/255\n",
        "\n",
        "reshape_test = test_images[:300].reshape(len(test_images[:300]), 28*28)\n",
        "reshape_test = reshape_test.astype('float32')/255\n",
        "\n",
        "reshape_model = GridSearchCV(svm.SVC(), parameters, scoring='accuracy', cv=5)\n",
        "reshape_model.fit(reshape_train, train_labels[:300])\n",
        "reshape_params = reshape_model.best_params_\n",
        "print(\"Chosing SVM params without HOG data: \", reshape_params, '\\n')\n",
        "\n",
        "pred_labels_HOG = hog_model.predict(hogdata_test_deskewed[:300])\n",
        "pred_labels = reshape_model.predict(reshape_test)\n",
        "\n",
        "print(\"SVM Accuracy with HOG images: {}\".format(accuracy_score(test_labels[:300], pred_labels_HOG)))\n",
        "print(\"SVM Accuracy without HOG images: {}\\n\".format(accuracy_score(test_labels[:300], pred_labels)))\n",
        "\n",
        "print(\"SVM Confusion matrix with HOG images:\\n{}\".format(confusion_matrix(test_labels[:300], pred_labels_HOG)))\n",
        "print(\"SVM Classification report with HOG images:\\n{}\\n\\n\".format(classification_report(test_labels[:300], pred_labels_HOG)))\n",
        "\n",
        "print(\"SVM Confusion matrix without HOG images:\\n{}\".format(confusion_matrix(test_labels[:300], pred_labels)))\n",
        "print(\"SVM Classification report without HOG images:\\n{}\\n\\n\".format(classification_report(test_labels[:300], pred_labels)))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Chosing SVM params with HOG data:  {'C': 0.5635326633165829, 'kernel': 'linear'} \n",
            "\n",
            "Chosing SVM params without HOG data:  {'C': 1.7086884422110553, 'kernel': 'rbf'} \n",
            "\n",
            "SVM Accuracy with HOG images: 0.9033333333333333\n",
            "SVM Accuracy without HOG images: 0.81\n",
            "\n",
            "SVM Confusion matrix with HOG images:\n",
            "[[24  0  0  0  0  0  0  0  0  0]\n",
            " [ 0 41  0  0  0  0  0  0  0  0]\n",
            " [ 0  1 30  0  0  0  0  0  0  1]\n",
            " [ 0  0  1 22  0  0  0  0  1  0]\n",
            " [ 0  0  0  0 34  0  3  0  0  0]\n",
            " [ 0  0  0  0  0 27  0  0  0  2]\n",
            " [ 0  0  0  0  0  0 24  0  0  0]\n",
            " [ 0  1  6  2  0  0  0 24  0  1]\n",
            " [ 0  1  0  1  1  0  0  0 13  5]\n",
            " [ 0  0  0  0  0  0  1  0  1 32]]\n",
            "SVM Classification report with HOG images:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        24\n",
            "           1       0.93      1.00      0.96        41\n",
            "           2       0.81      0.94      0.87        32\n",
            "           3       0.88      0.92      0.90        24\n",
            "           4       0.97      0.92      0.94        37\n",
            "           5       1.00      0.93      0.96        29\n",
            "           6       0.86      1.00      0.92        24\n",
            "           7       1.00      0.71      0.83        34\n",
            "           8       0.87      0.62      0.72        21\n",
            "           9       0.78      0.94      0.85        34\n",
            "\n",
            "    accuracy                           0.90       300\n",
            "   macro avg       0.91      0.90      0.90       300\n",
            "weighted avg       0.91      0.90      0.90       300\n",
            "\n",
            "\n",
            "\n",
            "SVM Confusion matrix without HOG images:\n",
            "[[23  0  1  0  0  0  0  0  0  0]\n",
            " [ 0 41  0  0  0  0  0  0  0  0]\n",
            " [ 0  2 26  0  1  1  0  2  0  0]\n",
            " [ 0  1  1 19  0  3  0  0  0  0]\n",
            " [ 0  0  1  0 31  0  0  0  0  5]\n",
            " [ 0  1  1  6  1 18  0  2  0  0]\n",
            " [ 1  0  4  0  1  1 17  0  0  0]\n",
            " [ 0  1  2  0  1  0  0 28  0  2]\n",
            " [ 1  1  1  1  1  0  0  1 15  0]\n",
            " [ 0  0  1  2  4  0  0  1  1 25]]\n",
            "SVM Classification report without HOG images:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.96      0.94        24\n",
            "           1       0.87      1.00      0.93        41\n",
            "           2       0.68      0.81      0.74        32\n",
            "           3       0.68      0.79      0.73        24\n",
            "           4       0.78      0.84      0.81        37\n",
            "           5       0.78      0.62      0.69        29\n",
            "           6       1.00      0.71      0.83        24\n",
            "           7       0.82      0.82      0.82        34\n",
            "           8       0.94      0.71      0.81        21\n",
            "           9       0.78      0.74      0.76        34\n",
            "\n",
            "    accuracy                           0.81       300\n",
            "   macro avg       0.83      0.80      0.81       300\n",
            "weighted avg       0.82      0.81      0.81       300\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47dyd7bn2Y_e"
      },
      "source": [
        "Na podstawie powyższych rezultatów można zauważyć, że klasyfikator SVM działa lepiej dla obrazów z wykorzystaniem deskryptora HOG.\n",
        "\n",
        "*   Accuracy dla obrazów z wykorzystaniem deskryptora HOG: 0.9033\n",
        "*   Accuracy dla obrazów bez wykorzystania deskryptora HOG: 0.81\n",
        "    \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNly37dh28Df"
      },
      "source": [
        "**Las losowy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5ly3-g329gq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e8ef091-20d9-49ca-92e7-a544afa8bfb4"
      },
      "source": [
        "parameters_for_cross_validation = {'max_depth':[5, 10, 15], 'n_estimators': [80,100,120], 'max_features': [30, 45, 60]}\n",
        "hog_model = GridSearchCV(RandomForestClassifier(), parameters_for_cross_validation, cv=5, scoring='accuracy')\n",
        "hog_model.fit(hogdata_train_deskewed[:300], train_labels[:300])\n",
        "hog_params = hog_model.best_params_\n",
        "print(\"Chosing RandomForestClassifier params with HOG data: \", hog_params, '\\n')\n",
        "\n",
        "reshape_train = train_images[:300].reshape(len(train_images[:300]), 28*28)\n",
        "reshape_train = reshape_train.astype('float32')/255\n",
        "\n",
        "reshape_test = test_images[:300].reshape(len(test_images[:300]), 28*28)\n",
        "reshape_test = reshape_test.astype('float32')/255\n",
        "\n",
        "reshape_model = GridSearchCV(RandomForestClassifier(), parameters_for_cross_validation, cv=5, scoring='accuracy')\n",
        "reshape_model.fit(reshape_train, train_labels[:300])\n",
        "params = reshape_model.best_params_\n",
        "print(\"Chosing RandomForestClassifier params without HOG data: \", params, '\\n')\n",
        "\n",
        "pred_labels_HOG = hog_model.predict(hogdata_test_deskewed[:300])\n",
        "pred_labels = reshape_model.predict(reshape_test)\n",
        "\n",
        "print(\"RFC Accuracy with HOG images: {}\".format(accuracy_score(test_labels[:300], pred_labels_HOG)))\n",
        "print(\"RFC Accuracy without HOG images: {}\\n\".format(accuracy_score(test_labels[:300], pred_labels)))\n",
        "\n",
        "print(\"RFC Confusion matrix with HOG images:\\n{}\".format(confusion_matrix(test_labels[:300], pred_labels_HOG)))\n",
        "print(\"RFC Classification report with HOG images:\\n{}\\n\\n\".format(classification_report(test_labels[:300], pred_labels_HOG)))\n",
        "\n",
        "print(\"RFC Confusion matrix without HOG images:\\n{}\".format(confusion_matrix(test_labels[:300], pred_labels)))\n",
        "print(\"RFC Classification report without HOG images:\\n{}\\n\\n\".format(classification_report(test_labels[:300], pred_labels)))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Chosing RandomForestClassifier params with HOG data:  {'max_depth': 10, 'max_features': 30, 'n_estimators': 80} \n",
            "\n",
            "Chosing RandomForestClassifier params without HOG data:  {'max_depth': 15, 'max_features': 45, 'n_estimators': 100} \n",
            "\n",
            "RFC Accuracy with HOG images: 0.9066666666666666\n",
            "RFC Accuracy without HOG images: 0.6633333333333333\n",
            "\n",
            "RFC Confusion matrix with HOG images:\n",
            "[[24  0  0  0  0  0  0  0  0  0]\n",
            " [ 0 41  0  0  0  0  0  0  0  0]\n",
            " [ 0  2 29  1  0  0  0  0  0  0]\n",
            " [ 0  0  1 23  0  0  0  0  0  0]\n",
            " [ 0  0  0  0 36  0  1  0  0  0]\n",
            " [ 1  0  0  0  0 27  0  0  0  1]\n",
            " [ 1  0  0  0  0  0 23  0  0  0]\n",
            " [ 0  0  2  4  0  0  0 27  0  1]\n",
            " [ 0  1  0  1  1  1  0  0 14  3]\n",
            " [ 2  0  0  0  2  0  1  0  1 28]]\n",
            "RFC Classification report with HOG images:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      1.00      0.92        24\n",
            "           1       0.93      1.00      0.96        41\n",
            "           2       0.91      0.91      0.91        32\n",
            "           3       0.79      0.96      0.87        24\n",
            "           4       0.92      0.97      0.95        37\n",
            "           5       0.96      0.93      0.95        29\n",
            "           6       0.92      0.96      0.94        24\n",
            "           7       1.00      0.79      0.89        34\n",
            "           8       0.93      0.67      0.78        21\n",
            "           9       0.85      0.82      0.84        34\n",
            "\n",
            "    accuracy                           0.91       300\n",
            "   macro avg       0.91      0.90      0.90       300\n",
            "weighted avg       0.91      0.91      0.90       300\n",
            "\n",
            "\n",
            "\n",
            "RFC Confusion matrix without HOG images:\n",
            "[[24  0  0  0  0  0  0  0  0  0]\n",
            " [ 0 41  0  0  0  0  0  0  0  0]\n",
            " [ 3  2 20  0  0  0  2  3  2  0]\n",
            " [ 1  2  1 15  0  2  1  1  0  1]\n",
            " [ 0  0  0  0 25  0  3  1  0  8]\n",
            " [ 0  1  0 13  3  6  0  1  0  5]\n",
            " [ 2  0  3  0  3  1 14  0  0  1]\n",
            " [ 0  2  1  1  2  0  0 25  0  3]\n",
            " [ 2  1  1  1  2  0  3  0  9  2]\n",
            " [ 0  0  0  3  8  0  0  2  1 20]]\n",
            "RFC Classification report without HOG images:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      1.00      0.86        24\n",
            "           1       0.84      1.00      0.91        41\n",
            "           2       0.77      0.62      0.69        32\n",
            "           3       0.45      0.62      0.53        24\n",
            "           4       0.58      0.68      0.63        37\n",
            "           5       0.67      0.21      0.32        29\n",
            "           6       0.61      0.58      0.60        24\n",
            "           7       0.76      0.74      0.75        34\n",
            "           8       0.75      0.43      0.55        21\n",
            "           9       0.50      0.59      0.54        34\n",
            "\n",
            "    accuracy                           0.66       300\n",
            "   macro avg       0.67      0.65      0.64       300\n",
            "weighted avg       0.67      0.66      0.65       300\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l53tetDR2-NJ"
      },
      "source": [
        "Na podstawie powyższych rezultatów można zauważyć, że klasyfikator RFC działa lepiej dla obrazów z wykorzystaniem deskryptora HOG.\n",
        "\n",
        "*   Accuracy dla obrazów z wykorzystaniem deskryptora HOG: 0.9066\n",
        "*   Accuracy dla obrazów bez wykorzystania deskryptora HOG: 0.6633\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-H4Yb1C3B5y"
      },
      "source": [
        "**Sieć neuronowa**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_npJ5gN3CO9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7975b350-71f9-4f2a-d216-88d914cdf89c"
      },
      "source": [
        "reshape_train = train_images.reshape((60000, 28*28))\n",
        "reshape_train = reshape_train.astype('float32')/255\n",
        "\n",
        "reshape_test = test_images.reshape((10000, 28*28))\n",
        "reshape_test = reshape_test.astype('float32')/255\n",
        "\n",
        "nn_train_hog = np.array(hogdata_train_deskewed).reshape((60000, 81))\n",
        "nn_train_hog = nn_train_hog.astype('float32') / 255\n",
        "\n",
        "nn_test_hog = np.array(hogdata_test_deskewed).reshape((10000, 81))\n",
        "nn_test_hog = nn_test_hog.astype('float32') / 255\n",
        "\n",
        "\n",
        "encoded_train_labels = to_categorical(train_labels)\n",
        "encoded_test_labels = to_categorical(test_labels)\n",
        "\n",
        "parameters_for_cross_validation = {'epochs':[1,6,12], 'batch_size':[32,64,128]}\n",
        "hog_network = KerasClassifier(create_model)\n",
        "hog_model = GridSearchCV(estimator=hog_network, param_grid=parameters_for_cross_validation, cv=5)\n",
        "hog_model.fit(nn_train_hog, encoded_train_labels)\n",
        "deskew_params = hog_model.best_params_\n",
        "print(\"Chosing Neural Network params with HOG data: \", deskew_params)\n",
        "\n",
        "network = KerasClassifier(build_fn=create_model)\n",
        "reshape_model = GridSearchCV(estimator=network, param_grid=parameters_for_cross_validation, cv=5)\n",
        "reshape_model.fit(reshape_train, encoded_train_labels)\n",
        "params = reshape_model.best_params_\n",
        "print(\"Chosing Neural Network params without HOG data: \", params)\n",
        "\n",
        "\n",
        "pred_labels_HOG = hog_model.predict(nn_test_hog)\n",
        "pred_labels = reshape_model.predict(reshape_test)\n",
        "\n",
        "print(\"NN Accuracy with HOG images: {}\".format(accuracy_score(test_labels, pred_labels_HOG)))\n",
        "print(\"NN Accuracy without HOG images: {}\\n\".format(accuracy_score(test_labels, pred_labels)))\n",
        "\n",
        "print(\"NN Confusion matrix with HOG images:\\n{}\".format(confusion_matrix(test_labels, pred_labels_HOG)))\n",
        "print(\"NN Classification report with HOG images:\\n{}\\n\\n\".format(classification_report(test_labels, pred_labels_HOG)))\n",
        "\n",
        "print(\"NN Confusion matrix without HOG images:\\n{}\".format(confusion_matrix(test_labels, pred_labels)))\n",
        "print(\"NN Classification report without HOG images:\\n{}\\n\\n\".format(classification_report(test_labels, pred_labels)))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1500/1500 [==============================] - 4s 2ms/step - loss: 2.1377 - accuracy: 0.3025\n",
            "375/375 [==============================] - 1s 1ms/step - loss: 1.4345 - accuracy: 0.6208\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 2.1562 - accuracy: 0.2673\n",
            "375/375 [==============================] - 1s 1ms/step - loss: 1.4419 - accuracy: 0.6981\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 2.1361 - accuracy: 0.3094\n",
            "375/375 [==============================] - 1s 1ms/step - loss: 1.4032 - accuracy: 0.6667\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 2.1454 - accuracy: 0.3176\n",
            "375/375 [==============================] - 1s 1ms/step - loss: 1.4607 - accuracy: 0.6538\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 2.1569 - accuracy: 0.2710\n",
            "375/375 [==============================] - 1s 1ms/step - loss: 1.4936 - accuracy: 0.5997\n",
            "Epoch 1/6\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 2.1372 - accuracy: 0.3071\n",
            "Epoch 2/6\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 1.2500 - accuracy: 0.7131\n",
            "Epoch 3/6\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.7538 - accuracy: 0.8168\n",
            "Epoch 4/6\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.5240 - accuracy: 0.8612\n",
            "Epoch 5/6\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.4077 - accuracy: 0.8860\n",
            "Epoch 6/6\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3343 - accuracy: 0.9055\n",
            "375/375 [==============================] - 1s 1ms/step - loss: 0.2935 - accuracy: 0.9198\n",
            "Epoch 1/6\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 2.1419 - accuracy: 0.2939\n",
            "Epoch 2/6\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 1.2751 - accuracy: 0.7036\n",
            "Epoch 3/6\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.7719 - accuracy: 0.8171\n",
            "Epoch 4/6\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.5442 - accuracy: 0.8582\n",
            "Epoch 5/6\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.4229 - accuracy: 0.8849\n",
            "Epoch 6/6\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3467 - accuracy: 0.9047\n",
            "375/375 [==============================] - 1s 1ms/step - loss: 0.3061 - accuracy: 0.9121\n",
            "Epoch 1/6\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 2.1302 - accuracy: 0.3079\n",
            "Epoch 2/6\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 1.2000 - accuracy: 0.7317\n",
            "Epoch 3/6\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.7097 - accuracy: 0.8287\n",
            "Epoch 4/6\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.4911 - accuracy: 0.8726\n",
            "Epoch 5/6\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3800 - accuracy: 0.8968\n",
            "Epoch 6/6\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3169 - accuracy: 0.9116\n",
            "375/375 [==============================] - 1s 1ms/step - loss: 0.3002 - accuracy: 0.9140\n",
            "Epoch 1/6\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 2.1288 - accuracy: 0.3138\n",
            "Epoch 2/6\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 1.2057 - accuracy: 0.7196\n",
            "Epoch 3/6\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.7159 - accuracy: 0.8279\n",
            "Epoch 4/6\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.4996 - accuracy: 0.8682\n",
            "Epoch 5/6\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3912 - accuracy: 0.8931\n",
            "Epoch 6/6\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3216 - accuracy: 0.9100\n",
            "375/375 [==============================] - 1s 1ms/step - loss: 0.2996 - accuracy: 0.9144\n",
            "Epoch 1/6\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 2.1362 - accuracy: 0.2916\n",
            "Epoch 2/6\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 1.2608 - accuracy: 0.7034\n",
            "Epoch 3/6\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.7575 - accuracy: 0.8153\n",
            "Epoch 4/6\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.5245 - accuracy: 0.8610\n",
            "Epoch 5/6\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.4086 - accuracy: 0.8892\n",
            "Epoch 6/6\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3341 - accuracy: 0.9079\n",
            "375/375 [==============================] - 1s 1ms/step - loss: 0.2914 - accuracy: 0.9191\n",
            "Epoch 1/12\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 2.1234 - accuracy: 0.3116\n",
            "Epoch 2/12\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 1.1892 - accuracy: 0.7381\n",
            "Epoch 3/12\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.7000 - accuracy: 0.8294\n",
            "Epoch 4/12\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.4943 - accuracy: 0.8677\n",
            "Epoch 5/12\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3928 - accuracy: 0.8905\n",
            "Epoch 6/12\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3247 - accuracy: 0.9055\n",
            "Epoch 7/12\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2841 - accuracy: 0.9160\n",
            "Epoch 8/12\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2540 - accuracy: 0.9239\n",
            "Epoch 9/12\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2304 - accuracy: 0.9309\n",
            "Epoch 10/12\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2082 - accuracy: 0.9364\n",
            "Epoch 11/12\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1972 - accuracy: 0.9393\n",
            "Epoch 12/12\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1844 - accuracy: 0.9440\n",
            "375/375 [==============================] - 1s 1ms/step - loss: 0.1783 - accuracy: 0.9467\n",
            "Epoch 1/12\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 2.1297 - accuracy: 0.2932\n",
            "Epoch 2/12\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 1.2041 - accuracy: 0.7225\n",
            "Epoch 3/12\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.7153 - accuracy: 0.8250\n",
            "Epoch 4/12\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.4940 - accuracy: 0.8719\n",
            "Epoch 5/12\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3831 - accuracy: 0.8964\n",
            "Epoch 6/12\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3185 - accuracy: 0.9109\n",
            "Epoch 7/12\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2737 - accuracy: 0.9224\n",
            "Epoch 8/12\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2380 - accuracy: 0.9325\n",
            "Epoch 9/12\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2196 - accuracy: 0.9355\n",
            "Epoch 10/12\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2076 - accuracy: 0.9391\n",
            "Epoch 11/12\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1883 - accuracy: 0.9433\n",
            "Epoch 12/12\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1834 - accuracy: 0.9452\n",
            "375/375 [==============================] - 1s 1ms/step - loss: 0.1733 - accuracy: 0.9451\n",
            "Epoch 1/12\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 2.1424 - accuracy: 0.3059\n",
            "Epoch 2/12\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 1.2618 - accuracy: 0.7055\n",
            "Epoch 3/12\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.7726 - accuracy: 0.8162\n",
            "Epoch 4/12\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.5400 - accuracy: 0.8584\n",
            "Epoch 5/12\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.4203 - accuracy: 0.8845\n",
            "Epoch 6/12\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3503 - accuracy: 0.9002\n",
            "Epoch 7/12\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2977 - accuracy: 0.9152\n",
            "Epoch 8/12\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2706 - accuracy: 0.9225\n",
            "Epoch 9/12\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2409 - accuracy: 0.9302\n",
            "Epoch 10/12\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2207 - accuracy: 0.9351\n",
            "Epoch 11/12\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2012 - accuracy: 0.9403\n",
            "Epoch 12/12\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1890 - accuracy: 0.9437\n",
            "375/375 [==============================] - 1s 1ms/step - loss: 0.1957 - accuracy: 0.9393\n",
            "Epoch 1/12\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 2.1341 - accuracy: 0.3061\n",
            "Epoch 2/12\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 1.2102 - accuracy: 0.7232\n",
            "Epoch 3/12\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.7184 - accuracy: 0.8259\n",
            "Epoch 4/12\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.4957 - accuracy: 0.8705\n",
            "Epoch 5/12\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3818 - accuracy: 0.8944\n",
            "Epoch 6/12\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3211 - accuracy: 0.9094\n",
            "Epoch 7/12\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2766 - accuracy: 0.9191\n",
            "Epoch 8/12\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2444 - accuracy: 0.9289\n",
            "Epoch 9/12\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2253 - accuracy: 0.9350\n",
            "Epoch 10/12\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2070 - accuracy: 0.9383\n",
            "Epoch 11/12\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1938 - accuracy: 0.9422\n",
            "Epoch 12/12\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1817 - accuracy: 0.9457\n",
            "375/375 [==============================] - 1s 1ms/step - loss: 0.1970 - accuracy: 0.9416\n",
            "Epoch 1/12\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 2.1397 - accuracy: 0.2874\n",
            "Epoch 2/12\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 1.2509 - accuracy: 0.7118\n",
            "Epoch 3/12\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.7607 - accuracy: 0.8161\n",
            "Epoch 4/12\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.5352 - accuracy: 0.8601\n",
            "Epoch 5/12\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.4204 - accuracy: 0.8827\n",
            "Epoch 6/12\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3496 - accuracy: 0.9019\n",
            "Epoch 7/12\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2965 - accuracy: 0.9156\n",
            "Epoch 8/12\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2608 - accuracy: 0.9245\n",
            "Epoch 9/12\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2394 - accuracy: 0.9280\n",
            "Epoch 10/12\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2206 - accuracy: 0.9344\n",
            "Epoch 11/12\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2014 - accuracy: 0.9396\n",
            "Epoch 12/12\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1959 - accuracy: 0.9406\n",
            "375/375 [==============================] - 1s 1ms/step - loss: 0.1765 - accuracy: 0.9492\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 2.2160 - accuracy: 0.2232\n",
            "188/188 [==============================] - 0s 1ms/step - loss: 1.7303 - accuracy: 0.6109\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 2.2223 - accuracy: 0.2362\n",
            "188/188 [==============================] - 0s 1ms/step - loss: 1.7318 - accuracy: 0.5992\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 2.2375 - accuracy: 0.2216\n",
            "188/188 [==============================] - 0s 1ms/step - loss: 1.8332 - accuracy: 0.5907\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 2.2368 - accuracy: 0.2001\n",
            "188/188 [==============================] - 0s 1ms/step - loss: 1.8254 - accuracy: 0.5197\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 2.2244 - accuracy: 0.2128\n",
            "188/188 [==============================] - 0s 2ms/step - loss: 1.7762 - accuracy: 0.5468\n",
            "Epoch 1/6\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 2.2235 - accuracy: 0.2544\n",
            "Epoch 2/6\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 1.6051 - accuracy: 0.6373\n",
            "Epoch 3/6\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 1.1113 - accuracy: 0.7564\n",
            "Epoch 4/6\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.7831 - accuracy: 0.8167\n",
            "Epoch 5/6\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.5862 - accuracy: 0.8548\n",
            "Epoch 6/6\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.4698 - accuracy: 0.8760\n",
            "188/188 [==============================] - 0s 1ms/step - loss: 0.4044 - accuracy: 0.8943\n",
            "Epoch 1/6\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 2.2255 - accuracy: 0.2285\n",
            "Epoch 2/6\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 1.6147 - accuracy: 0.6153\n",
            "Epoch 3/6\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 1.1373 - accuracy: 0.7451\n",
            "Epoch 4/6\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.8092 - accuracy: 0.8081\n",
            "Epoch 5/6\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.6104 - accuracy: 0.8464\n",
            "Epoch 6/6\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.4887 - accuracy: 0.8712\n",
            "188/188 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.8812\n",
            "Epoch 1/6\n",
            "750/750 [==============================] - 3s 2ms/step - loss: 2.2177 - accuracy: 0.2308\n",
            "Epoch 2/6\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 1.5759 - accuracy: 0.6412\n",
            "Epoch 3/6\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 1.0835 - accuracy: 0.7598\n",
            "Epoch 4/6\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.7657 - accuracy: 0.8186\n",
            "Epoch 5/6\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.5786 - accuracy: 0.8506\n",
            "Epoch 6/6\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.4667 - accuracy: 0.8796\n",
            "188/188 [==============================] - 0s 1ms/step - loss: 0.4169 - accuracy: 0.8852\n",
            "Epoch 1/6\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 2.2348 - accuracy: 0.2278\n",
            "Epoch 2/6\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 1.6682 - accuracy: 0.5752\n",
            "Epoch 3/6\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 1.1876 - accuracy: 0.7304\n",
            "Epoch 4/6\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.8584 - accuracy: 0.7951\n",
            "Epoch 5/6\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.6491 - accuracy: 0.8377\n",
            "Epoch 6/6\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.5192 - accuracy: 0.8643\n",
            "188/188 [==============================] - 0s 2ms/step - loss: 0.4696 - accuracy: 0.8708\n",
            "Epoch 1/6\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 2.2245 - accuracy: 0.2123\n",
            "Epoch 2/6\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 1.6156 - accuracy: 0.6101\n",
            "Epoch 3/6\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 1.1262 - accuracy: 0.7437\n",
            "Epoch 4/6\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.8053 - accuracy: 0.8072\n",
            "Epoch 5/6\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.6082 - accuracy: 0.8461\n",
            "Epoch 6/6\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.4968 - accuracy: 0.8692\n",
            "188/188 [==============================] - 0s 1ms/step - loss: 0.4221 - accuracy: 0.8877\n",
            "Epoch 1/12\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 2.2220 - accuracy: 0.2227\n",
            "Epoch 2/12\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 1.5762 - accuracy: 0.6159\n",
            "Epoch 3/12\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 1.0815 - accuracy: 0.7606\n",
            "Epoch 4/12\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.7636 - accuracy: 0.8209\n",
            "Epoch 5/12\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.5827 - accuracy: 0.8533\n",
            "Epoch 6/12\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.4655 - accuracy: 0.8764\n",
            "Epoch 7/12\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.3946 - accuracy: 0.8921\n",
            "Epoch 8/12\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.3455 - accuracy: 0.9037\n",
            "Epoch 9/12\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.3084 - accuracy: 0.9129\n",
            "Epoch 10/12\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.2759 - accuracy: 0.9204\n",
            "Epoch 11/12\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.2497 - accuracy: 0.9283\n",
            "Epoch 12/12\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.2361 - accuracy: 0.9302\n",
            "188/188 [==============================] - 0s 1ms/step - loss: 0.2175 - accuracy: 0.9382\n",
            "Epoch 1/12\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 2.2233 - accuracy: 0.2452\n",
            "Epoch 2/12\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 1.6101 - accuracy: 0.6005\n",
            "Epoch 3/12\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 1.1226 - accuracy: 0.7471\n",
            "Epoch 4/12\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.8075 - accuracy: 0.8092\n",
            "Epoch 5/12\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.6122 - accuracy: 0.8446\n",
            "Epoch 6/12\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.4986 - accuracy: 0.8678\n",
            "Epoch 7/12\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.4168 - accuracy: 0.8869\n",
            "Epoch 8/12\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.3652 - accuracy: 0.9004\n",
            "Epoch 9/12\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.3178 - accuracy: 0.9110\n",
            "Epoch 10/12\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.2934 - accuracy: 0.9171\n",
            "Epoch 11/12\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.2608 - accuracy: 0.9267\n",
            "Epoch 12/12\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2448 - accuracy: 0.9290\n",
            "188/188 [==============================] - 0s 2ms/step - loss: 0.2293 - accuracy: 0.9295\n",
            "Epoch 1/12\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 2.2310 - accuracy: 0.2187\n",
            "Epoch 2/12\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 1.6403 - accuracy: 0.6117\n",
            "Epoch 3/12\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 1.1568 - accuracy: 0.7419\n",
            "Epoch 4/12\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.8332 - accuracy: 0.8037\n",
            "Epoch 5/12\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.6337 - accuracy: 0.8426\n",
            "Epoch 6/12\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.5062 - accuracy: 0.8662\n",
            "Epoch 7/12\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.4274 - accuracy: 0.8866\n",
            "Epoch 8/12\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.3635 - accuracy: 0.9029\n",
            "Epoch 9/12\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.3235 - accuracy: 0.9113\n",
            "Epoch 10/12\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.2881 - accuracy: 0.9184\n",
            "Epoch 11/12\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.2611 - accuracy: 0.9256\n",
            "Epoch 12/12\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.2413 - accuracy: 0.9311\n",
            "188/188 [==============================] - 0s 1ms/step - loss: 0.2437 - accuracy: 0.9287\n",
            "Epoch 1/12\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 2.2243 - accuracy: 0.2490\n",
            "Epoch 2/12\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 1.6110 - accuracy: 0.5846\n",
            "Epoch 3/12\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 1.1446 - accuracy: 0.7373\n",
            "Epoch 4/12\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.8153 - accuracy: 0.8044\n",
            "Epoch 5/12\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.6117 - accuracy: 0.8463\n",
            "Epoch 6/12\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.4905 - accuracy: 0.8715\n",
            "Epoch 7/12\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.4058 - accuracy: 0.8914\n",
            "Epoch 8/12\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.3551 - accuracy: 0.9015\n",
            "Epoch 9/12\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.3111 - accuracy: 0.9116\n",
            "Epoch 10/12\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.2836 - accuracy: 0.9180\n",
            "Epoch 11/12\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.2544 - accuracy: 0.9269\n",
            "Epoch 12/12\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.2405 - accuracy: 0.9298\n",
            "188/188 [==============================] - 0s 2ms/step - loss: 0.2351 - accuracy: 0.9317\n",
            "Epoch 1/12\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 2.2332 - accuracy: 0.2114\n",
            "Epoch 2/12\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 1.6471 - accuracy: 0.6071\n",
            "Epoch 3/12\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 1.1600 - accuracy: 0.7411\n",
            "Epoch 4/12\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.8318 - accuracy: 0.8058\n",
            "Epoch 5/12\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.6263 - accuracy: 0.8434\n",
            "Epoch 6/12\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.5114 - accuracy: 0.8662\n",
            "Epoch 7/12\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.4300 - accuracy: 0.8833\n",
            "Epoch 8/12\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.3707 - accuracy: 0.8990\n",
            "Epoch 9/12\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.3288 - accuracy: 0.9075\n",
            "Epoch 10/12\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.2960 - accuracy: 0.9153\n",
            "Epoch 11/12\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2664 - accuracy: 0.9237\n",
            "Epoch 12/12\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2485 - accuracy: 0.9276\n",
            "188/188 [==============================] - 1s 2ms/step - loss: 0.2258 - accuracy: 0.9372\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.2685 - accuracy: 0.1679\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 2.0582 - accuracy: 0.4150\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.2712 - accuracy: 0.1813\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 2.0704 - accuracy: 0.3284\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.2684 - accuracy: 0.1733\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 2.0448 - accuracy: 0.4005\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.2684 - accuracy: 0.1898\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 2.0574 - accuracy: 0.4601\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.2684 - accuracy: 0.1784\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 2.0645 - accuracy: 0.4083\n",
            "Epoch 1/6\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.2704 - accuracy: 0.1687\n",
            "Epoch 2/6\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.9641 - accuracy: 0.4780\n",
            "Epoch 3/6\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.5713 - accuracy: 0.6378\n",
            "Epoch 4/6\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.2745 - accuracy: 0.7157\n",
            "Epoch 5/6\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.0368 - accuracy: 0.7679\n",
            "Epoch 6/6\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.8411 - accuracy: 0.8072\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.7232 - accuracy: 0.8278\n",
            "Epoch 1/6\n",
            "375/375 [==============================] - 2s 3ms/step - loss: 2.2681 - accuracy: 0.2148\n",
            "Epoch 2/6\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.9440 - accuracy: 0.4896\n",
            "Epoch 3/6\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.5398 - accuracy: 0.6328\n",
            "Epoch 4/6\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.2401 - accuracy: 0.7250\n",
            "Epoch 5/6\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.0016 - accuracy: 0.7727\n",
            "Epoch 6/6\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.8054 - accuracy: 0.8111\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6887 - accuracy: 0.8331\n",
            "Epoch 1/6\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.2680 - accuracy: 0.1960\n",
            "Epoch 2/6\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.9392 - accuracy: 0.4987\n",
            "Epoch 3/6\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.5274 - accuracy: 0.6570\n",
            "Epoch 4/6\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.2173 - accuracy: 0.7386\n",
            "Epoch 5/6\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.9687 - accuracy: 0.7846\n",
            "Epoch 6/6\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.7770 - accuracy: 0.8195\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6766 - accuracy: 0.8329\n",
            "Epoch 1/6\n",
            "375/375 [==============================] - 2s 3ms/step - loss: 2.2688 - accuracy: 0.1876\n",
            "Epoch 2/6\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.9426 - accuracy: 0.4956\n",
            "Epoch 3/6\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.5300 - accuracy: 0.6574\n",
            "Epoch 4/6\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.2159 - accuracy: 0.7386\n",
            "Epoch 5/6\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.9680 - accuracy: 0.7860\n",
            "Epoch 6/6\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.7764 - accuracy: 0.8234\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6788 - accuracy: 0.8344\n",
            "Epoch 1/6\n",
            "375/375 [==============================] - 2s 3ms/step - loss: 2.2733 - accuracy: 0.1937\n",
            "Epoch 2/6\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.9914 - accuracy: 0.4745\n",
            "Epoch 3/6\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.6039 - accuracy: 0.6123\n",
            "Epoch 4/6\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.3002 - accuracy: 0.7040\n",
            "Epoch 5/6\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.0637 - accuracy: 0.7537\n",
            "Epoch 6/6\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.8659 - accuracy: 0.7945\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.7419 - accuracy: 0.8239\n",
            "Epoch 1/12\n",
            "375/375 [==============================] - 2s 3ms/step - loss: 2.2692 - accuracy: 0.1600\n",
            "Epoch 2/12\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.9504 - accuracy: 0.5147\n",
            "Epoch 3/12\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.5441 - accuracy: 0.6631\n",
            "Epoch 4/12\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.2404 - accuracy: 0.7331\n",
            "Epoch 5/12\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.9932 - accuracy: 0.7831\n",
            "Epoch 6/12\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.7987 - accuracy: 0.8151\n",
            "Epoch 7/12\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.6594 - accuracy: 0.8384\n",
            "Epoch 8/12\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5624 - accuracy: 0.8562\n",
            "Epoch 9/12\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4855 - accuracy: 0.8729\n",
            "Epoch 10/12\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4292 - accuracy: 0.8836\n",
            "Epoch 11/12\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3817 - accuracy: 0.8953\n",
            "Epoch 12/12\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3443 - accuracy: 0.9057\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.3218 - accuracy: 0.9137\n",
            "Epoch 1/12\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.2683 - accuracy: 0.1844\n",
            "Epoch 2/12\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.9442 - accuracy: 0.4459\n",
            "Epoch 3/12\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.5392 - accuracy: 0.6548\n",
            "Epoch 4/12\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.2406 - accuracy: 0.7267\n",
            "Epoch 5/12\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.9955 - accuracy: 0.7793\n",
            "Epoch 6/12\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.8078 - accuracy: 0.8083\n",
            "Epoch 7/12\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.6613 - accuracy: 0.8375\n",
            "Epoch 8/12\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5559 - accuracy: 0.8604\n",
            "Epoch 9/12\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4837 - accuracy: 0.8734\n",
            "Epoch 10/12\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4316 - accuracy: 0.8837\n",
            "Epoch 11/12\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3865 - accuracy: 0.8959\n",
            "Epoch 12/12\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3461 - accuracy: 0.9055\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.3260 - accuracy: 0.9061\n",
            "Epoch 1/12\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.2724 - accuracy: 0.1819\n",
            "Epoch 2/12\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.9751 - accuracy: 0.4926\n",
            "Epoch 3/12\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.5839 - accuracy: 0.6219\n",
            "Epoch 4/12\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.2894 - accuracy: 0.7166\n",
            "Epoch 5/12\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.0501 - accuracy: 0.7692\n",
            "Epoch 6/12\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.8489 - accuracy: 0.8075\n",
            "Epoch 7/12\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.6968 - accuracy: 0.8343\n",
            "Epoch 8/12\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.5883 - accuracy: 0.8553\n",
            "Epoch 9/12\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5087 - accuracy: 0.8684\n",
            "Epoch 10/12\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4491 - accuracy: 0.8829\n",
            "Epoch 11/12\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4031 - accuracy: 0.8915\n",
            "Epoch 12/12\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3694 - accuracy: 0.8989\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.3533 - accuracy: 0.9020\n",
            "Epoch 1/12\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.2719 - accuracy: 0.1897\n",
            "Epoch 2/12\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.9634 - accuracy: 0.4799\n",
            "Epoch 3/12\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.5571 - accuracy: 0.6525\n",
            "Epoch 4/12\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.2440 - accuracy: 0.7351\n",
            "Epoch 5/12\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.0012 - accuracy: 0.7814\n",
            "Epoch 6/12\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.8009 - accuracy: 0.8194\n",
            "Epoch 7/12\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.6648 - accuracy: 0.8386\n",
            "Epoch 8/12\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.5614 - accuracy: 0.8595\n",
            "Epoch 9/12\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4874 - accuracy: 0.8738\n",
            "Epoch 10/12\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4325 - accuracy: 0.8827\n",
            "Epoch 11/12\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3881 - accuracy: 0.8943\n",
            "Epoch 12/12\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3471 - accuracy: 0.9046\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.3390 - accuracy: 0.9066\n",
            "Epoch 1/12\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.2719 - accuracy: 0.1572\n",
            "Epoch 2/12\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.9715 - accuracy: 0.4663\n",
            "Epoch 3/12\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.5837 - accuracy: 0.6363\n",
            "Epoch 4/12\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.2766 - accuracy: 0.7186\n",
            "Epoch 5/12\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.0437 - accuracy: 0.7667\n",
            "Epoch 6/12\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.8455 - accuracy: 0.8060\n",
            "Epoch 7/12\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.6992 - accuracy: 0.8309\n",
            "Epoch 8/12\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5960 - accuracy: 0.8480\n",
            "Epoch 9/12\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5204 - accuracy: 0.8657\n",
            "Epoch 10/12\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4611 - accuracy: 0.8765\n",
            "Epoch 11/12\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4141 - accuracy: 0.8873\n",
            "Epoch 12/12\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3775 - accuracy: 0.8963\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.3405 - accuracy: 0.9080\n",
            "Epoch 1/12\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 2.0630 - accuracy: 0.3338\n",
            "Epoch 2/12\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 1.0032 - accuracy: 0.7748\n",
            "Epoch 3/12\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5615 - accuracy: 0.8554\n",
            "Epoch 4/12\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4014 - accuracy: 0.8882\n",
            "Epoch 5/12\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3175 - accuracy: 0.9095\n",
            "Epoch 6/12\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2636 - accuracy: 0.9231\n",
            "Epoch 7/12\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2350 - accuracy: 0.9294\n",
            "Epoch 8/12\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2127 - accuracy: 0.9365\n",
            "Epoch 9/12\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1907 - accuracy: 0.9427\n",
            "Epoch 10/12\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1849 - accuracy: 0.9430\n",
            "Epoch 11/12\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1703 - accuracy: 0.9481\n",
            "Epoch 12/12\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1639 - accuracy: 0.9492\n",
            "Chosing Neural Network params with HOG data:  {'batch_size': 32, 'epochs': 12}\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 0.3591 - accuracy: 0.8945\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1265 - accuracy: 0.9633\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 0.3528 - accuracy: 0.8949\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1329 - accuracy: 0.9623\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 0.3458 - accuracy: 0.8989\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1326 - accuracy: 0.9603\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 0.3490 - accuracy: 0.8975\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1412 - accuracy: 0.9578\n",
            "1500/1500 [==============================] - 12s 7ms/step - loss: 0.3628 - accuracy: 0.8921\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1332 - accuracy: 0.9617\n",
            "Epoch 1/6\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 0.3624 - accuracy: 0.8941\n",
            "Epoch 2/6\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0973 - accuracy: 0.9703\n",
            "Epoch 3/6\n",
            "1500/1500 [==============================] - 11s 8ms/step - loss: 0.0641 - accuracy: 0.9810\n",
            "Epoch 4/6\n",
            "1500/1500 [==============================] - 11s 8ms/step - loss: 0.0476 - accuracy: 0.9861\n",
            "Epoch 5/6\n",
            "1500/1500 [==============================] - 11s 8ms/step - loss: 0.0380 - accuracy: 0.9886\n",
            "Epoch 6/6\n",
            "1500/1500 [==============================] - 11s 8ms/step - loss: 0.0333 - accuracy: 0.9910\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1137 - accuracy: 0.9729\n",
            "Epoch 1/6\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 0.3575 - accuracy: 0.8925\n",
            "Epoch 2/6\n",
            "1500/1500 [==============================] - 11s 8ms/step - loss: 0.0987 - accuracy: 0.9702\n",
            "Epoch 3/6\n",
            "1500/1500 [==============================] - 11s 7ms/step - loss: 0.0648 - accuracy: 0.9812\n",
            "Epoch 4/6\n",
            "1500/1500 [==============================] - 11s 8ms/step - loss: 0.0474 - accuracy: 0.9868\n",
            "Epoch 5/6\n",
            "1500/1500 [==============================] - 11s 7ms/step - loss: 0.0373 - accuracy: 0.9891\n",
            "Epoch 6/6\n",
            "1500/1500 [==============================] - 11s 7ms/step - loss: 0.0274 - accuracy: 0.9920\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1260 - accuracy: 0.9719\n",
            "Epoch 1/6\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 0.3581 - accuracy: 0.8953\n",
            "Epoch 2/6\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1017 - accuracy: 0.9702\n",
            "Epoch 3/6\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0668 - accuracy: 0.9804\n",
            "Epoch 4/6\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0482 - accuracy: 0.9853\n",
            "Epoch 5/6\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0385 - accuracy: 0.9888\n",
            "Epoch 6/6\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0283 - accuracy: 0.9914\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1119 - accuracy: 0.9748\n",
            "Epoch 1/6\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 0.3588 - accuracy: 0.8950\n",
            "Epoch 2/6\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0971 - accuracy: 0.9707\n",
            "Epoch 3/6\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0683 - accuracy: 0.9813\n",
            "Epoch 4/6\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0484 - accuracy: 0.9866\n",
            "Epoch 5/6\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0381 - accuracy: 0.9893\n",
            "Epoch 6/6\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0304 - accuracy: 0.9915\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1388 - accuracy: 0.9698\n",
            "Epoch 1/6\n",
            "1500/1500 [==============================] - 13s 8ms/step - loss: 0.3592 - accuracy: 0.8940\n",
            "Epoch 2/6\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1016 - accuracy: 0.9683\n",
            "Epoch 3/6\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0675 - accuracy: 0.9801\n",
            "Epoch 4/6\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0456 - accuracy: 0.9868\n",
            "Epoch 5/6\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0367 - accuracy: 0.9894\n",
            "Epoch 6/6\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0322 - accuracy: 0.9909\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1073 - accuracy: 0.9775\n",
            "Epoch 1/12\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 0.3618 - accuracy: 0.8922\n",
            "Epoch 2/12\n",
            "1500/1500 [==============================] - 11s 8ms/step - loss: 0.1027 - accuracy: 0.9695\n",
            "Epoch 3/12\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0676 - accuracy: 0.9800\n",
            "Epoch 4/12\n",
            "1500/1500 [==============================] - 11s 8ms/step - loss: 0.0487 - accuracy: 0.9854\n",
            "Epoch 5/12\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0409 - accuracy: 0.9887\n",
            "Epoch 6/12\n",
            "1500/1500 [==============================] - 11s 7ms/step - loss: 0.0292 - accuracy: 0.9919\n",
            "Epoch 7/12\n",
            "1500/1500 [==============================] - 11s 8ms/step - loss: 0.0224 - accuracy: 0.9936\n",
            "Epoch 8/12\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0177 - accuracy: 0.9949\n",
            "Epoch 9/12\n",
            "1500/1500 [==============================] - 11s 8ms/step - loss: 0.0133 - accuracy: 0.9956\n",
            "Epoch 10/12\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0117 - accuracy: 0.9968\n",
            "Epoch 11/12\n",
            "1500/1500 [==============================] - 11s 8ms/step - loss: 0.0100 - accuracy: 0.9974\n",
            "Epoch 12/12\n",
            "1500/1500 [==============================] - 11s 8ms/step - loss: 0.0081 - accuracy: 0.9978\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1255 - accuracy: 0.9801\n",
            "Epoch 1/12\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 0.3536 - accuracy: 0.8926\n",
            "Epoch 2/12\n",
            "1500/1500 [==============================] - 11s 8ms/step - loss: 0.1038 - accuracy: 0.9690\n",
            "Epoch 3/12\n",
            "1500/1500 [==============================] - 11s 8ms/step - loss: 0.0700 - accuracy: 0.9798\n",
            "Epoch 4/12\n",
            "1500/1500 [==============================] - 11s 7ms/step - loss: 0.0496 - accuracy: 0.9850\n",
            "Epoch 5/12\n",
            "1500/1500 [==============================] - 11s 8ms/step - loss: 0.0408 - accuracy: 0.9886\n",
            "Epoch 6/12\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0318 - accuracy: 0.9916\n",
            "Epoch 7/12\n",
            "1500/1500 [==============================] - 11s 8ms/step - loss: 0.0248 - accuracy: 0.9927\n",
            "Epoch 8/12\n",
            "1500/1500 [==============================] - 11s 8ms/step - loss: 0.0211 - accuracy: 0.9941\n",
            "Epoch 9/12\n",
            "1500/1500 [==============================] - 11s 8ms/step - loss: 0.0175 - accuracy: 0.9953\n",
            "Epoch 10/12\n",
            "1500/1500 [==============================] - 11s 7ms/step - loss: 0.0154 - accuracy: 0.9955\n",
            "Epoch 11/12\n",
            "1500/1500 [==============================] - 11s 8ms/step - loss: 0.0125 - accuracy: 0.9969\n",
            "Epoch 12/12\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0092 - accuracy: 0.9976\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1392 - accuracy: 0.9771\n",
            "Epoch 1/12\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 0.3621 - accuracy: 0.8927\n",
            "Epoch 2/12\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0988 - accuracy: 0.9699\n",
            "Epoch 3/12\n",
            "1500/1500 [==============================] - 11s 8ms/step - loss: 0.0680 - accuracy: 0.9788\n",
            "Epoch 4/12\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0470 - accuracy: 0.9848\n",
            "Epoch 5/12\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0384 - accuracy: 0.9886\n",
            "Epoch 6/12\n",
            "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0322 - accuracy: 0.9908\n",
            "Epoch 7/12\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0230 - accuracy: 0.9936\n",
            "Epoch 8/12\n",
            "1500/1500 [==============================] - 11s 8ms/step - loss: 0.0194 - accuracy: 0.9950\n",
            "Epoch 9/12\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0148 - accuracy: 0.9958\n",
            "Epoch 10/12\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0120 - accuracy: 0.9966\n",
            "Epoch 11/12\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0099 - accuracy: 0.9975\n",
            "Epoch 12/12\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0066 - accuracy: 0.9981\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1346 - accuracy: 0.9805\n",
            "Epoch 1/12\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 0.3526 - accuracy: 0.8969\n",
            "Epoch 2/12\n",
            "1500/1500 [==============================] - 11s 8ms/step - loss: 0.0975 - accuracy: 0.9714\n",
            "Epoch 3/12\n",
            "1500/1500 [==============================] - 11s 8ms/step - loss: 0.0640 - accuracy: 0.9818\n",
            "Epoch 4/12\n",
            "1500/1500 [==============================] - 11s 8ms/step - loss: 0.0470 - accuracy: 0.9872\n",
            "Epoch 5/12\n",
            "1500/1500 [==============================] - 11s 8ms/step - loss: 0.0368 - accuracy: 0.9895\n",
            "Epoch 6/12\n",
            "1500/1500 [==============================] - 11s 8ms/step - loss: 0.0281 - accuracy: 0.9918\n",
            "Epoch 7/12\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0232 - accuracy: 0.9931\n",
            "Epoch 8/12\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0161 - accuracy: 0.9951\n",
            "Epoch 9/12\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0137 - accuracy: 0.9957\n",
            "Epoch 10/12\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0123 - accuracy: 0.9967\n",
            "Epoch 11/12\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0090 - accuracy: 0.9975\n",
            "Epoch 12/12\n",
            "1500/1500 [==============================] - 11s 8ms/step - loss: 0.0062 - accuracy: 0.9984\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1758 - accuracy: 0.9745\n",
            "Epoch 1/12\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 0.3627 - accuracy: 0.8899\n",
            "Epoch 2/12\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1013 - accuracy: 0.9713\n",
            "Epoch 3/12\n",
            "1500/1500 [==============================] - 11s 8ms/step - loss: 0.0665 - accuracy: 0.9807\n",
            "Epoch 4/12\n",
            "1500/1500 [==============================] - 11s 8ms/step - loss: 0.0479 - accuracy: 0.9862\n",
            "Epoch 5/12\n",
            "1500/1500 [==============================] - 11s 8ms/step - loss: 0.0415 - accuracy: 0.9888\n",
            "Epoch 6/12\n",
            "1500/1500 [==============================] - 11s 8ms/step - loss: 0.0297 - accuracy: 0.9916\n",
            "Epoch 7/12\n",
            "1500/1500 [==============================] - 11s 8ms/step - loss: 0.0226 - accuracy: 0.9939\n",
            "Epoch 8/12\n",
            "1500/1500 [==============================] - 11s 8ms/step - loss: 0.0206 - accuracy: 0.9942\n",
            "Epoch 9/12\n",
            "1500/1500 [==============================] - 11s 8ms/step - loss: 0.0150 - accuracy: 0.9953\n",
            "Epoch 10/12\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0106 - accuracy: 0.9971\n",
            "Epoch 11/12\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0088 - accuracy: 0.9974\n",
            "Epoch 12/12\n",
            "1500/1500 [==============================] - 11s 8ms/step - loss: 0.0076 - accuracy: 0.9976\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1368 - accuracy: 0.9797\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.3995 - accuracy: 0.8820\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1326 - accuracy: 0.9608\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.3907 - accuracy: 0.8865\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1594 - accuracy: 0.9555\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.4056 - accuracy: 0.8820\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1522 - accuracy: 0.9522\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.4089 - accuracy: 0.8783\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1528 - accuracy: 0.9548\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.4129 - accuracy: 0.8779\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1285 - accuracy: 0.9621\n",
            "Epoch 1/6\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.3953 - accuracy: 0.8849\n",
            "Epoch 2/6\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.1101 - accuracy: 0.9668\n",
            "Epoch 3/6\n",
            "750/750 [==============================] - 6s 9ms/step - loss: 0.0667 - accuracy: 0.9798\n",
            "Epoch 4/6\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0479 - accuracy: 0.9857\n",
            "Epoch 5/6\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0340 - accuracy: 0.9896\n",
            "Epoch 6/6\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0246 - accuracy: 0.9923\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0808 - accuracy: 0.9795\n",
            "Epoch 1/6\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.3900 - accuracy: 0.8860\n",
            "Epoch 2/6\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.1035 - accuracy: 0.9685\n",
            "Epoch 3/6\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0714 - accuracy: 0.9790\n",
            "Epoch 4/6\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0492 - accuracy: 0.9850\n",
            "Epoch 5/6\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0353 - accuracy: 0.9900\n",
            "Epoch 6/6\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0257 - accuracy: 0.9927\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0968 - accuracy: 0.9750\n",
            "Epoch 1/6\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.4055 - accuracy: 0.8818\n",
            "Epoch 2/6\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.1099 - accuracy: 0.9680\n",
            "Epoch 3/6\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0681 - accuracy: 0.9800\n",
            "Epoch 4/6\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0489 - accuracy: 0.9850\n",
            "Epoch 5/6\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0366 - accuracy: 0.9882\n",
            "Epoch 6/6\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0288 - accuracy: 0.9917\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0934 - accuracy: 0.9759\n",
            "Epoch 1/6\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.3841 - accuracy: 0.8892\n",
            "Epoch 2/6\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.1036 - accuracy: 0.9696\n",
            "Epoch 3/6\n",
            "750/750 [==============================] - 7s 10ms/step - loss: 0.0667 - accuracy: 0.9797\n",
            "Epoch 4/6\n",
            "750/750 [==============================] - 7s 10ms/step - loss: 0.0501 - accuracy: 0.9853\n",
            "Epoch 5/6\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0346 - accuracy: 0.9898\n",
            "Epoch 6/6\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0256 - accuracy: 0.9929\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1058 - accuracy: 0.9743\n",
            "Epoch 1/6\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.4039 - accuracy: 0.8813\n",
            "Epoch 2/6\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.1080 - accuracy: 0.9682\n",
            "Epoch 3/6\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0682 - accuracy: 0.9795\n",
            "Epoch 4/6\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0460 - accuracy: 0.9861\n",
            "Epoch 5/6\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0366 - accuracy: 0.9893\n",
            "Epoch 6/6\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0264 - accuracy: 0.9920\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0914 - accuracy: 0.9767\n",
            "Epoch 1/12\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.4078 - accuracy: 0.8836\n",
            "Epoch 2/12\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.1087 - accuracy: 0.9676\n",
            "Epoch 3/12\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0634 - accuracy: 0.9806\n",
            "Epoch 4/12\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0471 - accuracy: 0.9853\n",
            "Epoch 5/12\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0353 - accuracy: 0.9894\n",
            "Epoch 6/12\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0256 - accuracy: 0.9923\n",
            "Epoch 7/12\n",
            "750/750 [==============================] - 7s 10ms/step - loss: 0.0195 - accuracy: 0.9943\n",
            "Epoch 8/12\n",
            "750/750 [==============================] - 7s 10ms/step - loss: 0.0138 - accuracy: 0.9957\n",
            "Epoch 9/12\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0107 - accuracy: 0.9968\n",
            "Epoch 10/12\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0089 - accuracy: 0.9975\n",
            "Epoch 11/12\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0064 - accuracy: 0.9982\n",
            "Epoch 12/12\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0040 - accuracy: 0.9988\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1069 - accuracy: 0.9785\n",
            "Epoch 1/12\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.3978 - accuracy: 0.8816\n",
            "Epoch 2/12\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.1077 - accuracy: 0.9683\n",
            "Epoch 3/12\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0704 - accuracy: 0.9792\n",
            "Epoch 4/12\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0477 - accuracy: 0.9862\n",
            "Epoch 5/12\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0338 - accuracy: 0.9905\n",
            "Epoch 6/12\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0263 - accuracy: 0.9926\n",
            "Epoch 7/12\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0201 - accuracy: 0.9944\n",
            "Epoch 8/12\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0189 - accuracy: 0.9947\n",
            "Epoch 9/12\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0113 - accuracy: 0.9969\n",
            "Epoch 10/12\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0096 - accuracy: 0.9975\n",
            "Epoch 11/12\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0081 - accuracy: 0.9974\n",
            "Epoch 12/12\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0054 - accuracy: 0.9985\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1197 - accuracy: 0.9785\n",
            "Epoch 1/12\n",
            "750/750 [==============================] - 8s 9ms/step - loss: 0.4037 - accuracy: 0.8816\n",
            "Epoch 2/12\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.1094 - accuracy: 0.9670\n",
            "Epoch 3/12\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0683 - accuracy: 0.9786\n",
            "Epoch 4/12\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0461 - accuracy: 0.9867\n",
            "Epoch 5/12\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0376 - accuracy: 0.9892\n",
            "Epoch 6/12\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0282 - accuracy: 0.9918\n",
            "Epoch 7/12\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0206 - accuracy: 0.9940\n",
            "Epoch 8/12\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0153 - accuracy: 0.9950\n",
            "Epoch 9/12\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0122 - accuracy: 0.9962\n",
            "Epoch 10/12\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0092 - accuracy: 0.9970\n",
            "Epoch 11/12\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0065 - accuracy: 0.9983\n",
            "Epoch 12/12\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0052 - accuracy: 0.9985\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1108 - accuracy: 0.9793\n",
            "Epoch 1/12\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.3964 - accuracy: 0.8847\n",
            "Epoch 2/12\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.1035 - accuracy: 0.9700\n",
            "Epoch 3/12\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0638 - accuracy: 0.9798\n",
            "Epoch 4/12\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0476 - accuracy: 0.9867\n",
            "Epoch 5/12\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0307 - accuracy: 0.9911\n",
            "Epoch 6/12\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0258 - accuracy: 0.9921\n",
            "Epoch 7/12\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0196 - accuracy: 0.9944\n",
            "Epoch 8/12\n",
            "750/750 [==============================] - 7s 10ms/step - loss: 0.0144 - accuracy: 0.9957\n",
            "Epoch 9/12\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0117 - accuracy: 0.9969\n",
            "Epoch 10/12\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0076 - accuracy: 0.9978\n",
            "Epoch 11/12\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0057 - accuracy: 0.9983\n",
            "Epoch 12/12\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0042 - accuracy: 0.9990\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1295 - accuracy: 0.9770\n",
            "Epoch 1/12\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.4018 - accuracy: 0.8823\n",
            "Epoch 2/12\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.1082 - accuracy: 0.9667\n",
            "Epoch 3/12\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0677 - accuracy: 0.9803\n",
            "Epoch 4/12\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0462 - accuracy: 0.9869\n",
            "Epoch 5/12\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0342 - accuracy: 0.9897\n",
            "Epoch 6/12\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0245 - accuracy: 0.9928\n",
            "Epoch 7/12\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0205 - accuracy: 0.9938\n",
            "Epoch 8/12\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0154 - accuracy: 0.9955\n",
            "Epoch 9/12\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0108 - accuracy: 0.9968\n",
            "Epoch 10/12\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0081 - accuracy: 0.9977\n",
            "Epoch 11/12\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0061 - accuracy: 0.9984\n",
            "Epoch 12/12\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0042 - accuracy: 0.9989\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1228 - accuracy: 0.9774\n",
            "375/375 [==============================] - 5s 12ms/step - loss: 0.4792 - accuracy: 0.8619\n",
            "94/94 [==============================] - 1s 5ms/step - loss: 0.1488 - accuracy: 0.9578\n",
            "375/375 [==============================] - 5s 12ms/step - loss: 0.4727 - accuracy: 0.8627\n",
            "94/94 [==============================] - 1s 5ms/step - loss: 0.1573 - accuracy: 0.9542\n",
            "375/375 [==============================] - 5s 12ms/step - loss: 0.4618 - accuracy: 0.8673\n",
            "94/94 [==============================] - 1s 5ms/step - loss: 0.1792 - accuracy: 0.9430\n",
            "375/375 [==============================] - 5s 11ms/step - loss: 0.4737 - accuracy: 0.8626\n",
            "94/94 [==============================] - 1s 5ms/step - loss: 0.1631 - accuracy: 0.9513\n",
            "375/375 [==============================] - 5s 12ms/step - loss: 0.4699 - accuracy: 0.8625\n",
            "94/94 [==============================] - 1s 5ms/step - loss: 0.1580 - accuracy: 0.9541\n",
            "Epoch 1/6\n",
            "375/375 [==============================] - 5s 12ms/step - loss: 0.4759 - accuracy: 0.8615\n",
            "Epoch 2/6\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.1246 - accuracy: 0.9639\n",
            "Epoch 3/6\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.0817 - accuracy: 0.9758\n",
            "Epoch 4/6\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.0549 - accuracy: 0.9836\n",
            "Epoch 5/6\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 0.0374 - accuracy: 0.9888\n",
            "Epoch 6/6\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.0300 - accuracy: 0.9909\n",
            "94/94 [==============================] - 1s 5ms/step - loss: 0.0738 - accuracy: 0.9782\n",
            "Epoch 1/6\n",
            "375/375 [==============================] - 5s 12ms/step - loss: 0.4650 - accuracy: 0.8646\n",
            "Epoch 2/6\n",
            "375/375 [==============================] - 5s 12ms/step - loss: 0.1281 - accuracy: 0.9627\n",
            "Epoch 3/6\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.0788 - accuracy: 0.9769\n",
            "Epoch 4/6\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.0576 - accuracy: 0.9834\n",
            "Epoch 5/6\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.0391 - accuracy: 0.9886\n",
            "Epoch 6/6\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.0301 - accuracy: 0.9916\n",
            "94/94 [==============================] - 1s 5ms/step - loss: 0.0831 - accuracy: 0.9757\n",
            "Epoch 1/6\n",
            "375/375 [==============================] - 5s 12ms/step - loss: 0.4731 - accuracy: 0.8610\n",
            "Epoch 2/6\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.1261 - accuracy: 0.9631\n",
            "Epoch 3/6\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.0769 - accuracy: 0.9777\n",
            "Epoch 4/6\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.0531 - accuracy: 0.9848\n",
            "Epoch 5/6\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.0385 - accuracy: 0.9884\n",
            "Epoch 6/6\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.0287 - accuracy: 0.9918\n",
            "94/94 [==============================] - 1s 5ms/step - loss: 0.0805 - accuracy: 0.9772\n",
            "Epoch 1/6\n",
            "375/375 [==============================] - 5s 12ms/step - loss: 0.4635 - accuracy: 0.8627\n",
            "Epoch 2/6\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.1253 - accuracy: 0.9631\n",
            "Epoch 3/6\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 0.0782 - accuracy: 0.9773\n",
            "Epoch 4/6\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.0529 - accuracy: 0.9844\n",
            "Epoch 5/6\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.0388 - accuracy: 0.9893\n",
            "Epoch 6/6\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.0283 - accuracy: 0.9923\n",
            "94/94 [==============================] - 1s 5ms/step - loss: 0.1030 - accuracy: 0.9717\n",
            "Epoch 1/6\n",
            "375/375 [==============================] - 5s 12ms/step - loss: 0.4755 - accuracy: 0.8599\n",
            "Epoch 2/6\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.1297 - accuracy: 0.9612\n",
            "Epoch 3/6\n",
            "375/375 [==============================] - 5s 12ms/step - loss: 0.0772 - accuracy: 0.9779\n",
            "Epoch 4/6\n",
            "375/375 [==============================] - 5s 12ms/step - loss: 0.0560 - accuracy: 0.9831\n",
            "Epoch 5/6\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.0395 - accuracy: 0.9883\n",
            "Epoch 6/6\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.0281 - accuracy: 0.9920\n",
            "94/94 [==============================] - 1s 5ms/step - loss: 0.0815 - accuracy: 0.9773\n",
            "Epoch 1/12\n",
            "375/375 [==============================] - 5s 12ms/step - loss: 0.4659 - accuracy: 0.8632\n",
            "Epoch 2/12\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.1265 - accuracy: 0.9622\n",
            "Epoch 3/12\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.0789 - accuracy: 0.9772\n",
            "Epoch 4/12\n",
            "375/375 [==============================] - 5s 12ms/step - loss: 0.0582 - accuracy: 0.9826\n",
            "Epoch 5/12\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.0418 - accuracy: 0.9869\n",
            "Epoch 6/12\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.0296 - accuracy: 0.9920\n",
            "Epoch 7/12\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.0217 - accuracy: 0.9937\n",
            "Epoch 8/12\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.0154 - accuracy: 0.9957\n",
            "Epoch 9/12\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.0123 - accuracy: 0.9965\n",
            "Epoch 10/12\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.0085 - accuracy: 0.9978\n",
            "Epoch 11/12\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.0073 - accuracy: 0.9981\n",
            "Epoch 12/12\n",
            "375/375 [==============================] - 5s 12ms/step - loss: 0.0062 - accuracy: 0.9984\n",
            "94/94 [==============================] - 1s 5ms/step - loss: 0.0743 - accuracy: 0.9812\n",
            "Epoch 1/12\n",
            "375/375 [==============================] - 5s 12ms/step - loss: 0.4616 - accuracy: 0.8628\n",
            "Epoch 2/12\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.1274 - accuracy: 0.9629\n",
            "Epoch 3/12\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.0793 - accuracy: 0.9773\n",
            "Epoch 4/12\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.0530 - accuracy: 0.9850\n",
            "Epoch 5/12\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 0.0399 - accuracy: 0.9876\n",
            "Epoch 6/12\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.0286 - accuracy: 0.9915\n",
            "Epoch 7/12\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.0224 - accuracy: 0.9934\n",
            "Epoch 8/12\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.0160 - accuracy: 0.9956\n",
            "Epoch 9/12\n",
            "375/375 [==============================] - 5s 12ms/step - loss: 0.0131 - accuracy: 0.9962\n",
            "Epoch 10/12\n",
            "375/375 [==============================] - 5s 12ms/step - loss: 0.0099 - accuracy: 0.9974\n",
            "Epoch 11/12\n",
            "375/375 [==============================] - 5s 12ms/step - loss: 0.0075 - accuracy: 0.9982\n",
            "Epoch 12/12\n",
            "375/375 [==============================] - 5s 12ms/step - loss: 0.0061 - accuracy: 0.9985\n",
            "94/94 [==============================] - 1s 5ms/step - loss: 0.0963 - accuracy: 0.9795\n",
            "Epoch 1/12\n",
            "375/375 [==============================] - 5s 12ms/step - loss: 0.4765 - accuracy: 0.8607\n",
            "Epoch 2/12\n",
            "375/375 [==============================] - 5s 12ms/step - loss: 0.1294 - accuracy: 0.9620\n",
            "Epoch 3/12\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.0795 - accuracy: 0.9758\n",
            "Epoch 4/12\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.0541 - accuracy: 0.9842\n",
            "Epoch 5/12\n",
            "375/375 [==============================] - 5s 12ms/step - loss: 0.0403 - accuracy: 0.9879\n",
            "Epoch 6/12\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 0.0290 - accuracy: 0.9916\n",
            "Epoch 7/12\n",
            "375/375 [==============================] - 5s 12ms/step - loss: 0.0207 - accuracy: 0.9938\n",
            "Epoch 8/12\n",
            "375/375 [==============================] - 5s 12ms/step - loss: 0.0160 - accuracy: 0.9955\n",
            "Epoch 9/12\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.0124 - accuracy: 0.9966\n",
            "Epoch 10/12\n",
            "375/375 [==============================] - 5s 12ms/step - loss: 0.0093 - accuracy: 0.9975\n",
            "Epoch 11/12\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.0076 - accuracy: 0.9982\n",
            "Epoch 12/12\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.0056 - accuracy: 0.9987\n",
            "94/94 [==============================] - 1s 5ms/step - loss: 0.0941 - accuracy: 0.9803\n",
            "Epoch 1/12\n",
            "375/375 [==============================] - 5s 12ms/step - loss: 0.4575 - accuracy: 0.8668\n",
            "Epoch 2/12\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.1229 - accuracy: 0.9642\n",
            "Epoch 3/12\n",
            "375/375 [==============================] - 5s 12ms/step - loss: 0.0749 - accuracy: 0.9785\n",
            "Epoch 4/12\n",
            "375/375 [==============================] - 5s 12ms/step - loss: 0.0514 - accuracy: 0.9852\n",
            "Epoch 5/12\n",
            "375/375 [==============================] - 5s 12ms/step - loss: 0.0376 - accuracy: 0.9891\n",
            "Epoch 6/12\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.0306 - accuracy: 0.9913\n",
            "Epoch 7/12\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 0.0207 - accuracy: 0.9943\n",
            "Epoch 8/12\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.0146 - accuracy: 0.9962\n",
            "Epoch 9/12\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.0104 - accuracy: 0.9974\n",
            "Epoch 10/12\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.0084 - accuracy: 0.9980\n",
            "Epoch 11/12\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.0072 - accuracy: 0.9983\n",
            "Epoch 12/12\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.0053 - accuracy: 0.9985\n",
            "94/94 [==============================] - 1s 5ms/step - loss: 0.1084 - accuracy: 0.9754\n",
            "Epoch 1/12\n",
            "375/375 [==============================] - 5s 12ms/step - loss: 0.4867 - accuracy: 0.8579\n",
            "Epoch 2/12\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.1245 - accuracy: 0.9631\n",
            "Epoch 3/12\n",
            "375/375 [==============================] - 5s 12ms/step - loss: 0.0815 - accuracy: 0.9752\n",
            "Epoch 4/12\n",
            "375/375 [==============================] - 5s 12ms/step - loss: 0.0551 - accuracy: 0.9834\n",
            "Epoch 5/12\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.0387 - accuracy: 0.9891\n",
            "Epoch 6/12\n",
            "375/375 [==============================] - 5s 12ms/step - loss: 0.0274 - accuracy: 0.9920\n",
            "Epoch 7/12\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.0232 - accuracy: 0.9933\n",
            "Epoch 8/12\n",
            "375/375 [==============================] - 5s 12ms/step - loss: 0.0166 - accuracy: 0.9952\n",
            "Epoch 9/12\n",
            "375/375 [==============================] - 5s 12ms/step - loss: 0.0122 - accuracy: 0.9970\n",
            "Epoch 10/12\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.0094 - accuracy: 0.9974\n",
            "Epoch 11/12\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.0072 - accuracy: 0.9979\n",
            "Epoch 12/12\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.0054 - accuracy: 0.9986\n",
            "94/94 [==============================] - 1s 5ms/step - loss: 0.1256 - accuracy: 0.9734\n",
            "Epoch 1/12\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.3290 - accuracy: 0.9021\n",
            "Epoch 2/12\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0910 - accuracy: 0.9732\n",
            "Epoch 3/12\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0596 - accuracy: 0.9822\n",
            "Epoch 4/12\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0499 - accuracy: 0.9864\n",
            "Epoch 5/12\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0377 - accuracy: 0.9893\n",
            "Epoch 6/12\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0315 - accuracy: 0.9915\n",
            "Epoch 7/12\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0227 - accuracy: 0.9942\n",
            "Epoch 8/12\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0193 - accuracy: 0.9947\n",
            "Epoch 9/12\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0176 - accuracy: 0.9956\n",
            "Epoch 10/12\n",
            "1875/1875 [==============================] - 16s 8ms/step - loss: 0.0112 - accuracy: 0.9966\n",
            "Epoch 11/12\n",
            "1875/1875 [==============================] - 16s 8ms/step - loss: 0.0101 - accuracy: 0.9975\n",
            "Epoch 12/12\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0086 - accuracy: 0.9978\n",
            "Chosing Neural Network params without HOG data:  {'batch_size': 32, 'epochs': 12}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NN Accuracy with HOG images: 0.9545\n",
            "NN Accuracy without HOG images: 0.979\n",
            "\n",
            "NN Confusion matrix with HOG images:\n",
            "[[ 960    1    3    0    1    3    4    2    1    5]\n",
            " [   1 1120    1    1    2    0    2    6    1    1]\n",
            " [   1    2  983   12    0    0    1   27    4    2]\n",
            " [   0    0   13  976    0    6    0   12    2    1]\n",
            " [   2    3    4    0  949    1    8    1    2   12]\n",
            " [   5    0    1    6    3  860    2    1    7    7]\n",
            " [  13    3    0    0   12    3  924    0    3    0]\n",
            " [   4    2   38   27    0    0    0  946    3    8]\n",
            " [   2    0    6   14    9    5    1    4  901   32]\n",
            " [  10    1    6    1    4   11    4   23   23  926]]\n",
            "NN Classification report with HOG images:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.98      0.97       980\n",
            "           1       0.99      0.99      0.99      1135\n",
            "           2       0.93      0.95      0.94      1032\n",
            "           3       0.94      0.97      0.95      1010\n",
            "           4       0.97      0.97      0.97       982\n",
            "           5       0.97      0.96      0.97       892\n",
            "           6       0.98      0.96      0.97       958\n",
            "           7       0.93      0.92      0.92      1028\n",
            "           8       0.95      0.93      0.94       974\n",
            "           9       0.93      0.92      0.92      1009\n",
            "\n",
            "    accuracy                           0.95     10000\n",
            "   macro avg       0.95      0.95      0.95     10000\n",
            "weighted avg       0.95      0.95      0.95     10000\n",
            "\n",
            "\n",
            "\n",
            "NN Confusion matrix without HOG images:\n",
            "[[ 971    1    0    1    0    1    3    1    1    1]\n",
            " [   0 1128    3    0    0    1    1    1    1    0]\n",
            " [   3    1 1006   12    1    0    2    1    6    0]\n",
            " [   0    0    1 1003    0    0    0    2    1    3]\n",
            " [   4    0    2    1  960    0    4    2    2    7]\n",
            " [   2    0    0   15    2  862    5    1    3    2]\n",
            " [   4    3    0    1    1    2  945    0    2    0]\n",
            " [   1    3    8    3    0    0    0 1007    5    1]\n",
            " [   2    0    3   14    3    4    1    2  941    4]\n",
            " [   1    2    2   14   10    3    0    8    2  967]]\n",
            "NN Classification report without HOG images:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.99       980\n",
            "           1       0.99      0.99      0.99      1135\n",
            "           2       0.98      0.97      0.98      1032\n",
            "           3       0.94      0.99      0.97      1010\n",
            "           4       0.98      0.98      0.98       982\n",
            "           5       0.99      0.97      0.98       892\n",
            "           6       0.98      0.99      0.98       958\n",
            "           7       0.98      0.98      0.98      1028\n",
            "           8       0.98      0.97      0.97       974\n",
            "           9       0.98      0.96      0.97      1009\n",
            "\n",
            "    accuracy                           0.98     10000\n",
            "   macro avg       0.98      0.98      0.98     10000\n",
            "weighted avg       0.98      0.98      0.98     10000\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1Z0PSqD3CbZ"
      },
      "source": [
        "Na podstawie powyższych rezultatów można zauważyć, że Sieć neuronowa działa nieco lepiej dla obrazów bez wykorzystania deskryptora HOG.\n",
        "\n",
        "*   Accuracy dla obrazów z wykorzystaniem deskryptora HOG: 0.9545\n",
        "*   Accuracy dla obrazów bez wykorzystania deskryptora HOG: 0.979\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FD1OE0byo2nq"
      },
      "source": [
        "Accuracy jest znacznie lepsze w przypadku klasyfikatorów SVM oraz Lasu losowego, które wykorzystują deskryptor HOG. Wykorzystanie deskryptora HOG pozwala zredukować ilość informacji tylko do cech niezbędnych do rozpoznania obrazu, co redukuje szansę na błędną klasyfikację obrazu, kiedy obrazy niewiele się różnią. W przypadku Sieci neuronowych wynik jest nieco lepszy dla danych surowych."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1EE8_POTT6_"
      },
      "source": [
        "# **Zadanie 4**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imjyyKLvjM-y"
      },
      "source": [
        "Porównanie wyników działania klasyfikatorów dla poniższych przypadków:\n",
        "\n",
        "1.   Obrazy oryginalne->Deskew-> ReshapeTo1D -> Klasyfikator (SVM, Las losowy, Sieć)\n",
        "2.   Obrazy oryginalne->Deskew-> ReshapeTo1D -> Shuffle -> Klasyfikator (SVM, Las losowy, Sieć)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMRMCQ7hjXPt"
      },
      "source": [
        "**SVM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7XeWEtaTYl1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f7caeed-4d1c-43a0-a0ce-b2eb224a4ff8"
      },
      "source": [
        "parameters = {'kernel':('linear', 'rbf'), 'C': np.linspace(start = 0.001, stop = 2, num = 100)}\n",
        "\n",
        "non_shuffle_model = GridSearchCV(svm.SVC(), parameters, scoring='accuracy', cv=5)\n",
        "non_shuffle_model.fit(train_raw[:600], train_labels[:600])\n",
        "non_shuffle_params = non_shuffle_model.best_params_\n",
        "print(\"Chosing SVM params without shuffled data: \", non_shuffle_params, '\\n')\n",
        "\n",
        "\n",
        "shuffle_model = GridSearchCV(svm.SVC(), parameters, scoring='accuracy', cv=5)\n",
        "shuffle_model.fit(train_shuffle_data[:600], train_labels[:600])\n",
        "shuffle_params = shuffle_model.best_params_\n",
        "print(\"Chosing SVM params with shuffled data: \", shuffle_params, '\\n')\n",
        "\n",
        "pred_labels_non_shuffled = non_shuffle_model.predict(np.asarray(test_raw[:600]))\n",
        "pred_labels = shuffle_model.predict(test_shuffle_data[:600])\n",
        "\n",
        "print(\"SVM Accuracy without shuffled data: {}\".format(accuracy_score(test_labels[:600], pred_labels_non_shuffled)))\n",
        "print(\"SVM Accuracy with shuffled data: {}\\n\".format(accuracy_score(test_labels[:600], pred_labels)))\n",
        "\n",
        "print(\"SVM Confusion matrix without shuffled data:\\n{}\".format(confusion_matrix(test_labels[:600], pred_labels_non_shuffled)))\n",
        "print(\"SVM Classification report without shuffled data:\\n{}\\n\\n\".format(classification_report(test_labels[:600], pred_labels_non_shuffled)))\n",
        "\n",
        "print(\"SVM Confusion matrix with shuffled data:\\n{}\".format(confusion_matrix(test_labels[:600], pred_labels)))\n",
        "print(\"SVM Classification report with shuffled data:\\n{}\\n\\n\".format(classification_report(test_labels[:600], pred_labels)))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Chosing SVM params without shuffled data:  {'C': 1.273090909090909, 'kernel': 'rbf'} \n",
            "\n",
            "Chosing SVM params with shuffled data:  {'C': 0.001, 'kernel': 'rbf'} \n",
            "\n",
            "SVM Accuracy without shuffled data: 0.855\n",
            "SVM Accuracy with shuffled data: 0.12166666666666667\n",
            "\n",
            "SVM Confusion matrix without shuffled data:\n",
            "[[52  0  0  0  0  1  0  0  0  0]\n",
            " [ 0 73  0  0  0  0  0  0  0  0]\n",
            " [ 1  1 57  0  1  0  0  3  1  0]\n",
            " [ 0  0  2 43  0 12  0  2  2  1]\n",
            " [ 0  0  1  0 54  0  2  0  0 10]\n",
            " [ 1  1  1  1  1 47  0  3  0  1]\n",
            " [ 2  0  5  0  1  2 42  0  0  0]\n",
            " [ 0  1  0  0  2  0  0 52  0  2]\n",
            " [ 2  0  3  2  1  2  1  1 37  3]\n",
            " [ 0  0  1  1  0  1  0  3  2 56]]\n",
            "SVM Classification report without shuffled data:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.98      0.94        53\n",
            "           1       0.96      1.00      0.98        73\n",
            "           2       0.81      0.89      0.85        64\n",
            "           3       0.91      0.69      0.79        62\n",
            "           4       0.90      0.81      0.85        67\n",
            "           5       0.72      0.84      0.78        56\n",
            "           6       0.93      0.81      0.87        52\n",
            "           7       0.81      0.91      0.86        57\n",
            "           8       0.88      0.71      0.79        52\n",
            "           9       0.77      0.88      0.82        64\n",
            "\n",
            "    accuracy                           0.85       600\n",
            "   macro avg       0.86      0.85      0.85       600\n",
            "weighted avg       0.86      0.85      0.85       600\n",
            "\n",
            "\n",
            "\n",
            "SVM Confusion matrix with shuffled data:\n",
            "[[ 0 53  0  0  0  0  0  0  0  0]\n",
            " [ 0 73  0  0  0  0  0  0  0  0]\n",
            " [ 0 64  0  0  0  0  0  0  0  0]\n",
            " [ 0 62  0  0  0  0  0  0  0  0]\n",
            " [ 0 67  0  0  0  0  0  0  0  0]\n",
            " [ 0 56  0  0  0  0  0  0  0  0]\n",
            " [ 0 52  0  0  0  0  0  0  0  0]\n",
            " [ 0 57  0  0  0  0  0  0  0  0]\n",
            " [ 0 52  0  0  0  0  0  0  0  0]\n",
            " [ 0 64  0  0  0  0  0  0  0  0]]\n",
            "SVM Classification report with shuffled data:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        53\n",
            "           1       0.12      1.00      0.22        73\n",
            "           2       0.00      0.00      0.00        64\n",
            "           3       0.00      0.00      0.00        62\n",
            "           4       0.00      0.00      0.00        67\n",
            "           5       0.00      0.00      0.00        56\n",
            "           6       0.00      0.00      0.00        52\n",
            "           7       0.00      0.00      0.00        57\n",
            "           8       0.00      0.00      0.00        52\n",
            "           9       0.00      0.00      0.00        64\n",
            "\n",
            "    accuracy                           0.12       600\n",
            "   macro avg       0.01      0.10      0.02       600\n",
            "weighted avg       0.01      0.12      0.03       600\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjeTNxNcjcUd"
      },
      "source": [
        "Na podstawie powyższych rezultatów można zauważyc, że klasyfikator SVM działa lepiej dla obrazów, które nie zostały zmieszane. \n",
        "\n",
        "*   Accuracy dla obrazów wymiesznaych: 0.1217\n",
        "*   Accuracy dla obrazów niewymieszanych: 0.855\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4utV1qejdH-"
      },
      "source": [
        "**Las losowy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_sqEXMmjgj-",
        "outputId": "19734855-476b-4565-8630-7f6530dae90e"
      },
      "source": [
        "parameters_for_cross_validation = {'max_depth':[5, 10, 15], 'n_estimators': [80,100,120], 'max_features': [30, 45, 60]}\n",
        "\n",
        "non_shuffle_model = GridSearchCV(RandomForestClassifier(), parameters_for_cross_validation, cv=5, scoring='accuracy')\n",
        "non_shuffle_model.fit(train_raw[:600], train_labels[:600])\n",
        "non_shuffle_params = non_shuffle_model.best_params_\n",
        "print(\"Chosing RandomForestClassifier params without shuffled data: \", non_shuffle_params, '\\n')\n",
        "\n",
        "\n",
        "shuffle_model = GridSearchCV(RandomForestClassifier(), parameters_for_cross_validation, cv=5, scoring='accuracy')\n",
        "shuffle_model.fit(train_shuffle_data[:600], train_labels[:600])\n",
        "params = shuffle_model.best_params_\n",
        "print(\"Chosing RandomForestClassifier params with shuffled data: \", params, '\\n')\n",
        "\n",
        "pred_labels_non_shuffled = non_shuffle_model.predict(test_raw[:600])\n",
        "pred_labels = shuffle_model.predict(test_shuffle_data[:600])\n",
        "\n",
        "print(\"RFC Accuracy without shuffled data: {}\".format(accuracy_score(test_labels[:600], pred_labels_non_shuffled)))\n",
        "print(\"RFC Accuracy with shuffled data: {}\\n\".format(accuracy_score(test_labels[:600], pred_labels)))\n",
        "\n",
        "print(\"RFC Confusion matrix without shuffled data:\\n{}\".format(confusion_matrix(test_labels[:600], pred_labels_non_shuffled)))\n",
        "print(\"RFC Classification report without shuffled data:\\n{}\\n\\n\".format(classification_report(test_labels[:600], pred_labels_non_shuffled)))\n",
        "\n",
        "print(\"RFC Confusion matrix with shuffled data:\\n{}\".format(confusion_matrix(test_labels[:600], pred_labels)))\n",
        "print(\"RFC Classification report with shuffled data:\\n{}\\n\\n\".format(classification_report(test_labels[:600], pred_labels)))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Chosing RandomForestClassifier params without shuffled data:  {'max_depth': 10, 'max_features': 60, 'n_estimators': 120} \n",
            "\n",
            "Chosing RandomForestClassifier params with shuffled data:  {'max_depth': 5, 'max_features': 45, 'n_estimators': 100} \n",
            "\n",
            "RFC Accuracy without shuffled data: 0.82\n",
            "RFC Accuracy with shuffled data: 0.115\n",
            "\n",
            "RFC Confusion matrix without shuffled data:\n",
            "[[51  0  0  0  0  1  1  0  0  0]\n",
            " [ 0 73  0  0  0  0  0  0  0  0]\n",
            " [ 0  2 55  1  0  1  0  4  1  0]\n",
            " [ 0  1  2 43  0  9  2  2  1  2]\n",
            " [ 1  2  1  0 52  0  2  0  0  9]\n",
            " [ 2  1  1  6  4 39  1  1  0  1]\n",
            " [ 2  0  3  0  4  2 41  0  0  0]\n",
            " [ 0  1  2  0  2  0  0 46  0  6]\n",
            " [ 2  0  2  2  0  1  1  0 35  9]\n",
            " [ 0  1  1  2  1  0  0  1  1 57]]\n",
            "RFC Classification report without shuffled data:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.96      0.92        53\n",
            "           1       0.90      1.00      0.95        73\n",
            "           2       0.82      0.86      0.84        64\n",
            "           3       0.80      0.69      0.74        62\n",
            "           4       0.83      0.78      0.80        67\n",
            "           5       0.74      0.70      0.72        56\n",
            "           6       0.85      0.79      0.82        52\n",
            "           7       0.85      0.81      0.83        57\n",
            "           8       0.92      0.67      0.78        52\n",
            "           9       0.68      0.89      0.77        64\n",
            "\n",
            "    accuracy                           0.82       600\n",
            "   macro avg       0.83      0.81      0.82       600\n",
            "weighted avg       0.83      0.82      0.82       600\n",
            "\n",
            "\n",
            "\n",
            "RFC Confusion matrix with shuffled data:\n",
            "[[ 3 30  8  2  0  1  1  4  0  4]\n",
            " [ 0 38  7  3  3  4  2  9  0  7]\n",
            " [ 5 33 10  1  0  1  3  4  2  5]\n",
            " [ 3 33  8  6  2  0  1  2  0  7]\n",
            " [ 6 36  5  2  2  0  4  3  1  8]\n",
            " [ 2 28  7  4  1  1  1  5  0  7]\n",
            " [ 4 31  6  1  2  0  1  3  0  4]\n",
            " [ 5 30  5  4  2  1  1  3  0  6]\n",
            " [ 3 30  8  3  0  1  2  4  0  1]\n",
            " [10 29 10  4  2  2  0  2  0  5]]\n",
            "RFC Classification report with shuffled data:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.07      0.06      0.06        53\n",
            "           1       0.12      0.52      0.19        73\n",
            "           2       0.14      0.16      0.14        64\n",
            "           3       0.20      0.10      0.13        62\n",
            "           4       0.14      0.03      0.05        67\n",
            "           5       0.09      0.02      0.03        56\n",
            "           6       0.06      0.02      0.03        52\n",
            "           7       0.08      0.05      0.06        57\n",
            "           8       0.00      0.00      0.00        52\n",
            "           9       0.09      0.08      0.08        64\n",
            "\n",
            "    accuracy                           0.12       600\n",
            "   macro avg       0.10      0.10      0.08       600\n",
            "weighted avg       0.10      0.12      0.08       600\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxjscM9QjhUK"
      },
      "source": [
        "Na podstawie powyższych rezultatów można zauważyc, że klasyfikator RFC działa lepiej dla obrazów, które nie zostały zmieszane. \n",
        "\n",
        "*   Accuracy dla obrazów wymiesznaych: 0.115\n",
        "*   Accuracy dla obrazów niewymieszanych: 0.82\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2j8Kp5iqjjfo"
      },
      "source": [
        "**Sieć neuronowa**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7brtWpOXjnMX",
        "outputId": "4a00d1e8-fd48-4330-e27c-9566dd95b8ea"
      },
      "source": [
        "encoded_train_labels = to_categorical(train_labels)\n",
        "encoded_test_labels = to_categorical(test_labels)\n",
        "\n",
        "parameters_for_cross_validation = {'epochs':[1,6,12], 'batch_size':[32,64,128]}\n",
        "non_shuffle_network = KerasClassifier(create_model)\n",
        "non_shuffle_model = GridSearchCV(estimator=non_shuffle_network, param_grid=parameters_for_cross_validation, cv=5)\n",
        "non_shuffle_model.fit(train_raw[:600], encoded_train_labels[:600])\n",
        "non_shuffle_params = non_shuffle_model.best_params_\n",
        "print(\"Chosing Neural Network params with HOG data: \", non_shuffle_params)\n",
        "\n",
        "shuffle_network = KerasClassifier(build_fn=create_model)\n",
        "shuffle_model = GridSearchCV(estimator=shuffle_network, param_grid=parameters_for_cross_validation, cv=5)\n",
        "shuffle_model.fit(train_shuffle_data[:600], encoded_train_labels[:600])\n",
        "shuffle_params = shuffle_model.best_params_\n",
        "print(\"Chosing Neural Network params without HOG data: \", shuffle_params)\n",
        "\n",
        "\n",
        "pred_labels_non_shuffled = non_shuffle_model.predict(test_raw[:600])\n",
        "pred_labels = shuffle_model.predict(test_shuffle_data[:600])\n",
        "\n",
        "print(\"NN Accuracy without shuffled data: {}\".format(accuracy_score(test_labels[:600], pred_labels_non_shuffled)))\n",
        "print(\"NN Accuracy with shuffled data: {}\\n\".format(accuracy_score(test_labels[:600], pred_labels)))\n",
        "\n",
        "print(\"NN Confusion matrix without shuffled data:\\n{}\".format(confusion_matrix(test_labels[:600], pred_labels_non_shuffled)))\n",
        "print(\"NN Classification report without shuffled data:\\n{}\\n\\n\".format(classification_report(test_labels[:600], pred_labels_non_shuffled)))\n",
        "\n",
        "print(\"NN Confusion matrix with shuffled data:\\n{}\".format(confusion_matrix(test_labels[:600], pred_labels)))\n",
        "print(\"NN Classification report with shuffled data:\\n{}\\n\\n\".format(classification_report(test_labels[:600], pred_labels)))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15/15 [==============================] - 1s 7ms/step - loss: 125.7921 - accuracy: 0.3848\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 17.1635 - accuracy: 0.7500\n",
            "15/15 [==============================] - 1s 7ms/step - loss: 145.8134 - accuracy: 0.3567\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 14.9604 - accuracy: 0.7500\n",
            "15/15 [==============================] - 1s 7ms/step - loss: 96.9405 - accuracy: 0.4297\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 10.3872 - accuracy: 0.7917\n",
            "15/15 [==============================] - 1s 7ms/step - loss: 100.9080 - accuracy: 0.4094\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 15.8772 - accuracy: 0.8167\n",
            "15/15 [==============================] - 1s 7ms/step - loss: 136.0266 - accuracy: 0.3590\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 38.3126 - accuracy: 0.6000\n",
            "Epoch 1/6\n",
            "15/15 [==============================] - 1s 8ms/step - loss: 153.0049 - accuracy: 0.3324\n",
            "Epoch 2/6\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 4.9072 - accuracy: 0.8924\n",
            "Epoch 3/6\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 5.8228 - accuracy: 0.8927\n",
            "Epoch 4/6\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 3.7661 - accuracy: 0.9290\n",
            "Epoch 5/6\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.9211 - accuracy: 0.9367\n",
            "Epoch 6/6\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.1299 - accuracy: 0.9570\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 17.1080 - accuracy: 0.8500\n",
            "Epoch 1/6\n",
            "15/15 [==============================] - 1s 7ms/step - loss: 127.9191 - accuracy: 0.3794\n",
            "Epoch 2/6\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 10.3281 - accuracy: 0.8285\n",
            "Epoch 3/6\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 4.5601 - accuracy: 0.8957\n",
            "Epoch 4/6\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 2.4183 - accuracy: 0.9438\n",
            "Epoch 5/6\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.3328 - accuracy: 0.9614\n",
            "Epoch 6/6\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.9679 - accuracy: 0.9452\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 16.7218 - accuracy: 0.8083\n",
            "Epoch 1/6\n",
            "15/15 [==============================] - 1s 7ms/step - loss: 128.0948 - accuracy: 0.3837\n",
            "Epoch 2/6\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 7.2058 - accuracy: 0.8748\n",
            "Epoch 3/6\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 8.5292 - accuracy: 0.8671\n",
            "Epoch 4/6\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 4.2665 - accuracy: 0.8909\n",
            "Epoch 5/6\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.5351 - accuracy: 0.9574\n",
            "Epoch 6/6\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.5421 - accuracy: 0.9426\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 13.9663 - accuracy: 0.8250\n",
            "Epoch 1/6\n",
            "15/15 [==============================] - 1s 7ms/step - loss: 125.7720 - accuracy: 0.3715\n",
            "Epoch 2/6\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 5.4993 - accuracy: 0.8764\n",
            "Epoch 3/6\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 3.2556 - accuracy: 0.9200\n",
            "Epoch 4/6\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.2799 - accuracy: 0.9444\n",
            "Epoch 5/6\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.3862 - accuracy: 0.9662\n",
            "Epoch 6/6\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.6373 - accuracy: 0.9520\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 20.3896 - accuracy: 0.8167\n",
            "Epoch 1/6\n",
            "15/15 [==============================] - 1s 8ms/step - loss: 116.6154 - accuracy: 0.4085\n",
            "Epoch 2/6\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 8.1978 - accuracy: 0.8818\n",
            "Epoch 3/6\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 3.7870 - accuracy: 0.9150\n",
            "Epoch 4/6\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 3.9636 - accuracy: 0.9107\n",
            "Epoch 5/6\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.1577 - accuracy: 0.9662\n",
            "Epoch 6/6\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.1141 - accuracy: 0.9811\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 23.9483 - accuracy: 0.6917\n",
            "Epoch 1/12\n",
            "15/15 [==============================] - 1s 7ms/step - loss: 107.7670 - accuracy: 0.3986\n",
            "Epoch 2/12\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 9.0360 - accuracy: 0.8473\n",
            "Epoch 3/12\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.3721 - accuracy: 0.9459\n",
            "Epoch 4/12\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.8472 - accuracy: 0.9491\n",
            "Epoch 5/12\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.2174 - accuracy: 0.9438\n",
            "Epoch 6/12\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.2502 - accuracy: 0.9428\n",
            "Epoch 7/12\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.7881 - accuracy: 0.9813\n",
            "Epoch 8/12\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.4876 - accuracy: 0.9926\n",
            "Epoch 9/12\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.8970 - accuracy: 0.9761\n",
            "Epoch 10/12\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.6567 - accuracy: 0.9645\n",
            "Epoch 11/12\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.5580 - accuracy: 0.9658\n",
            "Epoch 12/12\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2296 - accuracy: 0.9921\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 13.6841 - accuracy: 0.8667\n",
            "Epoch 1/12\n",
            "15/15 [==============================] - 1s 8ms/step - loss: 126.3299 - accuracy: 0.4054\n",
            "Epoch 2/12\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 6.0408 - accuracy: 0.9082\n",
            "Epoch 3/12\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 3.0047 - accuracy: 0.9162\n",
            "Epoch 4/12\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.7623 - accuracy: 0.9193\n",
            "Epoch 5/12\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.4361 - accuracy: 0.9377\n",
            "Epoch 6/12\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 3.0433 - accuracy: 0.9151\n",
            "Epoch 7/12\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.7152 - accuracy: 0.9761\n",
            "Epoch 8/12\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3283 - accuracy: 0.9921\n",
            "Epoch 9/12\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.4540 - accuracy: 0.9710\n",
            "Epoch 10/12\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.2327 - accuracy: 0.9731\n",
            "Epoch 11/12\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3133 - accuracy: 0.9834\n",
            "Epoch 12/12\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 4.3753 - accuracy: 0.9395\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 19.6212 - accuracy: 0.8333\n",
            "Epoch 1/12\n",
            "15/15 [==============================] - 1s 7ms/step - loss: 111.7709 - accuracy: 0.3888\n",
            "Epoch 2/12\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 11.4347 - accuracy: 0.8434\n",
            "Epoch 3/12\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 4.2121 - accuracy: 0.9146\n",
            "Epoch 4/12\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 3.9274 - accuracy: 0.9338\n",
            "Epoch 5/12\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.7894 - accuracy: 0.9549\n",
            "Epoch 6/12\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.6408 - accuracy: 0.9825\n",
            "Epoch 7/12\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.5280 - accuracy: 0.9660\n",
            "Epoch 8/12\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.6109 - accuracy: 0.9862\n",
            "Epoch 9/12\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.1512 - accuracy: 0.9718\n",
            "Epoch 10/12\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.4378 - accuracy: 0.9832\n",
            "Epoch 11/12\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.7030 - accuracy: 0.9729\n",
            "Epoch 12/12\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.3846 - accuracy: 0.9839\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 24.7254 - accuracy: 0.7750\n",
            "Epoch 1/12\n",
            "15/15 [==============================] - 1s 8ms/step - loss: 109.3014 - accuracy: 0.4099\n",
            "Epoch 2/12\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 5.3469 - accuracy: 0.9085\n",
            "Epoch 3/12\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 3.1470 - accuracy: 0.9205\n",
            "Epoch 4/12\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 2.9774 - accuracy: 0.9390\n",
            "Epoch 5/12\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.1456 - accuracy: 0.9532\n",
            "Epoch 6/12\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 4.2861 - accuracy: 0.9191\n",
            "Epoch 7/12\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0847 - accuracy: 0.9978\n",
            "Epoch 8/12\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.1005 - accuracy: 0.9629\n",
            "Epoch 9/12\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.6563 - accuracy: 0.9859\n",
            "Epoch 10/12\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.6366 - accuracy: 0.9732\n",
            "Epoch 11/12\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.5703 - accuracy: 0.9515\n",
            "Epoch 12/12\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1707 - accuracy: 0.9894\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 14.2858 - accuracy: 0.8333\n",
            "Epoch 1/12\n",
            "15/15 [==============================] - 1s 8ms/step - loss: 111.9595 - accuracy: 0.4120\n",
            "Epoch 2/12\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 7.9372 - accuracy: 0.8618\n",
            "Epoch 3/12\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 6.6477 - accuracy: 0.8617\n",
            "Epoch 4/12\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.7350 - accuracy: 0.9691\n",
            "Epoch 5/12\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 3.2985 - accuracy: 0.9365\n",
            "Epoch 6/12\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 3.4181 - accuracy: 0.9278\n",
            "Epoch 7/12\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0576 - accuracy: 0.9938\n",
            "Epoch 8/12\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.7336 - accuracy: 0.9820\n",
            "Epoch 9/12\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3664 - accuracy: 0.9906\n",
            "Epoch 10/12\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.4880 - accuracy: 0.9735\n",
            "Epoch 11/12\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.5884 - accuracy: 0.9880\n",
            "Epoch 12/12\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.4649 - accuracy: 0.9679\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 37.7106 - accuracy: 0.6917\n",
            "8/8 [==============================] - 1s 8ms/step - loss: 154.4944 - accuracy: 0.2677\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 11.2605 - accuracy: 0.8167\n",
            "8/8 [==============================] - 1s 8ms/step - loss: 120.0717 - accuracy: 0.3706\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 26.2005 - accuracy: 0.7167\n",
            "8/8 [==============================] - 1s 9ms/step - loss: 118.6277 - accuracy: 0.3975\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd9c25ec560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 17.3633 - accuracy: 0.7000\n",
            "8/8 [==============================] - 1s 8ms/step - loss: 145.2520 - accuracy: 0.2788\n",
            "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd9bd786e60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 14.4984 - accuracy: 0.7667\n",
            "8/8 [==============================] - 1s 8ms/step - loss: 133.4646 - accuracy: 0.3506\n",
            "WARNING:tensorflow:6 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd9b4b387a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 49.7087 - accuracy: 0.6250\n",
            "Epoch 1/6\n",
            "8/8 [==============================] - 1s 8ms/step - loss: 132.1493 - accuracy: 0.2380\n",
            "Epoch 2/6\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 14.2869 - accuracy: 0.7952\n",
            "Epoch 3/6\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 6.4363 - accuracy: 0.9086\n",
            "Epoch 4/6\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.8193 - accuracy: 0.9767\n",
            "Epoch 5/6\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.2501 - accuracy: 0.9137\n",
            "Epoch 6/6\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3.7033 - accuracy: 0.9129\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd9c7925290> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 12.7274 - accuracy: 0.8833\n",
            "Epoch 1/6\n",
            "8/8 [==============================] - 1s 10ms/step - loss: 130.3129 - accuracy: 0.3771\n",
            "Epoch 2/6\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 11.8491 - accuracy: 0.8418\n",
            "Epoch 3/6\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 8.5421 - accuracy: 0.8479\n",
            "Epoch 4/6\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.9965 - accuracy: 0.9665\n",
            "Epoch 5/6\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3.7929 - accuracy: 0.9359\n",
            "Epoch 6/6\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3.8982 - accuracy: 0.9409\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd9c771acb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 21.8380 - accuracy: 0.7833\n",
            "Epoch 1/6\n",
            "8/8 [==============================] - 1s 8ms/step - loss: 154.3574 - accuracy: 0.2514\n",
            "Epoch 2/6\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 10.9123 - accuracy: 0.8277\n",
            "Epoch 3/6\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3.8034 - accuracy: 0.9104\n",
            "Epoch 4/6\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.8543 - accuracy: 0.9409\n",
            "Epoch 5/6\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3.0343 - accuracy: 0.9368\n",
            "Epoch 6/6\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1182 - accuracy: 0.9850\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd9c788ce60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 12.7075 - accuracy: 0.7917\n",
            "Epoch 1/6\n",
            "8/8 [==============================] - 1s 10ms/step - loss: 154.3927 - accuracy: 0.3139\n",
            "Epoch 2/6\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 17.2473 - accuracy: 0.8288\n",
            "Epoch 3/6\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 5.3548 - accuracy: 0.8921\n",
            "Epoch 4/6\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0667 - accuracy: 0.8921\n",
            "Epoch 5/6\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1.1666 - accuracy: 0.9668\n",
            "Epoch 6/6\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.5225 - accuracy: 0.9006\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd9c784ff80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 12.2011 - accuracy: 0.8167\n",
            "Epoch 1/6\n",
            "8/8 [==============================] - 1s 8ms/step - loss: 156.2923 - accuracy: 0.2679\n",
            "Epoch 2/6\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 12.0524 - accuracy: 0.8322\n",
            "Epoch 3/6\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3.4901 - accuracy: 0.9141\n",
            "Epoch 4/6\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 2.3184 - accuracy: 0.9308\n",
            "Epoch 5/6\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 17.4831 - accuracy: 0.8673\n",
            "Epoch 6/6\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1147 - accuracy: 0.9940\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd9c48d3c20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 23.3432 - accuracy: 0.6917\n",
            "Epoch 1/12\n",
            "8/8 [==============================] - 1s 8ms/step - loss: 138.2611 - accuracy: 0.3040\n",
            "Epoch 2/12\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 10.6158 - accuracy: 0.8195\n",
            "Epoch 3/12\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 4.0159 - accuracy: 0.9203\n",
            "Epoch 4/12\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2.2660 - accuracy: 0.9182\n",
            "Epoch 5/12\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 2.3247 - accuracy: 0.9407\n",
            "Epoch 6/12\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1.6458 - accuracy: 0.9496\n",
            "Epoch 7/12\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.5185 - accuracy: 0.9519\n",
            "Epoch 8/12\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 2.8611 - accuracy: 0.9283\n",
            "Epoch 9/12\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4702 - accuracy: 0.9769\n",
            "Epoch 10/12\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1.6935 - accuracy: 0.9654\n",
            "Epoch 11/12\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 3.2136 - accuracy: 0.9536\n",
            "Epoch 12/12\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.5055 - accuracy: 0.9840\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd9cc1efe60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 14.6706 - accuracy: 0.8083\n",
            "Epoch 1/12\n",
            "8/8 [==============================] - 1s 9ms/step - loss: 143.9514 - accuracy: 0.3195\n",
            "Epoch 2/12\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 13.3350 - accuracy: 0.7857\n",
            "Epoch 3/12\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2.8752 - accuracy: 0.9430\n",
            "Epoch 4/12\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 9.9317 - accuracy: 0.8863\n",
            "Epoch 5/12\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1.3729 - accuracy: 0.9562\n",
            "Epoch 6/12\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1.2725 - accuracy: 0.9602\n",
            "Epoch 7/12\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.2143 - accuracy: 0.9880\n",
            "Epoch 8/12\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.7527 - accuracy: 0.9890\n",
            "Epoch 9/12\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 11.4996 - accuracy: 0.8781\n",
            "Epoch 10/12\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4301 - accuracy: 0.9897\n",
            "Epoch 11/12\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.4743 - accuracy: 0.9649\n",
            "Epoch 12/12\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.3433 - accuracy: 0.9644\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd9bd68ccb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 16.9918 - accuracy: 0.8250\n",
            "Epoch 1/12\n",
            "8/8 [==============================] - 1s 9ms/step - loss: 167.4064 - accuracy: 0.2971\n",
            "Epoch 2/12\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 17.6599 - accuracy: 0.7853\n",
            "Epoch 3/12\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3.2929 - accuracy: 0.9276\n",
            "Epoch 4/12\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 2.9470 - accuracy: 0.9042\n",
            "Epoch 5/12\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.1304 - accuracy: 0.9600\n",
            "Epoch 6/12\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.2796 - accuracy: 0.9826\n",
            "Epoch 7/12\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 15.5691 - accuracy: 0.8593\n",
            "Epoch 8/12\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.9860 - accuracy: 0.9849\n",
            "Epoch 9/12\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3.5553 - accuracy: 0.9368\n",
            "Epoch 10/12\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.6970 - accuracy: 0.9671\n",
            "Epoch 11/12\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.3935 - accuracy: 0.9255\n",
            "Epoch 12/12\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.2883 - accuracy: 0.9889\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd9c3fcba70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 13.4987 - accuracy: 0.8500\n",
            "Epoch 1/12\n",
            "8/8 [==============================] - 1s 11ms/step - loss: 116.6615 - accuracy: 0.3486\n",
            "Epoch 2/12\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 9.2706 - accuracy: 0.8411\n",
            "Epoch 3/12\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.5460 - accuracy: 0.8876\n",
            "Epoch 4/12\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.9454 - accuracy: 0.9504\n",
            "Epoch 5/12\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6036 - accuracy: 0.9717\n",
            "Epoch 6/12\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 2.0465 - accuracy: 0.9268\n",
            "Epoch 7/12\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 11.4930 - accuracy: 0.8564\n",
            "Epoch 8/12\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.2017 - accuracy: 0.9956\n",
            "Epoch 9/12\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0116 - accuracy: 0.9987\n",
            "Epoch 10/12\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0596 - accuracy: 0.9979\n",
            "Epoch 11/12\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 5.1634 - accuracy: 0.9235\n",
            "Epoch 12/12\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6087 - accuracy: 0.9801\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd9bf9d2b90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 11.6724 - accuracy: 0.8667\n",
            "Epoch 1/12\n",
            "8/8 [==============================] - 1s 10ms/step - loss: 200.0948 - accuracy: 0.2298\n",
            "Epoch 2/12\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 9.3770 - accuracy: 0.8709\n",
            "Epoch 3/12\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 7.2641 - accuracy: 0.8571\n",
            "Epoch 4/12\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1.8418 - accuracy: 0.9452\n",
            "Epoch 5/12\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.1659 - accuracy: 0.9667\n",
            "Epoch 6/12\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.2649 - accuracy: 0.9620\n",
            "Epoch 7/12\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 8.2039 - accuracy: 0.8825\n",
            "Epoch 8/12\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6775 - accuracy: 0.9729\n",
            "Epoch 9/12\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0045 - accuracy: 1.0000\n",
            "Epoch 10/12\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 8.4868e-07 - accuracy: 1.0000\n",
            "Epoch 11/12\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 7.7342e-07 - accuracy: 1.0000\n",
            "Epoch 12/12\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 5.9912e-07 - accuracy: 1.0000\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd9c6335a70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 26.8950 - accuracy: 0.7417\n",
            "4/4 [==============================] - 1s 12ms/step - loss: 180.5810 - accuracy: 0.2115\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd9c79a2320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 76.7256 - accuracy: 0.5917\n",
            "4/4 [==============================] - 1s 12ms/step - loss: 156.4430 - accuracy: 0.1803\n",
            "WARNING:tensorflow:7 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd9c7635b00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 121ms/step - loss: 123.0914 - accuracy: 0.3750\n",
            "4/4 [==============================] - 1s 12ms/step - loss: 163.4470 - accuracy: 0.2404\n",
            "WARNING:tensorflow:7 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd9b4afd440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 121ms/step - loss: 84.9659 - accuracy: 0.5250\n",
            "4/4 [==============================] - 1s 11ms/step - loss: 173.8560 - accuracy: 0.1938\n",
            "WARNING:tensorflow:8 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd9be88a3b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 77.8256 - accuracy: 0.6250\n",
            "4/4 [==============================] - 1s 11ms/step - loss: 147.4977 - accuracy: 0.2136\n",
            "WARNING:tensorflow:8 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd9bbd28170> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 124ms/step - loss: 70.0151 - accuracy: 0.4917\n",
            "Epoch 1/6\n",
            "4/4 [==============================] - 1s 12ms/step - loss: 200.7467 - accuracy: 0.2154\n",
            "Epoch 2/6\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 41.8957 - accuracy: 0.6069\n",
            "Epoch 3/6\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 8.4633 - accuracy: 0.8768\n",
            "Epoch 4/6\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.6822 - accuracy: 0.9565\n",
            "Epoch 5/6\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3561 - accuracy: 0.9773\n",
            "Epoch 6/6\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1029 - accuracy: 0.9920\n",
            "WARNING:tensorflow:9 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd9c3fe1dd0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 126ms/step - loss: 12.0528 - accuracy: 0.8000\n",
            "Epoch 1/6\n",
            "4/4 [==============================] - 1s 12ms/step - loss: 138.9301 - accuracy: 0.2038\n",
            "Epoch 2/6\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 46.3290 - accuracy: 0.7166\n",
            "Epoch 3/6\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 4.5686 - accuracy: 0.9174\n",
            "Epoch 4/6\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 2.0408 - accuracy: 0.9547\n",
            "Epoch 5/6\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4642 - accuracy: 0.9858\n",
            "Epoch 6/6\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 2.0382 - accuracy: 0.9282\n",
            "WARNING:tensorflow:9 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd9cc497c20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 13.7990 - accuracy: 0.8000\n",
            "Epoch 1/6\n",
            "4/4 [==============================] - 1s 13ms/step - loss: 156.0558 - accuracy: 0.2133\n",
            "Epoch 2/6\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 32.1460 - accuracy: 0.6832\n",
            "Epoch 3/6\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 6.4630 - accuracy: 0.8872\n",
            "Epoch 4/6\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 16.3920 - accuracy: 0.8366\n",
            "Epoch 5/6\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3784 - accuracy: 0.9783\n",
            "Epoch 6/6\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2495 - accuracy: 0.9891\n",
            "WARNING:tensorflow:10 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd9c780e290> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 11.7376 - accuracy: 0.8500\n",
            "Epoch 1/6\n",
            "4/4 [==============================] - 1s 14ms/step - loss: 179.5135 - accuracy: 0.2385\n",
            "Epoch 2/6\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 39.1518 - accuracy: 0.6594\n",
            "Epoch 3/6\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 4.6792 - accuracy: 0.8998\n",
            "Epoch 4/6\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.9016 - accuracy: 0.9453\n",
            "Epoch 5/6\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4903 - accuracy: 0.9576\n",
            "Epoch 6/6\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1416 - accuracy: 0.9883\n",
            "WARNING:tensorflow:10 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd9bf9cb5f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 9.8571 - accuracy: 0.8083\n",
            "Epoch 1/6\n",
            "4/4 [==============================] - 1s 12ms/step - loss: 187.8930 - accuracy: 0.2218\n",
            "Epoch 2/6\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 67.5697 - accuracy: 0.6014\n",
            "Epoch 3/6\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 6.1146 - accuracy: 0.8790\n",
            "Epoch 4/6\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 4.2681 - accuracy: 0.8917\n",
            "Epoch 5/6\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.9934 - accuracy: 0.9581\n",
            "Epoch 6/6\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1554 - accuracy: 0.9962\n",
            "WARNING:tensorflow:11 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd9c1c7af80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 18.5423 - accuracy: 0.7333\n",
            "Epoch 1/12\n",
            "4/4 [==============================] - 1s 12ms/step - loss: 168.2923 - accuracy: 0.1771\n",
            "Epoch 2/12\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 61.5065 - accuracy: 0.6048\n",
            "Epoch 3/12\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 7.5377 - accuracy: 0.8745\n",
            "Epoch 4/12\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 2.4157 - accuracy: 0.9304\n",
            "Epoch 5/12\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5156 - accuracy: 0.9735\n",
            "Epoch 6/12\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2639 - accuracy: 0.9773\n",
            "Epoch 7/12\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3327 - accuracy: 0.9698\n",
            "Epoch 8/12\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4141 - accuracy: 0.9732\n",
            "Epoch 9/12\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3665 - accuracy: 0.9803\n",
            "Epoch 10/12\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 2.1853 - accuracy: 0.9394\n",
            "Epoch 11/12\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 12.2573 - accuracy: 0.8566\n",
            "Epoch 12/12\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.8388 - accuracy: 0.9837\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd9c63188c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 130ms/step - loss: 13.0805 - accuracy: 0.8250\n",
            "Epoch 1/12\n",
            "4/4 [==============================] - 1s 14ms/step - loss: 156.6573 - accuracy: 0.2593\n",
            "Epoch 2/12\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 31.7292 - accuracy: 0.7176\n",
            "Epoch 3/12\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 5.3708 - accuracy: 0.9134\n",
            "Epoch 4/12\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.9966 - accuracy: 0.9332\n",
            "Epoch 5/12\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5447 - accuracy: 0.9818\n",
            "Epoch 6/12\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.3317 - accuracy: 0.9560\n",
            "Epoch 7/12\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1216 - accuracy: 0.9904\n",
            "Epoch 8/12\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0764 - accuracy: 0.9949\n",
            "Epoch 9/12\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0722 - accuracy: 0.9963\n",
            "Epoch 10/12\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 4.5994e-08 - accuracy: 1.0000\n",
            "Epoch 11/12\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 1.8338e-07 - accuracy: 1.0000\n",
            "Epoch 12/12\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 9.8768e-08 - accuracy: 1.0000\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd9c7802560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 10.0265 - accuracy: 0.8250\n",
            "Epoch 1/12\n",
            "4/4 [==============================] - 1s 12ms/step - loss: 158.0665 - accuracy: 0.2277\n",
            "Epoch 2/12\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 82.3600 - accuracy: 0.5483\n",
            "Epoch 3/12\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 5.4672 - accuracy: 0.8988\n",
            "Epoch 4/12\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 2.8076 - accuracy: 0.9117\n",
            "Epoch 5/12\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3960 - accuracy: 0.9735\n",
            "Epoch 6/12\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1710 - accuracy: 0.9832\n",
            "Epoch 7/12\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1377 - accuracy: 0.9920\n",
            "Epoch 8/12\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0147 - accuracy: 0.9986\n",
            "Epoch 9/12\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 8.3228e-08 - accuracy: 1.0000\n",
            "Epoch 10/12\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 1.9764e-07 - accuracy: 1.0000\n",
            "Epoch 11/12\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 9.0201e-08 - accuracy: 1.0000\n",
            "Epoch 12/12\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 1.0088e-07 - accuracy: 1.0000\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd9c788ab90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 12.3537 - accuracy: 0.7750\n",
            "Epoch 1/12\n",
            "4/4 [==============================] - 1s 13ms/step - loss: 177.4411 - accuracy: 0.2270\n",
            "Epoch 2/12\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 52.3531 - accuracy: 0.6464\n",
            "Epoch 3/12\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 8.7576 - accuracy: 0.8262\n",
            "Epoch 4/12\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.7324 - accuracy: 0.9447\n",
            "Epoch 5/12\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6854 - accuracy: 0.9532\n",
            "Epoch 6/12\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1472 - accuracy: 0.9875\n",
            "Epoch 7/12\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0308 - accuracy: 0.9970\n",
            "Epoch 8/12\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0274 - accuracy: 0.9963\n",
            "Epoch 9/12\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 2.2848e-06 - accuracy: 1.0000\n",
            "Epoch 10/12\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 4.3104e-06 - accuracy: 1.0000\n",
            "Epoch 11/12\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 3.4269e-06 - accuracy: 1.0000\n",
            "Epoch 12/12\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 1.3044e-06 - accuracy: 1.0000\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd9be8f57a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 13.0451 - accuracy: 0.8250\n",
            "Epoch 1/12\n",
            "4/4 [==============================] - 1s 13ms/step - loss: 177.3611 - accuracy: 0.2377\n",
            "Epoch 2/12\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 36.1659 - accuracy: 0.7177\n",
            "Epoch 3/12\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 4.6633 - accuracy: 0.9120\n",
            "Epoch 4/12\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 1.0091 - accuracy: 0.9719\n",
            "Epoch 5/12\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3266 - accuracy: 0.9707\n",
            "Epoch 6/12\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1799 - accuracy: 0.9803\n",
            "Epoch 7/12\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1268 - accuracy: 0.9926\n",
            "Epoch 8/12\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0092 - accuracy: 0.9986\n",
            "Epoch 9/12\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 3.9260e-04 - accuracy: 1.0000\n",
            "Epoch 10/12\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 2.8749e-06 - accuracy: 1.0000\n",
            "Epoch 11/12\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 3.2344e-06 - accuracy: 1.0000\n",
            "Epoch 12/12\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 2.3328e-06 - accuracy: 1.0000\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd9c7752cb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 21.4056 - accuracy: 0.7167\n",
            "Epoch 1/12\n",
            "10/10 [==============================] - 1s 8ms/step - loss: 132.8284 - accuracy: 0.3396\n",
            "Epoch 2/12\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 9.4671 - accuracy: 0.8215\n",
            "Epoch 3/12\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 3.0705 - accuracy: 0.9240\n",
            "Epoch 4/12\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 3.3735 - accuracy: 0.9273\n",
            "Epoch 5/12\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 2.1836 - accuracy: 0.9555\n",
            "Epoch 6/12\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.0737 - accuracy: 0.9780\n",
            "Epoch 7/12\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 3.1937 - accuracy: 0.9477\n",
            "Epoch 8/12\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8809 - accuracy: 0.9578\n",
            "Epoch 9/12\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.7803 - accuracy: 0.9813\n",
            "Epoch 10/12\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5792e-04 - accuracy: 1.0000\n",
            "Epoch 11/12\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.1153 - accuracy: 0.9969\n",
            "Epoch 12/12\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3924 - accuracy: 0.9881\n",
            "Chosing Neural Network params with HOG data:  {'batch_size': 64, 'epochs': 12}\n",
            "15/15 [==============================] - 1s 8ms/step - loss: 212.1836 - accuracy: 0.1174\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd9cc3028c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 86.8486 - accuracy: 0.1000\n",
            "15/15 [==============================] - 1s 8ms/step - loss: 172.7157 - accuracy: 0.0930\n",
            "WARNING:tensorflow:8 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd9cc1efa70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 78.5400 - accuracy: 0.1083\n",
            "15/15 [==============================] - 1s 8ms/step - loss: 202.4834 - accuracy: 0.1010\n",
            "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd9bf9c7950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 83.5480 - accuracy: 0.1083\n",
            "15/15 [==============================] - 1s 8ms/step - loss: 241.3313 - accuracy: 0.0548\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 96.3910 - accuracy: 0.0917\n",
            "15/15 [==============================] - 1s 9ms/step - loss: 177.7117 - accuracy: 0.0852\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 86.7262 - accuracy: 0.1417\n",
            "Epoch 1/6\n",
            "15/15 [==============================] - 1s 10ms/step - loss: 204.9466 - accuracy: 0.0960\n",
            "Epoch 2/6\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 49.2576 - accuracy: 0.2813\n",
            "Epoch 3/6\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 24.2286 - accuracy: 0.4111\n",
            "Epoch 4/6\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 17.2990 - accuracy: 0.5009\n",
            "Epoch 5/6\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 9.8834 - accuracy: 0.6580\n",
            "Epoch 6/6\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 10.2623 - accuracy: 0.6339\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 64.7791 - accuracy: 0.0750\n",
            "Epoch 1/6\n",
            "15/15 [==============================] - 1s 10ms/step - loss: 228.8639 - accuracy: 0.0896\n",
            "Epoch 2/6\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 44.9953 - accuracy: 0.2678\n",
            "Epoch 3/6\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 25.8651 - accuracy: 0.3928\n",
            "Epoch 4/6\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 16.5145 - accuracy: 0.5144\n",
            "Epoch 5/6\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 12.2647 - accuracy: 0.5596\n",
            "Epoch 6/6\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 7.4099 - accuracy: 0.7309\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 45.1525 - accuracy: 0.1583\n",
            "Epoch 1/6\n",
            "15/15 [==============================] - 1s 8ms/step - loss: 211.6140 - accuracy: 0.1005\n",
            "Epoch 2/6\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 50.5985 - accuracy: 0.2505\n",
            "Epoch 3/6\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 27.3623 - accuracy: 0.4386\n",
            "Epoch 4/6\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 20.2924 - accuracy: 0.4775\n",
            "Epoch 5/6\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 14.5839 - accuracy: 0.5745\n",
            "Epoch 6/6\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 7.4353 - accuracy: 0.7248\n",
            "4/4 [==============================] - 1s 5ms/step - loss: 60.5075 - accuracy: 0.1333\n",
            "Epoch 1/6\n",
            "15/15 [==============================] - 1s 10ms/step - loss: 211.2123 - accuracy: 0.0965\n",
            "Epoch 2/6\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 47.6898 - accuracy: 0.2689\n",
            "Epoch 3/6\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 32.6717 - accuracy: 0.3396\n",
            "Epoch 4/6\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 12.3464 - accuracy: 0.6008\n",
            "Epoch 5/6\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 14.4932 - accuracy: 0.6113\n",
            "Epoch 6/6\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 10.9262 - accuracy: 0.6520\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 61.7171 - accuracy: 0.1583\n",
            "Epoch 1/6\n",
            "15/15 [==============================] - 1s 8ms/step - loss: 230.9235 - accuracy: 0.1555\n",
            "Epoch 2/6\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 49.6742 - accuracy: 0.2305\n",
            "Epoch 3/6\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 24.4627 - accuracy: 0.4117\n",
            "Epoch 4/6\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 13.0255 - accuracy: 0.5807\n",
            "Epoch 5/6\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 13.6098 - accuracy: 0.6065\n",
            "Epoch 6/6\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 5.5070 - accuracy: 0.7649\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 58.0746 - accuracy: 0.1417\n",
            "Epoch 1/12\n",
            "15/15 [==============================] - 1s 9ms/step - loss: 194.2902 - accuracy: 0.1265\n",
            "Epoch 2/12\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 45.1672 - accuracy: 0.2938\n",
            "Epoch 3/12\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 25.7250 - accuracy: 0.4335\n",
            "Epoch 4/12\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 19.2818 - accuracy: 0.4873\n",
            "Epoch 5/12\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 14.8762 - accuracy: 0.5912\n",
            "Epoch 6/12\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 11.6833 - accuracy: 0.6611\n",
            "Epoch 7/12\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 5.9740 - accuracy: 0.7749\n",
            "Epoch 8/12\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 8.0128 - accuracy: 0.7076\n",
            "Epoch 9/12\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 3.2637 - accuracy: 0.8771\n",
            "Epoch 10/12\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 5.3727 - accuracy: 0.7908\n",
            "Epoch 11/12\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 4.3622 - accuracy: 0.8408\n",
            "Epoch 12/12\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 3.6854 - accuracy: 0.8385\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 61.9844 - accuracy: 0.1000\n",
            "Epoch 1/12\n",
            "15/15 [==============================] - 1s 8ms/step - loss: 204.7339 - accuracy: 0.1199\n",
            "Epoch 2/12\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 43.1795 - accuracy: 0.2519\n",
            "Epoch 3/12\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 26.5583 - accuracy: 0.3842\n",
            "Epoch 4/12\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 21.1253 - accuracy: 0.4736\n",
            "Epoch 5/12\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 9.6630 - accuracy: 0.6187\n",
            "Epoch 6/12\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 10.0063 - accuracy: 0.6586\n",
            "Epoch 7/12\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 4.7169 - accuracy: 0.7742\n",
            "Epoch 8/12\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 6.7232 - accuracy: 0.7455\n",
            "Epoch 9/12\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 6.6742 - accuracy: 0.7035\n",
            "Epoch 10/12\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.4698 - accuracy: 0.9036\n",
            "Epoch 11/12\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 4.5183 - accuracy: 0.8045\n",
            "Epoch 12/12\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 2.9029 - accuracy: 0.8471\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 58.7426 - accuracy: 0.1083\n",
            "Epoch 1/12\n",
            "15/15 [==============================] - 1s 9ms/step - loss: 211.7315 - accuracy: 0.0647\n",
            "Epoch 2/12\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 41.0569 - accuracy: 0.2867\n",
            "Epoch 3/12\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 22.1316 - accuracy: 0.4572\n",
            "Epoch 4/12\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 20.8088 - accuracy: 0.5181\n",
            "Epoch 5/12\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 8.0171 - accuracy: 0.6893\n",
            "Epoch 6/12\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 5.6140 - accuracy: 0.7286\n",
            "Epoch 7/12\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 6.4891 - accuracy: 0.7213\n",
            "Epoch 8/12\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 6.9676 - accuracy: 0.7771\n",
            "Epoch 9/12\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 3.4589 - accuracy: 0.8614\n",
            "Epoch 10/12\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 4.9710 - accuracy: 0.7588\n",
            "Epoch 11/12\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 3.9331 - accuracy: 0.8225\n",
            "Epoch 12/12\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 2.5586 - accuracy: 0.8457\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 54.0074 - accuracy: 0.1333\n",
            "Epoch 1/12\n",
            "15/15 [==============================] - 1s 8ms/step - loss: 211.7995 - accuracy: 0.0903\n",
            "Epoch 2/12\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 42.6982 - accuracy: 0.2825\n",
            "Epoch 3/12\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 25.8744 - accuracy: 0.4126\n",
            "Epoch 4/12\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 16.4866 - accuracy: 0.5050\n",
            "Epoch 5/12\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 7.7433 - accuracy: 0.6966\n",
            "Epoch 6/12\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 10.5345 - accuracy: 0.6519\n",
            "Epoch 7/12\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 6.8539 - accuracy: 0.6958\n",
            "Epoch 8/12\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 3.8507 - accuracy: 0.8319\n",
            "Epoch 9/12\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 4.2242 - accuracy: 0.7998\n",
            "Epoch 10/12\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.9831 - accuracy: 0.8408\n",
            "Epoch 11/12\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 2.8670 - accuracy: 0.8442\n",
            "Epoch 12/12\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 3.9207 - accuracy: 0.7871\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 54.9022 - accuracy: 0.1500\n",
            "Epoch 1/12\n",
            "15/15 [==============================] - 1s 8ms/step - loss: 177.9846 - accuracy: 0.0802\n",
            "Epoch 2/12\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 41.4432 - accuracy: 0.3016\n",
            "Epoch 3/12\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 25.1575 - accuracy: 0.4270\n",
            "Epoch 4/12\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 13.8274 - accuracy: 0.5678\n",
            "Epoch 5/12\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 12.5683 - accuracy: 0.6021\n",
            "Epoch 6/12\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 5.4847 - accuracy: 0.7770\n",
            "Epoch 7/12\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 6.2112 - accuracy: 0.7381\n",
            "Epoch 8/12\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 6.3269 - accuracy: 0.7880\n",
            "Epoch 9/12\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 5.1057 - accuracy: 0.7906\n",
            "Epoch 10/12\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 3.0114 - accuracy: 0.8409\n",
            "Epoch 11/12\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 3.9941 - accuracy: 0.8399\n",
            "Epoch 12/12\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 5.9797 - accuracy: 0.8161\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 69.6538 - accuracy: 0.0917\n",
            "8/8 [==============================] - 1s 10ms/step - loss: 245.2505 - accuracy: 0.1265\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 136.1006 - accuracy: 0.1167\n",
            "8/8 [==============================] - 1s 11ms/step - loss: 246.5792 - accuracy: 0.1163\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 159.8937 - accuracy: 0.1000\n",
            "8/8 [==============================] - 1s 10ms/step - loss: 190.9760 - accuracy: 0.1152\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd9c76f4a70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 121.4655 - accuracy: 0.1083\n",
            "8/8 [==============================] - 1s 9ms/step - loss: 237.4253 - accuracy: 0.0744\n",
            "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd9b396f290> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 94.6680 - accuracy: 0.1083\n",
            "8/8 [==============================] - 1s 9ms/step - loss: 233.6315 - accuracy: 0.1051\n",
            "WARNING:tensorflow:6 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd9c7a23050> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 108.8191 - accuracy: 0.1250\n",
            "Epoch 1/6\n",
            "8/8 [==============================] - 1s 8ms/step - loss: 262.7429 - accuracy: 0.1231\n",
            "Epoch 2/6\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 113.5815 - accuracy: 0.1859\n",
            "Epoch 3/6\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 34.2200 - accuracy: 0.3306\n",
            "Epoch 4/6\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 36.5408 - accuracy: 0.3946\n",
            "Epoch 5/6\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 26.6810 - accuracy: 0.4851\n",
            "Epoch 6/6\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 17.4686 - accuracy: 0.5381\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd9c7840440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 70.7773 - accuracy: 0.0917\n",
            "Epoch 1/6\n",
            "8/8 [==============================] - 1s 9ms/step - loss: 221.7162 - accuracy: 0.1102\n",
            "Epoch 2/6\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 66.1971 - accuracy: 0.2380\n",
            "Epoch 3/6\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 35.7918 - accuracy: 0.3470\n",
            "Epoch 4/6\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 26.4692 - accuracy: 0.4479\n",
            "Epoch 5/6\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 25.9613 - accuracy: 0.4425\n",
            "Epoch 6/6\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 20.7778 - accuracy: 0.5663\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd9cc494170> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 68.1504 - accuracy: 0.1167\n",
            "Epoch 1/6\n",
            "8/8 [==============================] - 1s 9ms/step - loss: 234.3593 - accuracy: 0.0962\n",
            "Epoch 2/6\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 72.5662 - accuracy: 0.2078\n",
            "Epoch 3/6\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 52.2560 - accuracy: 0.2771\n",
            "Epoch 4/6\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 24.9843 - accuracy: 0.4272\n",
            "Epoch 5/6\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 21.9249 - accuracy: 0.5364\n",
            "Epoch 6/6\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 17.0966 - accuracy: 0.6057\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd9c7a23e60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 60.3248 - accuracy: 0.1083\n",
            "Epoch 1/6\n",
            "8/8 [==============================] - 1s 10ms/step - loss: 225.0178 - accuracy: 0.0919\n",
            "Epoch 2/6\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 76.7186 - accuracy: 0.1637\n",
            "Epoch 3/6\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 36.7576 - accuracy: 0.3111\n",
            "Epoch 4/6\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 22.2781 - accuracy: 0.4592\n",
            "Epoch 5/6\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 14.0970 - accuracy: 0.5347\n",
            "Epoch 6/6\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 8.5240 - accuracy: 0.6434\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd9cc19cd40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 69.3645 - accuracy: 0.1417\n",
            "Epoch 1/6\n",
            "8/8 [==============================] - 1s 10ms/step - loss: 211.8111 - accuracy: 0.0735\n",
            "Epoch 2/6\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 62.1247 - accuracy: 0.2307\n",
            "Epoch 3/6\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 26.2408 - accuracy: 0.4067\n",
            "Epoch 4/6\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 25.7994 - accuracy: 0.4364\n",
            "Epoch 5/6\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 25.3704 - accuracy: 0.5180\n",
            "Epoch 6/6\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 8.7502 - accuracy: 0.6996\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd9c0b57a70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 59.8575 - accuracy: 0.1500\n",
            "Epoch 1/12\n",
            "8/8 [==============================] - 1s 10ms/step - loss: 218.0629 - accuracy: 0.1221\n",
            "Epoch 2/12\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 83.5082 - accuracy: 0.2018\n",
            "Epoch 3/12\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 32.7551 - accuracy: 0.3193\n",
            "Epoch 4/12\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 20.0690 - accuracy: 0.4908\n",
            "Epoch 5/12\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 19.6990 - accuracy: 0.4830\n",
            "Epoch 6/12\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 17.7390 - accuracy: 0.5569\n",
            "Epoch 7/12\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 6.6826 - accuracy: 0.7030\n",
            "Epoch 8/12\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 8.0742 - accuracy: 0.7185\n",
            "Epoch 9/12\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 3.6169 - accuracy: 0.8218\n",
            "Epoch 10/12\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 8.1740 - accuracy: 0.7203\n",
            "Epoch 11/12\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 4.8578 - accuracy: 0.7840\n",
            "Epoch 12/12\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 7.4635 - accuracy: 0.7513\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd9cc0d7200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 63.6434 - accuracy: 0.0917\n",
            "Epoch 1/12\n",
            "8/8 [==============================] - 1s 10ms/step - loss: 261.6412 - accuracy: 0.1103\n",
            "Epoch 2/12\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 86.5929 - accuracy: 0.1734\n",
            "Epoch 3/12\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 50.4526 - accuracy: 0.3118\n",
            "Epoch 4/12\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 22.1544 - accuracy: 0.4474\n",
            "Epoch 5/12\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 21.8782 - accuracy: 0.4789\n",
            "Epoch 6/12\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 12.5006 - accuracy: 0.6504\n",
            "Epoch 7/12\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 27.9614 - accuracy: 0.4928\n",
            "Epoch 8/12\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 5.6235 - accuracy: 0.7654\n",
            "Epoch 9/12\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 7.0280 - accuracy: 0.7455\n",
            "Epoch 10/12\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 11.5268 - accuracy: 0.6734\n",
            "Epoch 11/12\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 5.1880 - accuracy: 0.7854\n",
            "Epoch 12/12\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 4.6740 - accuracy: 0.8009\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd9b4b03b00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 67.1159 - accuracy: 0.1250\n",
            "Epoch 1/12\n",
            "8/8 [==============================] - 1s 12ms/step - loss: 234.0001 - accuracy: 0.0884\n",
            "Epoch 2/12\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 73.8771 - accuracy: 0.2115\n",
            "Epoch 3/12\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 41.1100 - accuracy: 0.3110\n",
            "Epoch 4/12\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 25.2425 - accuracy: 0.4482\n",
            "Epoch 5/12\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 21.6967 - accuracy: 0.5392\n",
            "Epoch 6/12\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 19.9508 - accuracy: 0.6040\n",
            "Epoch 7/12\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 8.3137 - accuracy: 0.7191\n",
            "Epoch 8/12\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 9.1919 - accuracy: 0.6977\n",
            "Epoch 9/12\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 8.2523 - accuracy: 0.7328\n",
            "Epoch 10/12\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 12.6394 - accuracy: 0.6718\n",
            "Epoch 11/12\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 2.4410 - accuracy: 0.8737\n",
            "Epoch 12/12\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 8.1999 - accuracy: 0.7726\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd9c789b560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 72.7453 - accuracy: 0.0833\n",
            "Epoch 1/12\n",
            "8/8 [==============================] - 1s 10ms/step - loss: 235.0842 - accuracy: 0.0978\n",
            "Epoch 2/12\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 64.8497 - accuracy: 0.2315\n",
            "Epoch 3/12\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 36.4610 - accuracy: 0.3639\n",
            "Epoch 4/12\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 21.2701 - accuracy: 0.4776\n",
            "Epoch 5/12\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 19.9201 - accuracy: 0.4925\n",
            "Epoch 6/12\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 8.7772 - accuracy: 0.6821\n",
            "Epoch 7/12\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 16.3069 - accuracy: 0.5792\n",
            "Epoch 8/12\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 7.1850 - accuracy: 0.7159\n",
            "Epoch 9/12\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 3.3609 - accuracy: 0.8476\n",
            "Epoch 10/12\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 5.6432 - accuracy: 0.7817\n",
            "Epoch 11/12\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 9.5739 - accuracy: 0.7196\n",
            "Epoch 12/12\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1.7992 - accuracy: 0.8945\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd9c761f170> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 68.7325 - accuracy: 0.1583\n",
            "Epoch 1/12\n",
            "8/8 [==============================] - 1s 11ms/step - loss: 221.7990 - accuracy: 0.0939\n",
            "Epoch 2/12\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 90.8567 - accuracy: 0.1907\n",
            "Epoch 3/12\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 51.0073 - accuracy: 0.2637\n",
            "Epoch 4/12\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 21.6996 - accuracy: 0.4610\n",
            "Epoch 5/12\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 18.7117 - accuracy: 0.5274\n",
            "Epoch 6/12\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 19.8549 - accuracy: 0.5076\n",
            "Epoch 7/12\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 15.3466 - accuracy: 0.6442\n",
            "Epoch 8/12\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 5.0485 - accuracy: 0.7565\n",
            "Epoch 9/12\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 10.9677 - accuracy: 0.6501\n",
            "Epoch 10/12\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 5.2096 - accuracy: 0.8186\n",
            "Epoch 11/12\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 7.1900 - accuracy: 0.7274\n",
            "Epoch 12/12\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 3.6933 - accuracy: 0.8129\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd9cc19cdd0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 66.0475 - accuracy: 0.0917\n",
            "4/4 [==============================] - 1s 15ms/step - loss: 232.8038 - accuracy: 0.1026\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd9c7a7e560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 298.7627 - accuracy: 0.0667\n",
            "4/4 [==============================] - 1s 12ms/step - loss: 221.3282 - accuracy: 0.1015\n",
            "WARNING:tensorflow:7 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd9c77527a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 234.5938 - accuracy: 0.0750\n",
            "4/4 [==============================] - 1s 14ms/step - loss: 221.5397 - accuracy: 0.0888\n",
            "WARNING:tensorflow:7 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd9c79beef0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 242.0293 - accuracy: 0.0833\n",
            "4/4 [==============================] - 1s 14ms/step - loss: 202.8532 - accuracy: 0.1184\n",
            "WARNING:tensorflow:8 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd9c0b25560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 298.8182 - accuracy: 0.1417\n",
            "4/4 [==============================] - 1s 14ms/step - loss: 204.1004 - accuracy: 0.1038\n",
            "WARNING:tensorflow:8 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd9c518e830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 128ms/step - loss: 324.7111 - accuracy: 0.1000\n",
            "Epoch 1/6\n",
            "4/4 [==============================] - 1s 13ms/step - loss: 212.0007 - accuracy: 0.1061\n",
            "Epoch 2/6\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 279.6539 - accuracy: 0.1387\n",
            "Epoch 3/6\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 128.5895 - accuracy: 0.1809\n",
            "Epoch 4/6\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 49.5969 - accuracy: 0.3013\n",
            "Epoch 5/6\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 45.3347 - accuracy: 0.3574\n",
            "Epoch 6/6\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 27.2183 - accuracy: 0.4231\n",
            "WARNING:tensorflow:9 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd9cc0d7680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 82.3325 - accuracy: 0.0917\n",
            "Epoch 1/6\n",
            "4/4 [==============================] - 1s 15ms/step - loss: 233.7918 - accuracy: 0.0815\n",
            "Epoch 2/6\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 182.3778 - accuracy: 0.1692\n",
            "Epoch 3/6\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 66.8910 - accuracy: 0.2258\n",
            "Epoch 4/6\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 31.8376 - accuracy: 0.4155\n",
            "Epoch 5/6\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 22.0523 - accuracy: 0.4602\n",
            "Epoch 6/6\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 20.9471 - accuracy: 0.5016\n",
            "WARNING:tensorflow:9 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd9c7934d40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 69.9179 - accuracy: 0.1000\n",
            "Epoch 1/6\n",
            "4/4 [==============================] - 1s 14ms/step - loss: 216.6728 - accuracy: 0.1102\n",
            "Epoch 2/6\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 235.2456 - accuracy: 0.1382\n",
            "Epoch 3/6\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 98.8263 - accuracy: 0.1823\n",
            "Epoch 4/6\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 40.6473 - accuracy: 0.3130\n",
            "Epoch 5/6\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 44.5702 - accuracy: 0.3421\n",
            "Epoch 6/6\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 20.4103 - accuracy: 0.4744\n",
            "WARNING:tensorflow:10 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd9c78e55f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 67.1114 - accuracy: 0.1250\n",
            "Epoch 1/6\n",
            "4/4 [==============================] - 1s 13ms/step - loss: 223.8421 - accuracy: 0.1000\n",
            "Epoch 2/6\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 207.4751 - accuracy: 0.1565\n",
            "Epoch 3/6\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 96.5968 - accuracy: 0.2097\n",
            "Epoch 4/6\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 42.5399 - accuracy: 0.3116\n",
            "Epoch 5/6\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 30.8759 - accuracy: 0.3873\n",
            "Epoch 6/6\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 15.0346 - accuracy: 0.5473\n",
            "WARNING:tensorflow:10 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd9c764aef0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 495ms/step - loss: 57.1400 - accuracy: 0.0833\n",
            "Epoch 1/6\n",
            "4/4 [==============================] - 1s 16ms/step - loss: 227.4376 - accuracy: 0.0803\n",
            "Epoch 2/6\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 254.5813 - accuracy: 0.1402\n",
            "Epoch 3/6\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 73.3385 - accuracy: 0.1939\n",
            "Epoch 4/6\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 50.9009 - accuracy: 0.2726\n",
            "Epoch 5/6\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 29.0670 - accuracy: 0.4220\n",
            "Epoch 6/6\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 21.7266 - accuracy: 0.5052\n",
            "WARNING:tensorflow:11 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd9c3748560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 73.3335 - accuracy: 0.1083\n",
            "Epoch 1/12\n",
            "4/4 [==============================] - 1s 14ms/step - loss: 241.3493 - accuracy: 0.0741\n",
            "Epoch 2/12\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 251.5754 - accuracy: 0.1526\n",
            "Epoch 3/12\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 88.3771 - accuracy: 0.2338\n",
            "Epoch 4/12\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 38.0813 - accuracy: 0.3146\n",
            "Epoch 5/12\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 28.8508 - accuracy: 0.4158\n",
            "Epoch 6/12\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 15.6091 - accuracy: 0.5191\n",
            "Epoch 7/12\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 30.9983 - accuracy: 0.4390\n",
            "Epoch 8/12\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 12.7261 - accuracy: 0.6133\n",
            "Epoch 9/12\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 9.2131 - accuracy: 0.6794\n",
            "Epoch 10/12\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 6.0589 - accuracy: 0.7478\n",
            "Epoch 11/12\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 2.0649 - accuracy: 0.9148\n",
            "Epoch 12/12\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 4.8846 - accuracy: 0.8064\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd9c79adb00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 103.0784 - accuracy: 0.0750\n",
            "Epoch 1/12\n",
            "4/4 [==============================] - 1s 15ms/step - loss: 241.1871 - accuracy: 0.0874\n",
            "Epoch 2/12\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 212.8804 - accuracy: 0.1409\n",
            "Epoch 3/12\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 74.1143 - accuracy: 0.2225\n",
            "Epoch 4/12\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 32.7405 - accuracy: 0.3795\n",
            "Epoch 5/12\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 26.6547 - accuracy: 0.4154\n",
            "Epoch 6/12\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 33.5404 - accuracy: 0.3915\n",
            "Epoch 7/12\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 20.1964 - accuracy: 0.5489\n",
            "Epoch 8/12\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 14.0675 - accuracy: 0.6655\n",
            "Epoch 9/12\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 20.3413 - accuracy: 0.5359\n",
            "Epoch 10/12\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 14.5575 - accuracy: 0.6371\n",
            "Epoch 11/12\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 7.5409 - accuracy: 0.7345\n",
            "Epoch 12/12\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 13.2113 - accuracy: 0.6660\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd9bd790050> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 61.8950 - accuracy: 0.1583\n",
            "Epoch 1/12\n",
            "4/4 [==============================] - 1s 16ms/step - loss: 233.5881 - accuracy: 0.1010\n",
            "Epoch 2/12\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 222.1792 - accuracy: 0.1715\n",
            "Epoch 3/12\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 80.4443 - accuracy: 0.2454\n",
            "Epoch 4/12\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 39.9336 - accuracy: 0.3603\n",
            "Epoch 5/12\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 19.1439 - accuracy: 0.5179\n",
            "Epoch 6/12\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 29.2151 - accuracy: 0.4337\n",
            "Epoch 7/12\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 25.4138 - accuracy: 0.4372\n",
            "Epoch 8/12\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 12.7145 - accuracy: 0.6548\n",
            "Epoch 9/12\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 7.9192 - accuracy: 0.7151\n",
            "Epoch 10/12\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 7.2150 - accuracy: 0.7225\n",
            "Epoch 11/12\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 6.7564 - accuracy: 0.7496\n",
            "Epoch 12/12\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 14.7619 - accuracy: 0.6559\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd9cc3029e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 71.0002 - accuracy: 0.0917\n",
            "Epoch 1/12\n",
            "4/4 [==============================] - 1s 13ms/step - loss: 210.6453 - accuracy: 0.1155\n",
            "Epoch 2/12\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 158.6173 - accuracy: 0.1634\n",
            "Epoch 3/12\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 62.3846 - accuracy: 0.2827\n",
            "Epoch 4/12\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 31.4881 - accuracy: 0.4294\n",
            "Epoch 5/12\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 16.3780 - accuracy: 0.5386\n",
            "Epoch 6/12\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 30.5362 - accuracy: 0.4486\n",
            "Epoch 7/12\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 9.8967 - accuracy: 0.6809\n",
            "Epoch 8/12\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 2.8207 - accuracy: 0.8388\n",
            "Epoch 9/12\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 3.8863 - accuracy: 0.7995\n",
            "Epoch 10/12\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 8.2928 - accuracy: 0.7304\n",
            "Epoch 11/12\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 6.1192 - accuracy: 0.7085\n",
            "Epoch 12/12\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 17.8815 - accuracy: 0.5741\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd9cc19cb90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 68.4456 - accuracy: 0.1167\n",
            "Epoch 1/12\n",
            "4/4 [==============================] - 1s 12ms/step - loss: 220.2295 - accuracy: 0.1096\n",
            "Epoch 2/12\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 198.4994 - accuracy: 0.1539\n",
            "Epoch 3/12\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 97.2220 - accuracy: 0.2152\n",
            "Epoch 4/12\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 22.4714 - accuracy: 0.4159\n",
            "Epoch 5/12\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 21.9706 - accuracy: 0.4824\n",
            "Epoch 6/12\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 19.5463 - accuracy: 0.5409\n",
            "Epoch 7/12\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 10.8404 - accuracy: 0.6468\n",
            "Epoch 8/12\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 14.7839 - accuracy: 0.5520\n",
            "Epoch 9/12\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 14.7965 - accuracy: 0.6711\n",
            "Epoch 10/12\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 12.1767 - accuracy: 0.6188\n",
            "Epoch 11/12\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 2.3180 - accuracy: 0.8720\n",
            "Epoch 12/12\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 1.6560 - accuracy: 0.8889\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd9bc6508c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 55.7611 - accuracy: 0.1000\n",
            "Epoch 1/6\n",
            "19/19 [==============================] - 1s 8ms/step - loss: 210.0042 - accuracy: 0.0826\n",
            "Epoch 2/6\n",
            "19/19 [==============================] - 0s 10ms/step - loss: 45.1324 - accuracy: 0.2858\n",
            "Epoch 3/6\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 29.6006 - accuracy: 0.3866\n",
            "Epoch 4/6\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 17.2055 - accuracy: 0.5037\n",
            "Epoch 5/6\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 12.3094 - accuracy: 0.6167\n",
            "Epoch 6/6\n",
            "19/19 [==============================] - 0s 10ms/step - loss: 8.1353 - accuracy: 0.6779\n",
            "Chosing Neural Network params without HOG data:  {'batch_size': 32, 'epochs': 6}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NN Accuracy without shuffled data: 0.815\n",
            "NN Accuracy with shuffled data: 0.11333333333333333\n",
            "\n",
            "NN Confusion matrix without shuffled data:\n",
            "[[42  0  1  0  0  1  0  6  3  0]\n",
            " [ 0 73  0  0  0  0  0  0  0  0]\n",
            " [ 0  0 59  0  0  1  1  2  1  0]\n",
            " [ 0  0  4 45  0 12  0  0  1  0]\n",
            " [ 0  2  0  1 53  1  3  0  0  7]\n",
            " [ 0  0  0  5  5 41  0  0  5  0]\n",
            " [ 1  0  1  1  1  3 43  2  0  0]\n",
            " [ 0  1  3  3  2  0  0 43  0  5]\n",
            " [ 0  2  3  0  2  2  2  1 39  1]\n",
            " [ 0  0  1  2  4  1  0  4  1 51]]\n",
            "NN Classification report without shuffled data:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.79      0.88        53\n",
            "           1       0.94      1.00      0.97        73\n",
            "           2       0.82      0.92      0.87        64\n",
            "           3       0.79      0.73      0.76        62\n",
            "           4       0.79      0.79      0.79        67\n",
            "           5       0.66      0.73      0.69        56\n",
            "           6       0.88      0.83      0.85        52\n",
            "           7       0.74      0.75      0.75        57\n",
            "           8       0.78      0.75      0.76        52\n",
            "           9       0.80      0.80      0.80        64\n",
            "\n",
            "    accuracy                           0.81       600\n",
            "   macro avg       0.82      0.81      0.81       600\n",
            "weighted avg       0.82      0.81      0.81       600\n",
            "\n",
            "\n",
            "\n",
            "NN Confusion matrix with shuffled data:\n",
            "[[ 4  6 10  7  6  2  3  4  3  8]\n",
            " [ 4 11 10  7  5  8  5  3  2 18]\n",
            " [ 6  9 12 10  5  3  1  3  6  9]\n",
            " [ 4  3 14 14  2  1  2  3 10  9]\n",
            " [10  8  6 10  6  1  4  3  7 12]\n",
            " [ 4  6 10  7  3  3  4  2  6 11]\n",
            " [ 4 11  6  6  5  1  2  3  3 11]\n",
            " [ 3  6 10  7  7  1  4  1  5 13]\n",
            " [ 5  5  9 12  2  2  3  1  4  9]\n",
            " [ 6 12 11 10  5  1  1  1  6 11]]\n",
            "NN Classification report with shuffled data:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.08      0.08      0.08        53\n",
            "           1       0.14      0.15      0.15        73\n",
            "           2       0.12      0.19      0.15        64\n",
            "           3       0.16      0.23      0.18        62\n",
            "           4       0.13      0.09      0.11        67\n",
            "           5       0.13      0.05      0.08        56\n",
            "           6       0.07      0.04      0.05        52\n",
            "           7       0.04      0.02      0.02        57\n",
            "           8       0.08      0.08      0.08        52\n",
            "           9       0.10      0.17      0.13        64\n",
            "\n",
            "    accuracy                           0.11       600\n",
            "   macro avg       0.10      0.11      0.10       600\n",
            "weighted avg       0.11      0.11      0.11       600\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zx95fVgLjnlG"
      },
      "source": [
        "Na podstawie powyższych rezultatów można zauważyc, że Sieć neuronowa działa lepiej dla obrazów, które nie zostały zmieszane. \n",
        "\n",
        "*   Accuracy dla obrazów wymiesznaych: 0.113\n",
        "*   Accuracy dla obrazów niewymieszanych: 0.815\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tB1AVegArWyE"
      },
      "source": [
        "Dla wszystkich klasyfikatorów wyniki z surowymi, wymieszanymi danymi były o wiele niższe w stosunku do danych, które nie zostały wymieszane. "
      ]
    }
  ]
}